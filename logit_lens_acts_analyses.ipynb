{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f6294ae",
   "metadata": {},
   "source": [
    "# ==============================================\n",
    "# Notebook for Logit Lens and Hidden Acts ======\n",
    "# =============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ad138a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datasets import load_dataset, DownloadMode\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from old_lens.mi_utils.quant_configs.bnb_configs import load_bnb_in_4bit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f24fe2",
   "metadata": {},
   "source": [
    "# ==============================================\n",
    "# Models & Dataset =============================\n",
    "# =============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340878a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r'D:\\LogitLensData\\nq'\n",
    "\n",
    "destination_path = str(Path(filepath))\n",
    "nq_dataset = load_dataset(\n",
    "    'sentence-transformers/natural-questions',\n",
    "    split={\n",
    "        'train': 'train[:1000]'\n",
    "    },\n",
    "    cache_dir=destination_path,\n",
    "    download_mode=DownloadMode.REUSE_DATASET_IF_EXISTS,\n",
    "    keep_in_memory=True\n",
    ")\n",
    "\n",
    "nq_queries = nq_dataset['train']['query']\n",
    "nq_answers = nq_dataset['train']['answer']\n",
    "\n",
    "nq_queries_200 = nq_queries[:200]\n",
    "\"\"\"nq_queries_400 = nq_queries[200:400]\n",
    "nq_queries_600 = nq_queries[400:600]\n",
    "nq_queries_800 = nq_queries[600:800]\n",
    "nq_queries_1000 = nq_queries[800:1000]\n",
    "nq_queries_200_1 = nq_queries[:1]\"\"\"\n",
    "nq_1000 = nq_queries[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce6d258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class Models(Enum):\n",
    "    LAIN8B = \"Models/LLaMA3Instruct\"\n",
    "    HF100B = \"Models/HF1BitLLM100Btokens\"\n",
    "\n",
    "\n",
    "class Names(Enum):\n",
    "    LAIN8B = \"Meta-Llama-3-8B-Instruct-fp\"\n",
    "    HF100B = \"Llama3-8B-1.58-100B-tokens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f135f946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_tok(\n",
    "    model_name: str,\n",
    "    low_cpu_mem_usage: bool = True,\n",
    "    local_files_only: bool = True,\n",
    "    device_map: str = \"cpu\",\n",
    "    dtype: torch.dtype = torch.float32,\n",
    "    load_in_8bit: bool = False\n",
    "):\n",
    "    tok = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        output_hidden_states=True,\n",
    "        return_dict_in_generate=True,\n",
    "        return_dict=True,\n",
    "        output_attentions=True,\n",
    "        low_cpu_mem_usage=low_cpu_mem_usage,\n",
    "        local_files_only=local_files_only,\n",
    "        device_map=device_map,\n",
    "        load_in_8bit=load_in_8bit,\n",
    "        torch_dtype=dtype,\n",
    "        attn_implementation=\"eager\",\n",
    "    )\n",
    "    return model, tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6741ccfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb304379379549fbbc289e12a1fb33dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_orig, orig_tokenizer = load_model_and_tok(Models.LAIN8B.value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50589c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79733ce402e4458ab08aea817c8b74a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_8bit, orig_tokenizer = load_model_and_tok(Models.LAIN8B.value, dtype=torch.float16, load_in_8bit=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee4cbb81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a5fe29eaa840b5b0df31e921543582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_4bit, orig_tokenizer = load_bnb_in_4bit(Models.LAIN8B.value, double_quant=False, dtype=torch.float16, device_map=\"cpu\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93562c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_quant, quant_tokenizer = load_model_and_tok(Models.HF100B.value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bdeb4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Token Length Statistics (LLaMA-3-8B-Instruct tokenizer) ===\n",
      "Samples analyzed: 1000\n",
      "Mean length:       11.21\n",
      "Median length:     11\n",
      "90th percentile:   14\n",
      "95th percentile:   15\n",
      "Max observed len:  21\n",
      "Min observed len:  9\n"
     ]
    }
   ],
   "source": [
    "lengths = []\n",
    "for q in nq_1000:\n",
    "    ids = orig_tokenizer.encode(q, add_special_tokens=True)\n",
    "    lengths.append(len(ids))\n",
    "\n",
    "print(\"=== Token Length Statistics (LLaMA-3-8B-Instruct tokenizer) ===\")\n",
    "print(f\"Samples analyzed: {len(lengths)}\")\n",
    "print(f\"Mean length:       {np.mean(lengths):.2f}\")\n",
    "print(f\"Median length:     {np.median(lengths):.0f}\")\n",
    "print(f\"90th percentile:   {np.percentile(lengths, 90):.0f}\")\n",
    "print(f\"95th percentile:   {np.percentile(lengths, 95):.0f}\")\n",
    "print(f\"Max observed len:  {np.max(lengths)}\")\n",
    "print(f\"Min observed len:  {np.min(lengths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f61cc4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(hidden_states: torch.Tensor, attention_mask: Optional[torch.Tensor] = None, position_ids: Optional[torch.LongTensor] = None, past_key_value: Optional[transformers.cache_utils.Cache] = None, output_attentions: Optional[bool] = False, use_cache: Optional[bool] = False, cache_position: Optional[torch.LongTensor] = None, position_embeddings: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, **kwargs) -> Tuple[torch.FloatTensor, Optional[Tuple[torch.FloatTensor, torch.FloatTensor]]]\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "sig = inspect.signature(model_orig.model.layers[0].forward)\n",
    "print(sig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b729d26",
   "metadata": {},
   "source": [
    "# ==============================================\n",
    "# Logit Lens with Normaliztion =================\n",
    "# =============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37206e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"MatMul8bitLt: inputs will be cast\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Normalization modes (as before)\n",
    "# ============================================================\n",
    "def apply_normalization(x, model, normalize_mode=\"raw\", block=None, layer_index=None):\n",
    "    x = x.to(torch.float32)  # ensure consistent dtype\n",
    "    \n",
    "    if normalize_mode == \"raw\":\n",
    "        return x\n",
    "\n",
    "    elif normalize_mode == \"unit_rms\":\n",
    "\n",
    "        eps = 1e-5\n",
    "        return x / (x.pow(2).mean(dim=-1, keepdim=True).add(eps).sqrt())\n",
    "\n",
    "    elif normalize_mode == \"rms_layer\":\n",
    "        if layer_index == -1:\n",
    "            return x\n",
    "        elif block is not None:\n",
    "            return block.post_attention_layernorm(x)\n",
    "        else:\n",
    "            #return model.model.norm(x)\n",
    "            return model.model.norm(x).to(torch.float32)\n",
    "\n",
    "    elif normalize_mode == \"norm_rms\":\n",
    "        if layer_index == -1:\n",
    "            return x\n",
    "        else:\n",
    "            #return model.model.norm(x)\n",
    "            return model.model.norm(x).to(torch.float32)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown normalization_mode: {normalize_mode}\")\n",
    "\n",
    "# ============================================================\n",
    "# Helper: causal + padding mask for LLaMA blocks\n",
    "# ============================================================\n",
    "def build_full_attention_mask(input_ids, attention_mask, device):\n",
    "    \"\"\"\n",
    "    Builds a [batch, 1, tgt_len, src_len] mask.\n",
    "    Uses boolean mask when possible (preferred by Flash/Sdp kernels),\n",
    "    otherwise additive mask in float32 with -1e9 fill.\n",
    "    \"\"\"\n",
    "    bsz, seq_len = input_ids.shape\n",
    "\n",
    "    # (1) causal mask\n",
    "    causal = torch.triu(torch.ones((seq_len, seq_len), device=device, dtype=torch.bool), diagonal=1)\n",
    "    causal = causal.unsqueeze(0).unsqueeze(0)  # [1, 1, T, T]\n",
    "\n",
    "    # (2) padding mask\n",
    "    if attention_mask is None:\n",
    "        padding_mask = torch.zeros((bsz, 1, 1, seq_len), device=device, dtype=torch.bool)\n",
    "    else:\n",
    "        padding_mask = (attention_mask[:, None, None, :] == 0)\n",
    "\n",
    "    # (3) combine: masked positions = True\n",
    "    full = causal | padding_mask  # bool mask\n",
    "\n",
    "    # For models expecting additive mask, convert to float\n",
    "    full = full.to(torch.float32) * -1e9\n",
    "    return full\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Collector with multiple normalization variants + attention weights (optional storage)\n",
    "# ============================================================\n",
    "@torch.no_grad()\n",
    "def collect_logit_lens_full(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    prompts,\n",
    "    batch_index=0,\n",
    "    max_len=17,\n",
    "    device=None,\n",
    "    clamp_logits=True,\n",
    "    save_path=None,\n",
    "    collect_attn=True,\n",
    "    save_attn=True,\n",
    "    norm_modes=(\"raw\", \"unit_rms\", \"norm_rms\"),\n",
    "):\n",
    "\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # --- Detect BitsAndBytes quantized models ---\n",
    "    bnb_layer_types = (\"Linear4bit\", \"Linear8bitLt\")\n",
    "    is_bnb_quantized = any(\n",
    "        any(name in type(m).__name__ for name in bnb_layer_types)\n",
    "        for m in model.modules()\n",
    "    )\n",
    "\n",
    "    if is_bnb_quantized:\n",
    "        try:\n",
    "            first_param_device = next(model.parameters()).device\n",
    "        except StopIteration:\n",
    "            first_param_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"[info] Detected BitsAndBytes quantized model → already on device {first_param_device}\")\n",
    "        model.eval()\n",
    "    else:\n",
    "        model = model.to(device).eval()\n",
    "\n",
    "    Path(save_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # ============================================================\n",
    "    # Tokenization\n",
    "    # ============================================================\n",
    "    encoded = []\n",
    "    pad_id = tokenizer.pad_token_id or tokenizer.eos_token_id\n",
    "    bos_id = tokenizer.bos_token_id\n",
    "    eos_id = tokenizer.eos_token_id\n",
    "\n",
    "    for p in prompts:\n",
    "        ids = tokenizer.encode(p, add_special_tokens=False)\n",
    "        content = ids[: max_len - 2]\n",
    "        ids = torch.tensor([bos_id] + content + [eos_id], dtype=torch.long)\n",
    "        if len(ids) < max_len:\n",
    "            ids = F.pad(ids, (0, max_len - len(ids)), value=pad_id)\n",
    "        encoded.append(ids)\n",
    "\n",
    "    input_ids = torch.stack(encoded, dim=0).to(device)\n",
    "\n",
    "    # ============================================================\n",
    "    # Build correct attention mask (BOS + content + first EOS)\n",
    "    # ============================================================\n",
    "    attention_mask = torch.ones_like(input_ids, dtype=torch.long)\n",
    "    for i, ids in enumerate(input_ids):\n",
    "        eos_positions = (ids == eos_id).nonzero(as_tuple=True)[0]\n",
    "        if len(eos_positions) > 0:\n",
    "            eos_pos = eos_positions[0].item()\n",
    "            attention_mask[i, eos_pos + 1 :] = 0\n",
    "\n",
    "    # ============================================================\n",
    "    # Attention + positional setup\n",
    "    # ============================================================\n",
    "    batch_size, seq_len = input_ids.shape\n",
    "    full_mask = build_full_attention_mask(input_ids, attention_mask, device)\n",
    "    position_ids = torch.arange(seq_len, device=device).unsqueeze(0).expand(batch_size, -1)\n",
    "    vocab_size = model.lm_head.out_features\n",
    "\n",
    "    print(f\"[info] Tokenized {batch_size} prompts | seq_len={seq_len} | pad_id={pad_id} | eos_id={eos_id}\")\n",
    "    print(f\"[info] Collecting from {len(model.model.layers)} layers | attn compute={collect_attn}, save={save_attn}\")\n",
    "\n",
    "    def project(x):\n",
    "        # ensure consistent dtype for analysis\n",
    "        x_fp32 = x.to(torch.float32)\n",
    "\n",
    "        # For quantized models, cast back to lm_head weight dtype before projection\n",
    "        head_dtype = next(model.lm_head.parameters()).dtype if any(p.dtype != torch.float32 for p in model.lm_head.parameters()) else torch.float32\n",
    "        x_cast = x_fp32.to(head_dtype)\n",
    "\n",
    "        logits = model.lm_head(x_cast)\n",
    "\n",
    "        if clamp_logits:\n",
    "            logits = torch.nan_to_num(logits, nan=0.0, posinf=80, neginf=-80)\n",
    "\n",
    "        # always return FP32 results for consistency\n",
    "        return logits.to(torch.float32)\n",
    "\n",
    "    rows = []\n",
    "    all_hidden, all_logits, all_attn = {}, {}, {}\n",
    "\n",
    "    # ============================================================\n",
    "    # Embedding layer\n",
    "    # ============================================================\n",
    "    #x = model.model.embed_tokens(input_ids)\n",
    "    x = model.model.embed_tokens(input_ids).to(torch.float32)\n",
    "    hidden_variants = {mode: apply_normalization(x.clone(), model, mode, layer_index=-1) for mode in norm_modes}\n",
    "    logits_variants = {mode: project(hidden_variants[mode]) for mode in norm_modes}\n",
    "\n",
    "    for mode in norm_modes:\n",
    "        all_hidden[f\"embed_tokens_{mode}\"] = hidden_variants[mode].cpu()\n",
    "        all_logits[f\"embed_tokens_{mode}\"] = logits_variants[mode].cpu()\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        rows.append({\n",
    "            \"prompt_id\": i,\n",
    "            \"prompt_text\": prompts[i],\n",
    "            \"batch_index\": batch_index,\n",
    "            \"vocab_size\": vocab_size,\n",
    "            \"layer_index\": -1,\n",
    "            \"layer_name\": \"embed_tokens\",\n",
    "            \"input_ids\": input_ids[i].cpu(),\n",
    "            \"target_ids\": input_ids[i, 1:].cpu(),\n",
    "            \"attention_mask\": attention_mask[i].cpu(),\n",
    "            **{f\"hidden_{m}\": hidden_variants[m][i, :-1].cpu() for m in norm_modes},\n",
    "            **{f\"logits_{m}\": logits_variants[m][i, :-1].cpu() for m in norm_modes},\n",
    "        })\n",
    "\n",
    "    # ============================================================\n",
    "    # Transformer layers\n",
    "    # ============================================================\n",
    "    for li, block in enumerate(model.model.layers):\n",
    "        out = block(\n",
    "            x,\n",
    "            position_ids=position_ids,\n",
    "            attention_mask=full_mask,\n",
    "            output_attentions=collect_attn,\n",
    "        )\n",
    "        x = out[0]\n",
    "        attn = out[1] if collect_attn else None\n",
    "\n",
    "        #layer_output = x.detach().clone()\n",
    "        layer_output = x.detach().clone().to(torch.float32)\n",
    "        hidden_variants = {\n",
    "            mode: apply_normalization(layer_output.clone(), model, mode, block=block, layer_index=li)\n",
    "            for mode in norm_modes\n",
    "        }\n",
    "        logits_variants = {mode: project(hidden_variants[mode]) for mode in norm_modes}\n",
    "\n",
    "        for mode in norm_modes:\n",
    "            hidden_variants[mode] = hidden_variants[mode][:, :-1, :]\n",
    "            logits_variants[mode] = logits_variants[mode][:, :-1, :]\n",
    "\n",
    "        for mode in norm_modes:\n",
    "            all_hidden[f\"layer.{li}_{mode}\"] = hidden_variants[mode].cpu()\n",
    "            all_logits[f\"layer.{li}_{mode}\"] = logits_variants[mode].cpu()\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            record = {\n",
    "                \"prompt_id\": i,\n",
    "                \"prompt_text\": prompts[i],\n",
    "                \"batch_index\": batch_index,\n",
    "                \"vocab_size\": vocab_size,\n",
    "                \"layer_index\": li,\n",
    "                \"layer_name\": f\"layer.{li}\",\n",
    "                \"input_ids\": input_ids[i].cpu(),\n",
    "                \"target_ids\": input_ids[i, 1:].cpu(),\n",
    "                \"attention_mask\": attention_mask[i].cpu(),\n",
    "                **{f\"hidden_{m}\": hidden_variants[m][i].cpu() for m in norm_modes},\n",
    "                **{f\"logits_{m}\": logits_variants[m][i].cpu() for m in norm_modes},\n",
    "            }\n",
    "            if save_attn and attn is not None:\n",
    "                record[\"attn\"] = attn[i].cpu()\n",
    "            rows.append(record)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    # ============================================================\n",
    "    # Final model RMSNorm output (apply model.norm for ALL modes)\n",
    "    # ============================================================\n",
    "    # Apply the model’s true RMSNorm — no custom normalization\n",
    "    #x = model.model.norm(x)\n",
    "    x = model.model.norm(x.to(torch.float32))\n",
    "\n",
    "    # Compute true hidden and logits using the same projection\n",
    "    h = x\n",
    "    l = project(h) \n",
    "\n",
    "    # Trim for next-token prediction\n",
    "    h, l = h[:, :-1, :], l[:, :-1, :]\n",
    "\n",
    "    # Store once for reference\n",
    "    all_hidden[\"output_true\"] = h.cpu()\n",
    "    all_logits[\"output_true\"] = l.cpu()\n",
    "\n",
    "    # --- Apply this SAME normalized output to all norm_modes ---\n",
    "    for mode in norm_modes:\n",
    "        all_hidden[f\"output_{mode}\"] = h.cpu()\n",
    "        all_logits[f\"output_{mode}\"] = l.cpu()\n",
    "\n",
    "    # --- Append a per-prompt metadata record identical to other layers ---\n",
    "    for i in range(batch_size):\n",
    "        rows.append({\n",
    "            \"prompt_id\": i,\n",
    "            \"prompt_text\": prompts[i],\n",
    "            \"batch_index\": batch_index,\n",
    "            \"vocab_size\": vocab_size,\n",
    "            \"layer_index\": len(model.model.layers),\n",
    "            \"layer_name\": \"output\",\n",
    "            \"input_ids\": input_ids[i].cpu(),\n",
    "            \"target_ids\": input_ids[i, 1:].cpu(),\n",
    "            \"attention_mask\": attention_mask[i].cpu(),\n",
    "            **{f\"hidden_{m}\": h[i].cpu() for m in norm_modes},\n",
    "            **{f\"logits_{m}\": l[i].cpu() for m in norm_modes},\n",
    "        })\n",
    "\n",
    "\n",
    "    # ============================================================\n",
    "    # Save and finish\n",
    "    # ============================================================\n",
    "    if save_path:\n",
    "        torch.save(rows, save_path)\n",
    "        print(f\"[saved] Logit-lens data → {save_path}\")\n",
    "\n",
    "    print(f\"[ok] Collected {len(rows)} entries from {len(model.model.layers)} layers (no redundant tensors)\")\n",
    "    return rows, all_hidden, all_logits, all_attn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8653a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "def run_logit_lens_in_batches(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    all_prompts,\n",
    "    batch_size=20,\n",
    "    save_prefix=\"logitlens_batch\",\n",
    "    max_len=17,\n",
    "    normalize_mode=(\"raw\", \"unit_rms\", \"norm_rms\"),\n",
    "    device=None,\n",
    "    clamp_logits=True,\n",
    "    collect_attn=False,\n",
    "    save_attn=False \n",
    "):\n",
    "    \"\"\"\n",
    "    Runs collect_logit_lens_full() in batches to avoid OOM.\n",
    "    Each batch is saved as a separate .pt file.\n",
    "    \"\"\"\n",
    "\n",
    "    num_batches = (len(all_prompts) + batch_size - 1) // batch_size\n",
    "    print(f\"[run] Processing {len(all_prompts)} prompts in {num_batches} batches of {batch_size}\")\n",
    "\n",
    "    for batch_idx in tqdm(range(num_batches), desc=\"Running logit lens batches\"):\n",
    "        start = batch_idx * batch_size\n",
    "        end = min((batch_idx + 1) * batch_size, len(all_prompts))\n",
    "        batch_prompts = all_prompts[start:end]\n",
    "\n",
    "        save_path = f\"{save_prefix}_batch{batch_idx:03d}.pt\"\n",
    "\n",
    "        print(f\"\\n[batch {batch_idx+1}/{num_batches}] {len(batch_prompts)} prompts → {save_path}\")\n",
    "\n",
    "        try:\n",
    "            rows, hidden_dict, logits_dict, all_attn = collect_logit_lens_full(\n",
    "                model=model,\n",
    "                tokenizer=tokenizer,\n",
    "                prompts=batch_prompts,\n",
    "                max_len=max_len,\n",
    "                device=device,\n",
    "                norm_modes=normalize_mode,\n",
    "                save_path=save_path,\n",
    "                clamp_logits=clamp_logits,\n",
    "                collect_attn=collect_attn,\n",
    "                save_attn=save_attn,\n",
    "            )\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            print(f\"[error] Batch {batch_idx} failed: {e}\")\n",
    "            continue\n",
    "\n",
    "        # -------------------------------\n",
    "        # Free GPU + CPU memory\n",
    "        # -------------------------------\n",
    "        del rows, hidden_dict, logits_dict, all_attn, batch_prompts\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    print(\"\\n[done] All batches processed and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c78c746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[run] Processing 1000 prompts in 50 batches of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running logit lens batches:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[batch 1/50] 20 prompts → saved_data/lens_data/m_4bit/m_4bit_modes_batch000.pt\n",
      "[info] Detected BitsAndBytes quantized model → already on device cpu\n",
      "[info] Tokenized 20 prompts | seq_len=17 | pad_id=128009 | eos_id=128009\n",
      "[info] Collecting from 32 layers | attn compute=False, save=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] Logit-lens data → saved_data/lens_data/m_4bit/m_4bit_modes_batch000.pt\n",
      "[ok] Collected 680 entries from 32 layers (no redundant tensors)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running logit lens batches:   2%|▏         | 1/50 [06:21<5:11:11, 381.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[batch 2/50] 20 prompts → saved_data/lens_data/m_4bit/m_4bit_modes_batch001.pt\n",
      "[info] Detected BitsAndBytes quantized model → already on device cpu\n",
      "[info] Tokenized 20 prompts | seq_len=17 | pad_id=128009 | eos_id=128009\n",
      "[info] Collecting from 32 layers | attn compute=False, save=False\n",
      "[saved] Logit-lens data → saved_data/lens_data/m_4bit/m_4bit_modes_batch001.pt\n",
      "[ok] Collected 680 entries from 32 layers (no redundant tensors)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running logit lens batches:   4%|▍         | 2/50 [12:24<4:56:42, 370.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[batch 3/50] 20 prompts → saved_data/lens_data/m_4bit/m_4bit_modes_batch002.pt\n",
      "[info] Detected BitsAndBytes quantized model → already on device cpu\n",
      "[info] Tokenized 20 prompts | seq_len=17 | pad_id=128009 | eos_id=128009\n",
      "[info] Collecting from 32 layers | attn compute=False, save=False\n",
      "[saved] Logit-lens data → saved_data/lens_data/m_4bit/m_4bit_modes_batch002.pt\n",
      "[ok] Collected 680 entries from 32 layers (no redundant tensors)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running logit lens batches:   6%|▌         | 3/50 [19:09<5:02:33, 386.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[batch 4/50] 20 prompts → saved_data/lens_data/m_4bit/m_4bit_modes_batch003.pt\n",
      "[info] Detected BitsAndBytes quantized model → already on device cpu\n",
      "[info] Tokenized 20 prompts | seq_len=17 | pad_id=128009 | eos_id=128009\n",
      "[info] Collecting from 32 layers | attn compute=False, save=False\n",
      "[saved] Logit-lens data → saved_data/lens_data/m_4bit/m_4bit_modes_batch003.pt\n",
      "[ok] Collected 680 entries from 32 layers (no redundant tensors)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running logit lens batches:   8%|▊         | 4/50 [25:24<4:52:53, 382.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[batch 5/50] 20 prompts → saved_data/lens_data/m_4bit/m_4bit_modes_batch004.pt\n",
      "[info] Detected BitsAndBytes quantized model → already on device cpu\n",
      "[info] Tokenized 20 prompts | seq_len=17 | pad_id=128009 | eos_id=128009\n",
      "[info] Collecting from 32 layers | attn compute=False, save=False\n",
      "[saved] Logit-lens data → saved_data/lens_data/m_4bit/m_4bit_modes_batch004.pt\n",
      "[ok] Collected 680 entries from 32 layers (no redundant tensors)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running logit lens batches:  10%|█         | 5/50 [32:18<4:55:05, 393.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[batch 6/50] 20 prompts → saved_data/lens_data/m_4bit/m_4bit_modes_batch005.pt\n",
      "[info] Detected BitsAndBytes quantized model → already on device cpu\n",
      "[info] Tokenized 20 prompts | seq_len=17 | pad_id=128009 | eos_id=128009\n",
      "[info] Collecting from 32 layers | attn compute=False, save=False\n",
      "[saved] Logit-lens data → saved_data/lens_data/m_4bit/m_4bit_modes_batch005.pt\n",
      "[ok] Collected 680 entries from 32 layers (no redundant tensors)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running logit lens batches:  12%|█▏        | 6/50 [38:52<4:48:37, 393.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[batch 7/50] 20 prompts → saved_data/lens_data/m_4bit/m_4bit_modes_batch006.pt\n",
      "[info] Detected BitsAndBytes quantized model → already on device cpu\n",
      "[info] Tokenized 20 prompts | seq_len=17 | pad_id=128009 | eos_id=128009\n",
      "[info] Collecting from 32 layers | attn compute=False, save=False\n",
      "[saved] Logit-lens data → saved_data/lens_data/m_4bit/m_4bit_modes_batch006.pt\n",
      "[ok] Collected 680 entries from 32 layers (no redundant tensors)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running logit lens batches:  14%|█▍        | 7/50 [45:22<4:41:11, 392.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[batch 8/50] 20 prompts → saved_data/lens_data/m_4bit/m_4bit_modes_batch007.pt\n",
      "[info] Detected BitsAndBytes quantized model → already on device cpu\n",
      "[info] Tokenized 20 prompts | seq_len=17 | pad_id=128009 | eos_id=128009\n",
      "[info] Collecting from 32 layers | attn compute=False, save=False\n",
      "[saved] Logit-lens data → saved_data/lens_data/m_4bit/m_4bit_modes_batch007.pt\n",
      "[ok] Collected 680 entries from 32 layers (no redundant tensors)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running logit lens batches:  16%|█▌        | 8/50 [51:51<4:33:58, 391.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[batch 9/50] 20 prompts → saved_data/lens_data/m_4bit/m_4bit_modes_batch008.pt\n",
      "[info] Detected BitsAndBytes quantized model → already on device cpu\n",
      "[info] Tokenized 20 prompts | seq_len=17 | pad_id=128009 | eos_id=128009\n",
      "[info] Collecting from 32 layers | attn compute=False, save=False\n",
      "[saved] Logit-lens data → saved_data/lens_data/m_4bit/m_4bit_modes_batch008.pt\n",
      "[ok] Collected 680 entries from 32 layers (no redundant tensors)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running logit lens batches:  18%|█▊        | 9/50 [58:39<4:30:57, 396.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[batch 10/50] 20 prompts → saved_data/lens_data/m_4bit/m_4bit_modes_batch009.pt\n",
      "[info] Detected BitsAndBytes quantized model → already on device cpu\n",
      "[info] Tokenized 20 prompts | seq_len=17 | pad_id=128009 | eos_id=128009\n",
      "[info] Collecting from 32 layers | attn compute=False, save=False\n",
      "[saved] Logit-lens data → saved_data/lens_data/m_4bit/m_4bit_modes_batch009.pt\n",
      "[ok] Collected 680 entries from 32 layers (no redundant tensors)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running logit lens batches:  20%|██        | 10/50 [1:04:57<4:20:29, 390.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[batch 11/50] 20 prompts → saved_data/lens_data/m_4bit/m_4bit_modes_batch010.pt\n",
      "[info] Detected BitsAndBytes quantized model → already on device cpu\n",
      "[info] Tokenized 20 prompts | seq_len=17 | pad_id=128009 | eos_id=128009\n",
      "[info] Collecting from 32 layers | attn compute=False, save=False\n",
      "[saved] Logit-lens data → saved_data/lens_data/m_4bit/m_4bit_modes_batch010.pt\n",
      "[ok] Collected 680 entries from 32 layers (no redundant tensors)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running logit lens batches:  22%|██▏       | 11/50 [1:11:07<4:09:49, 384.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[batch 12/50] 20 prompts → saved_data/lens_data/m_4bit/m_4bit_modes_batch011.pt\n",
      "[info] Detected BitsAndBytes quantized model → already on device cpu\n",
      "[info] Tokenized 20 prompts | seq_len=17 | pad_id=128009 | eos_id=128009\n",
      "[info] Collecting from 32 layers | attn compute=False, save=False\n",
      "[saved] Logit-lens data → saved_data/lens_data/m_4bit/m_4bit_modes_batch011.pt\n",
      "[ok] Collected 680 entries from 32 layers (no redundant tensors)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running logit lens batches:  24%|██▍       | 12/50 [1:17:09<3:59:11, 377.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[batch 13/50] 20 prompts → saved_data/lens_data/m_4bit/m_4bit_modes_batch012.pt\n",
      "[info] Detected BitsAndBytes quantized model → already on device cpu\n",
      "[info] Tokenized 20 prompts | seq_len=17 | pad_id=128009 | eos_id=128009\n",
      "[info] Collecting from 32 layers | attn compute=False, save=False\n",
      "[saved] Logit-lens data → saved_data/lens_data/m_4bit/m_4bit_modes_batch012.pt\n",
      "[ok] Collected 680 entries from 32 layers (no redundant tensors)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running logit lens batches:  26%|██▌       | 13/50 [1:24:29<4:04:28, 396.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[batch 14/50] 20 prompts → saved_data/lens_data/m_4bit/m_4bit_modes_batch013.pt\n",
      "[info] Detected BitsAndBytes quantized model → already on device cpu\n",
      "[info] Tokenized 20 prompts | seq_len=17 | pad_id=128009 | eos_id=128009\n",
      "[info] Collecting from 32 layers | attn compute=False, save=False\n",
      "[saved] Logit-lens data → saved_data/lens_data/m_4bit/m_4bit_modes_batch013.pt\n",
      "[ok] Collected 680 entries from 32 layers (no redundant tensors)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running logit lens batches:  28%|██▊       | 14/50 [1:33:15<4:21:20, 435.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[batch 15/50] 20 prompts → saved_data/lens_data/m_4bit/m_4bit_modes_batch014.pt\n",
      "[info] Detected BitsAndBytes quantized model → already on device cpu\n",
      "[info] Tokenized 20 prompts | seq_len=17 | pad_id=128009 | eos_id=128009\n",
      "[info] Collecting from 32 layers | attn compute=False, save=False\n",
      "[saved] Logit-lens data → saved_data/lens_data/m_4bit/m_4bit_modes_batch014.pt\n",
      "[ok] Collected 680 entries from 32 layers (no redundant tensors)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running logit lens batches:  30%|███       | 15/50 [1:40:14<4:11:18, 430.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[batch 16/50] 20 prompts → saved_data/lens_data/m_4bit/m_4bit_modes_batch015.pt\n",
      "[info] Detected BitsAndBytes quantized model → already on device cpu\n",
      "[info] Tokenized 20 prompts | seq_len=17 | pad_id=128009 | eos_id=128009\n",
      "[info] Collecting from 32 layers | attn compute=False, save=False\n",
      "[saved] Logit-lens data → saved_data/lens_data/m_4bit/m_4bit_modes_batch015.pt\n",
      "[ok] Collected 680 entries from 32 layers (no redundant tensors)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running logit lens batches:  32%|███▏      | 16/50 [1:48:00<4:10:05, 441.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[batch 17/50] 20 prompts → saved_data/lens_data/m_4bit/m_4bit_modes_batch016.pt\n",
      "[info] Detected BitsAndBytes quantized model → already on device cpu\n",
      "[info] Tokenized 20 prompts | seq_len=17 | pad_id=128009 | eos_id=128009\n",
      "[info] Collecting from 32 layers | attn compute=False, save=False\n",
      "[saved] Logit-lens data → saved_data/lens_data/m_4bit/m_4bit_modes_batch016.pt\n",
      "[ok] Collected 680 entries from 32 layers (no redundant tensors)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running logit lens batches:  34%|███▍      | 17/50 [1:54:31<3:54:21, 426.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[batch 18/50] 20 prompts → saved_data/lens_data/m_4bit/m_4bit_modes_batch017.pt\n",
      "[info] Detected BitsAndBytes quantized model → already on device cpu\n",
      "[info] Tokenized 20 prompts | seq_len=17 | pad_id=128009 | eos_id=128009\n",
      "[info] Collecting from 32 layers | attn compute=False, save=False\n",
      "[saved] Logit-lens data → saved_data/lens_data/m_4bit/m_4bit_modes_batch017.pt\n",
      "[ok] Collected 680 entries from 32 layers (no redundant tensors)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running logit lens batches:  36%|███▌      | 18/50 [2:03:14<4:02:49, 455.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[batch 19/50] 20 prompts → saved_data/lens_data/m_4bit/m_4bit_modes_batch018.pt\n",
      "[info] Detected BitsAndBytes quantized model → already on device cpu\n",
      "[info] Tokenized 20 prompts | seq_len=17 | pad_id=128009 | eos_id=128009\n",
      "[info] Collecting from 32 layers | attn compute=False, save=False\n",
      "[saved] Logit-lens data → saved_data/lens_data/m_4bit/m_4bit_modes_batch018.pt\n",
      "[ok] Collected 680 entries from 32 layers (no redundant tensors)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running logit lens batches:  38%|███▊      | 19/50 [2:11:54<4:05:14, 474.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[batch 20/50] 20 prompts → saved_data/lens_data/m_4bit/m_4bit_modes_batch019.pt\n",
      "[info] Detected BitsAndBytes quantized model → already on device cpu\n",
      "[info] Tokenized 20 prompts | seq_len=17 | pad_id=128009 | eos_id=128009\n",
      "[info] Collecting from 32 layers | attn compute=False, save=False\n",
      "[saved] Logit-lens data → saved_data/lens_data/m_4bit/m_4bit_modes_batch019.pt\n",
      "[ok] Collected 680 entries from 32 layers (no redundant tensors)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running logit lens batches:  40%|████      | 20/50 [2:18:31<3:45:44, 451.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[batch 21/50] 20 prompts → saved_data/lens_data/m_4bit/m_4bit_modes_batch020.pt\n",
      "[info] Detected BitsAndBytes quantized model → already on device cpu\n",
      "[info] Tokenized 20 prompts | seq_len=17 | pad_id=128009 | eos_id=128009\n",
      "[info] Collecting from 32 layers | attn compute=False, save=False\n",
      "[saved] Logit-lens data → saved_data/lens_data/m_4bit/m_4bit_modes_batch020.pt\n",
      "[ok] Collected 680 entries from 32 layers (no redundant tensors)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running logit lens batches:  42%|████▏     | 21/50 [2:24:32<3:25:04, 424.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[batch 22/50] 20 prompts → saved_data/lens_data/m_4bit/m_4bit_modes_batch021.pt\n",
      "[info] Detected BitsAndBytes quantized model → already on device cpu\n",
      "[info] Tokenized 20 prompts | seq_len=17 | pad_id=128009 | eos_id=128009\n",
      "[info] Collecting from 32 layers | attn compute=False, save=False\n",
      "[saved] Logit-lens data → saved_data/lens_data/m_4bit/m_4bit_modes_batch021.pt\n",
      "[ok] Collected 680 entries from 32 layers (no redundant tensors)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running logit lens batches:  44%|████▍     | 22/50 [2:30:46<3:10:55, 409.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[batch 23/50] 20 prompts → saved_data/lens_data/m_4bit/m_4bit_modes_batch022.pt\n",
      "[info] Detected BitsAndBytes quantized model → already on device cpu\n",
      "[info] Tokenized 20 prompts | seq_len=17 | pad_id=128009 | eos_id=128009\n",
      "[info] Collecting from 32 layers | attn compute=False, save=False\n",
      "[saved] Logit-lens data → saved_data/lens_data/m_4bit/m_4bit_modes_batch022.pt\n",
      "[ok] Collected 680 entries from 32 layers (no redundant tensors)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running logit lens batches:  46%|████▌     | 23/50 [2:36:39<2:56:30, 392.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[batch 24/50] 20 prompts → saved_data/lens_data/m_4bit/m_4bit_modes_batch023.pt\n",
      "[info] Detected BitsAndBytes quantized model → already on device cpu\n",
      "[info] Tokenized 20 prompts | seq_len=17 | pad_id=128009 | eos_id=128009\n",
      "[info] Collecting from 32 layers | attn compute=False, save=False\n",
      "[saved] Logit-lens data → saved_data/lens_data/m_4bit/m_4bit_modes_batch023.pt\n",
      "[ok] Collected 680 entries from 32 layers (no redundant tensors)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running logit lens batches:  48%|████▊     | 24/50 [2:43:42<2:54:01, 401.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[batch 25/50] 20 prompts → saved_data/lens_data/m_4bit/m_4bit_modes_batch024.pt\n",
      "[info] Detected BitsAndBytes quantized model → already on device cpu\n",
      "[info] Tokenized 20 prompts | seq_len=17 | pad_id=128009 | eos_id=128009\n",
      "[info] Collecting from 32 layers | attn compute=False, save=False\n",
      "[saved] Logit-lens data → saved_data/lens_data/m_4bit/m_4bit_modes_batch024.pt\n",
      "[ok] Collected 680 entries from 32 layers (no redundant tensors)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running logit lens batches:  50%|█████     | 25/50 [2:51:05<2:52:28, 413.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[batch 26/50] 20 prompts → saved_data/lens_data/m_4bit/m_4bit_modes_batch025.pt\n",
      "[info] Detected BitsAndBytes quantized model → already on device cpu\n",
      "[info] Tokenized 20 prompts | seq_len=17 | pad_id=128009 | eos_id=128009\n",
      "[info] Collecting from 32 layers | attn compute=False, save=False\n",
      "[saved] Logit-lens data → saved_data/lens_data/m_4bit/m_4bit_modes_batch025.pt\n",
      "[ok] Collected 680 entries from 32 layers (no redundant tensors)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running logit lens batches:  52%|█████▏    | 26/50 [2:57:50<2:44:31, 411.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[batch 27/50] 20 prompts → saved_data/lens_data/m_4bit/m_4bit_modes_batch026.pt\n",
      "[info] Detected BitsAndBytes quantized model → already on device cpu\n",
      "[info] Tokenized 20 prompts | seq_len=17 | pad_id=128009 | eos_id=128009\n",
      "[info] Collecting from 32 layers | attn compute=False, save=False\n",
      "[saved] Logit-lens data → saved_data/lens_data/m_4bit/m_4bit_modes_batch026.pt\n",
      "[ok] Collected 680 entries from 32 layers (no redundant tensors)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running logit lens batches:  54%|█████▍    | 27/50 [3:04:13<2:34:23, 402.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[batch 28/50] 20 prompts → saved_data/lens_data/m_4bit/m_4bit_modes_batch027.pt\n",
      "[info] Detected BitsAndBytes quantized model → already on device cpu\n",
      "[info] Tokenized 20 prompts | seq_len=17 | pad_id=128009 | eos_id=128009\n",
      "[info] Collecting from 32 layers | attn compute=False, save=False\n",
      "[saved] Logit-lens data → saved_data/lens_data/m_4bit/m_4bit_modes_batch027.pt\n",
      "[ok] Collected 680 entries from 32 layers (no redundant tensors)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running logit lens batches:  56%|█████▌    | 28/50 [3:11:26<2:31:02, 411.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[batch 29/50] 20 prompts → saved_data/lens_data/m_4bit/m_4bit_modes_batch028.pt\n",
      "[info] Detected BitsAndBytes quantized model → already on device cpu\n",
      "[info] Tokenized 20 prompts | seq_len=17 | pad_id=128009 | eos_id=128009\n",
      "[info] Collecting from 32 layers | attn compute=False, save=False\n",
      "[saved] Logit-lens data → saved_data/lens_data/m_4bit/m_4bit_modes_batch028.pt\n",
      "[ok] Collected 680 entries from 32 layers (no redundant tensors)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running logit lens batches:  58%|█████▊    | 29/50 [3:18:17<2:24:02, 411.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[batch 30/50] 20 prompts → saved_data/lens_data/m_4bit/m_4bit_modes_batch029.pt\n",
      "[info] Detected BitsAndBytes quantized model → already on device cpu\n",
      "[info] Tokenized 20 prompts | seq_len=17 | pad_id=128009 | eos_id=128009\n",
      "[info] Collecting from 32 layers | attn compute=False, save=False\n",
      "[saved] Logit-lens data → saved_data/lens_data/m_4bit/m_4bit_modes_batch029.pt\n",
      "[ok] Collected 680 entries from 32 layers (no redundant tensors)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running logit lens batches:  60%|██████    | 30/50 [3:24:53<2:15:37, 406.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[batch 31/50] 20 prompts → saved_data/lens_data/m_4bit/m_4bit_modes_batch030.pt\n",
      "[info] Detected BitsAndBytes quantized model → already on device cpu\n",
      "[info] Tokenized 20 prompts | seq_len=17 | pad_id=128009 | eos_id=128009\n",
      "[info] Collecting from 32 layers | attn compute=False, save=False\n",
      "[saved] Logit-lens data → saved_data/lens_data/m_4bit/m_4bit_modes_batch030.pt\n",
      "[ok] Collected 680 entries from 32 layers (no redundant tensors)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running logit lens batches:  62%|██████▏   | 31/50 [3:31:02<2:05:14, 395.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[batch 32/50] 20 prompts → saved_data/lens_data/m_4bit/m_4bit_modes_batch031.pt\n",
      "[info] Detected BitsAndBytes quantized model → already on device cpu\n",
      "[info] Tokenized 20 prompts | seq_len=17 | pad_id=128009 | eos_id=128009\n",
      "[info] Collecting from 32 layers | attn compute=False, save=False\n",
      "[saved] Logit-lens data → saved_data/lens_data/m_4bit/m_4bit_modes_batch031.pt\n",
      "[ok] Collected 680 entries from 32 layers (no redundant tensors)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running logit lens batches:  64%|██████▍   | 32/50 [3:37:13<1:56:30, 388.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[batch 33/50] 20 prompts → saved_data/lens_data/m_4bit/m_4bit_modes_batch032.pt\n",
      "[info] Detected BitsAndBytes quantized model → already on device cpu\n",
      "[info] Tokenized 20 prompts | seq_len=17 | pad_id=128009 | eos_id=128009\n",
      "[info] Collecting from 32 layers | attn compute=False, save=False\n"
     ]
    }
   ],
   "source": [
    "run_logit_lens_in_batches(\n",
    "    model=model_4bit,\n",
    "    tokenizer=orig_tokenizer,\n",
    "    all_prompts=nq_1000,\n",
    "    batch_size=20,\n",
    "    max_len=17,\n",
    "    normalize_mode=(\"raw\", \"unit_rms\", \"norm_rms\"),\n",
    "    save_prefix=\"saved_data/lens_data/m_4bit/m_4bit_modes\",\n",
    "    device=\"cpu\",\n",
    "    clamp_logits=True,\n",
    "    collect_attn=False,\n",
    "    save_attn=False  \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7730a4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logit_lens_in_batches(\n",
    "    model=model_quant,\n",
    "    tokenizer=quant_tokenizer,\n",
    "    all_prompts=nq_queries_200,\n",
    "    batch_size=20,\n",
    "    max_len=18,\n",
    "    normalize_mode=\"raw\",\n",
    "    save_prefix=\"logs/new_model_lens/raw/m_quant_raw\",\n",
    "    device=\"cpu\",\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5083361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd \n",
    "\n",
    "data = torch.load(\"saved_data/lens_data/m_orig_norm_modes_batch000.pt\", weights_only=False, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb5cba2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "baaafb88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>batch_index</th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>layer_index</th>\n",
       "      <th>layer_name</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>target_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>hidden_raw</th>\n",
       "      <th>hidden_unit_rms</th>\n",
       "      <th>hidden_norm_rms</th>\n",
       "      <th>logits_raw</th>\n",
       "      <th>logits_unit_rms</th>\n",
       "      <th>logits_norm_rms</th>\n",
       "      <th>hidden</th>\n",
       "      <th>logits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>when did richmond last play in a preliminary f...</td>\n",
       "      <td>0</td>\n",
       "      <td>128256</td>\n",
       "      <td>-1</td>\n",
       "      <td>embed_tokens</td>\n",
       "      <td>[tensor(128000), tensor(9493), tensor(1550), t...</td>\n",
       "      <td>[tensor(9493), tensor(1550), tensor(9257), ten...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "      <td>[[tensor(-8.2970e-05), tensor(0.0003), tensor(...</td>\n",
       "      <td>[[tensor(-8.2970e-05), tensor(0.0003), tensor(...</td>\n",
       "      <td>[[tensor(-8.2970e-05), tensor(0.0003), tensor(...</td>\n",
       "      <td>[[tensor(-0.0105), tensor(-0.0092), tensor(-0....</td>\n",
       "      <td>[[tensor(-0.0105), tensor(-0.0092), tensor(-0....</td>\n",
       "      <td>[[tensor(-0.0105), tensor(-0.0092), tensor(-0....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>when did richmond last play in a preliminary f...</td>\n",
       "      <td>0</td>\n",
       "      <td>128256</td>\n",
       "      <td>0</td>\n",
       "      <td>layer.0</td>\n",
       "      <td>[tensor(128000), tensor(9493), tensor(1550), t...</td>\n",
       "      <td>[tensor(9493), tensor(1550), tensor(9257), ten...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "      <td>[[tensor(0.0013), tensor(0.0040), tensor(-0.00...</td>\n",
       "      <td>[[tensor(0.0102), tensor(0.0307), tensor(-0.03...</td>\n",
       "      <td>[[tensor(0.0271), tensor(0.0790), tensor(-0.10...</td>\n",
       "      <td>[[tensor(-0.0531), tensor(-0.1477), tensor(-0....</td>\n",
       "      <td>[[tensor(-0.4077), tensor(-1.1344), tensor(-0....</td>\n",
       "      <td>[[tensor(-0.7749), tensor(-2.9273), tensor(-1....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>when did richmond last play in a preliminary f...</td>\n",
       "      <td>0</td>\n",
       "      <td>128256</td>\n",
       "      <td>1</td>\n",
       "      <td>layer.1</td>\n",
       "      <td>[tensor(128000), tensor(9493), tensor(1550), t...</td>\n",
       "      <td>[tensor(9493), tensor(1550), tensor(9257), ten...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "      <td>[[tensor(-0.0454), tensor(0.0954), tensor(-0.0...</td>\n",
       "      <td>[[tensor(-0.0075), tensor(0.0157), tensor(-0.0...</td>\n",
       "      <td>[[tensor(-0.0199), tensor(0.0405), tensor(-0.0...</td>\n",
       "      <td>[[tensor(-7.2014), tensor(-13.3586), tensor(-8...</td>\n",
       "      <td>[[tensor(-1.1870), tensor(-2.2018), tensor(-1....</td>\n",
       "      <td>[[tensor(-1.3217), tensor(-2.3338), tensor(-1....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>when did richmond last play in a preliminary f...</td>\n",
       "      <td>0</td>\n",
       "      <td>128256</td>\n",
       "      <td>2</td>\n",
       "      <td>layer.2</td>\n",
       "      <td>[tensor(128000), tensor(9493), tensor(1550), t...</td>\n",
       "      <td>[tensor(9493), tensor(1550), tensor(9257), ten...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "      <td>[[tensor(-0.0479), tensor(0.0981), tensor(-0.0...</td>\n",
       "      <td>[[tensor(-0.0079), tensor(0.0162), tensor(-0.0...</td>\n",
       "      <td>[[tensor(-0.0210), tensor(0.0417), tensor(-0.0...</td>\n",
       "      <td>[[tensor(-7.2171), tensor(-13.3865), tensor(-8...</td>\n",
       "      <td>[[tensor(-1.1894), tensor(-2.2061), tensor(-1....</td>\n",
       "      <td>[[tensor(-1.3264), tensor(-2.3425), tensor(-1....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>when did richmond last play in a preliminary f...</td>\n",
       "      <td>0</td>\n",
       "      <td>128256</td>\n",
       "      <td>3</td>\n",
       "      <td>layer.3</td>\n",
       "      <td>[tensor(128000), tensor(9493), tensor(1550), t...</td>\n",
       "      <td>[tensor(9493), tensor(1550), tensor(9257), ten...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "      <td>[[tensor(-0.0325), tensor(0.1043), tensor(-0.0...</td>\n",
       "      <td>[[tensor(-0.0054), tensor(0.0172), tensor(-0.0...</td>\n",
       "      <td>[[tensor(-0.0142), tensor(0.0443), tensor(-0.0...</td>\n",
       "      <td>[[tensor(-7.2138), tensor(-13.4237), tensor(-8...</td>\n",
       "      <td>[[tensor(-1.1886), tensor(-2.2117), tensor(-1....</td>\n",
       "      <td>[[tensor(-1.3254), tensor(-2.3557), tensor(-1....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prompt_id                                        prompt_text  batch_index  \\\n",
       "0          0  when did richmond last play in a preliminary f...            0   \n",
       "1          0  when did richmond last play in a preliminary f...            0   \n",
       "2          0  when did richmond last play in a preliminary f...            0   \n",
       "3          0  when did richmond last play in a preliminary f...            0   \n",
       "4          0  when did richmond last play in a preliminary f...            0   \n",
       "\n",
       "   vocab_size  layer_index    layer_name  \\\n",
       "0      128256           -1  embed_tokens   \n",
       "1      128256            0       layer.0   \n",
       "2      128256            1       layer.1   \n",
       "3      128256            2       layer.2   \n",
       "4      128256            3       layer.3   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [tensor(128000), tensor(9493), tensor(1550), t...   \n",
       "1  [tensor(128000), tensor(9493), tensor(1550), t...   \n",
       "2  [tensor(128000), tensor(9493), tensor(1550), t...   \n",
       "3  [tensor(128000), tensor(9493), tensor(1550), t...   \n",
       "4  [tensor(128000), tensor(9493), tensor(1550), t...   \n",
       "\n",
       "                                          target_ids  \\\n",
       "0  [tensor(9493), tensor(1550), tensor(9257), ten...   \n",
       "1  [tensor(9493), tensor(1550), tensor(9257), ten...   \n",
       "2  [tensor(9493), tensor(1550), tensor(9257), ten...   \n",
       "3  [tensor(9493), tensor(1550), tensor(9257), ten...   \n",
       "4  [tensor(9493), tensor(1550), tensor(9257), ten...   \n",
       "\n",
       "                                      attention_mask  \\\n",
       "0  [tensor(1), tensor(1), tensor(1), tensor(1), t...   \n",
       "1  [tensor(1), tensor(1), tensor(1), tensor(1), t...   \n",
       "2  [tensor(1), tensor(1), tensor(1), tensor(1), t...   \n",
       "3  [tensor(1), tensor(1), tensor(1), tensor(1), t...   \n",
       "4  [tensor(1), tensor(1), tensor(1), tensor(1), t...   \n",
       "\n",
       "                                          hidden_raw  \\\n",
       "0  [[tensor(-8.2970e-05), tensor(0.0003), tensor(...   \n",
       "1  [[tensor(0.0013), tensor(0.0040), tensor(-0.00...   \n",
       "2  [[tensor(-0.0454), tensor(0.0954), tensor(-0.0...   \n",
       "3  [[tensor(-0.0479), tensor(0.0981), tensor(-0.0...   \n",
       "4  [[tensor(-0.0325), tensor(0.1043), tensor(-0.0...   \n",
       "\n",
       "                                     hidden_unit_rms  \\\n",
       "0  [[tensor(-8.2970e-05), tensor(0.0003), tensor(...   \n",
       "1  [[tensor(0.0102), tensor(0.0307), tensor(-0.03...   \n",
       "2  [[tensor(-0.0075), tensor(0.0157), tensor(-0.0...   \n",
       "3  [[tensor(-0.0079), tensor(0.0162), tensor(-0.0...   \n",
       "4  [[tensor(-0.0054), tensor(0.0172), tensor(-0.0...   \n",
       "\n",
       "                                     hidden_norm_rms  \\\n",
       "0  [[tensor(-8.2970e-05), tensor(0.0003), tensor(...   \n",
       "1  [[tensor(0.0271), tensor(0.0790), tensor(-0.10...   \n",
       "2  [[tensor(-0.0199), tensor(0.0405), tensor(-0.0...   \n",
       "3  [[tensor(-0.0210), tensor(0.0417), tensor(-0.0...   \n",
       "4  [[tensor(-0.0142), tensor(0.0443), tensor(-0.0...   \n",
       "\n",
       "                                          logits_raw  \\\n",
       "0  [[tensor(-0.0105), tensor(-0.0092), tensor(-0....   \n",
       "1  [[tensor(-0.0531), tensor(-0.1477), tensor(-0....   \n",
       "2  [[tensor(-7.2014), tensor(-13.3586), tensor(-8...   \n",
       "3  [[tensor(-7.2171), tensor(-13.3865), tensor(-8...   \n",
       "4  [[tensor(-7.2138), tensor(-13.4237), tensor(-8...   \n",
       "\n",
       "                                     logits_unit_rms  \\\n",
       "0  [[tensor(-0.0105), tensor(-0.0092), tensor(-0....   \n",
       "1  [[tensor(-0.4077), tensor(-1.1344), tensor(-0....   \n",
       "2  [[tensor(-1.1870), tensor(-2.2018), tensor(-1....   \n",
       "3  [[tensor(-1.1894), tensor(-2.2061), tensor(-1....   \n",
       "4  [[tensor(-1.1886), tensor(-2.2117), tensor(-1....   \n",
       "\n",
       "                                     logits_norm_rms hidden logits  \n",
       "0  [[tensor(-0.0105), tensor(-0.0092), tensor(-0....    NaN    NaN  \n",
       "1  [[tensor(-0.7749), tensor(-2.9273), tensor(-1....    NaN    NaN  \n",
       "2  [[tensor(-1.3217), tensor(-2.3338), tensor(-1....    NaN    NaN  \n",
       "3  [[tensor(-1.3264), tensor(-2.3425), tensor(-1....    NaN    NaN  \n",
       "4  [[tensor(-1.3254), tensor(-2.3557), tensor(-1....    NaN    NaN  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c29c0ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>batch_index</th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>layer_index</th>\n",
       "      <th>layer_name</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>target_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>hidden_raw</th>\n",
       "      <th>hidden_unit_rms</th>\n",
       "      <th>hidden_norm_rms</th>\n",
       "      <th>logits_raw</th>\n",
       "      <th>logits_unit_rms</th>\n",
       "      <th>logits_norm_rms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>when did richmond last play in a preliminary f...</td>\n",
       "      <td>0</td>\n",
       "      <td>128256</td>\n",
       "      <td>28</td>\n",
       "      <td>layer.28</td>\n",
       "      <td>[tensor(128000), tensor(9493), tensor(1550), t...</td>\n",
       "      <td>[tensor(9493), tensor(1550), tensor(9257), ten...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "      <td>[[tensor(0.0686), tensor(0.1682), tensor(0.047...</td>\n",
       "      <td>[[tensor(0.0114), tensor(0.0280), tensor(0.007...</td>\n",
       "      <td>[[tensor(0.0303), tensor(0.0721), tensor(0.020...</td>\n",
       "      <td>[[tensor(-6.2383), tensor(-12.7422), tensor(-8...</td>\n",
       "      <td>[[tensor(-1.0371), tensor(-2.1172), tensor(-1....</td>\n",
       "      <td>[[tensor(-1.1064), tensor(-2.1855), tensor(-1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>when did richmond last play in a preliminary f...</td>\n",
       "      <td>0</td>\n",
       "      <td>128256</td>\n",
       "      <td>29</td>\n",
       "      <td>layer.29</td>\n",
       "      <td>[tensor(128000), tensor(9493), tensor(1550), t...</td>\n",
       "      <td>[tensor(9493), tensor(1550), tensor(9257), ten...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "      <td>[[tensor(0.1700), tensor(0.1889), tensor(0.050...</td>\n",
       "      <td>[[tensor(0.0283), tensor(0.0314), tensor(0.008...</td>\n",
       "      <td>[[tensor(0.0751), tensor(0.0811), tensor(0.021...</td>\n",
       "      <td>[[tensor(-5.3750), tensor(-12.2188), tensor(-7...</td>\n",
       "      <td>[[tensor(-0.8945), tensor(-2.0332), tensor(-1....</td>\n",
       "      <td>[[tensor(-0.8179), tensor(-2.0156), tensor(-1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>when did richmond last play in a preliminary f...</td>\n",
       "      <td>0</td>\n",
       "      <td>128256</td>\n",
       "      <td>30</td>\n",
       "      <td>layer.30</td>\n",
       "      <td>[tensor(128000), tensor(9493), tensor(1550), t...</td>\n",
       "      <td>[tensor(9493), tensor(1550), tensor(9257), ten...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "      <td>[[tensor(0.1513), tensor(0.2639), tensor(0.072...</td>\n",
       "      <td>[[tensor(0.0254), tensor(0.0443), tensor(0.012...</td>\n",
       "      <td>[[tensor(0.0675), tensor(0.1142), tensor(0.031...</td>\n",
       "      <td>[[tensor(-2.8730), tensor(-10.8047), tensor(-6...</td>\n",
       "      <td>[[tensor(-0.4824), tensor(-1.8154), tensor(-1....</td>\n",
       "      <td>[[tensor(0.0625), tensor(-1.5752), tensor(-1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>when did richmond last play in a preliminary f...</td>\n",
       "      <td>0</td>\n",
       "      <td>128256</td>\n",
       "      <td>31</td>\n",
       "      <td>layer.31</td>\n",
       "      <td>[tensor(128000), tensor(9493), tensor(1550), t...</td>\n",
       "      <td>[tensor(9493), tensor(1550), tensor(9257), ten...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "      <td>[[tensor(1.0524), tensor(-0.0069), tensor(-0.2...</td>\n",
       "      <td>[[tensor(1.6513), tensor(-0.0108), tensor(-0.3...</td>\n",
       "      <td>[[tensor(4.3862), tensor(-0.0278), tensor(-1.0...</td>\n",
       "      <td>[[tensor(1.6826), tensor(2.3926), tensor(3.320...</td>\n",
       "      <td>[[tensor(2.6406), tensor(3.7539), tensor(5.210...</td>\n",
       "      <td>[[tensor(4.7617), tensor(6.1094), tensor(10.72...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>when did richmond last play in a preliminary f...</td>\n",
       "      <td>0</td>\n",
       "      <td>128256</td>\n",
       "      <td>32</td>\n",
       "      <td>output</td>\n",
       "      <td>[tensor(128000), tensor(9493), tensor(1550), t...</td>\n",
       "      <td>[tensor(9493), tensor(1550), tensor(9257), ten...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "      <td>[[tensor(4.3862), tensor(-0.0278), tensor(-1.0...</td>\n",
       "      <td>[[tensor(4.3862), tensor(-0.0278), tensor(-1.0...</td>\n",
       "      <td>[[tensor(4.3862), tensor(-0.0278), tensor(-1.0...</td>\n",
       "      <td>[[tensor(4.7617), tensor(6.1094), tensor(10.72...</td>\n",
       "      <td>[[tensor(4.7617), tensor(6.1094), tensor(10.72...</td>\n",
       "      <td>[[tensor(4.7617), tensor(6.1094), tensor(10.72...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    prompt_id                                        prompt_text  batch_index  \\\n",
       "29          0  when did richmond last play in a preliminary f...            0   \n",
       "30          0  when did richmond last play in a preliminary f...            0   \n",
       "31          0  when did richmond last play in a preliminary f...            0   \n",
       "32          0  when did richmond last play in a preliminary f...            0   \n",
       "33          0  when did richmond last play in a preliminary f...            0   \n",
       "\n",
       "    vocab_size  layer_index layer_name  \\\n",
       "29      128256           28   layer.28   \n",
       "30      128256           29   layer.29   \n",
       "31      128256           30   layer.30   \n",
       "32      128256           31   layer.31   \n",
       "33      128256           32     output   \n",
       "\n",
       "                                            input_ids  \\\n",
       "29  [tensor(128000), tensor(9493), tensor(1550), t...   \n",
       "30  [tensor(128000), tensor(9493), tensor(1550), t...   \n",
       "31  [tensor(128000), tensor(9493), tensor(1550), t...   \n",
       "32  [tensor(128000), tensor(9493), tensor(1550), t...   \n",
       "33  [tensor(128000), tensor(9493), tensor(1550), t...   \n",
       "\n",
       "                                           target_ids  \\\n",
       "29  [tensor(9493), tensor(1550), tensor(9257), ten...   \n",
       "30  [tensor(9493), tensor(1550), tensor(9257), ten...   \n",
       "31  [tensor(9493), tensor(1550), tensor(9257), ten...   \n",
       "32  [tensor(9493), tensor(1550), tensor(9257), ten...   \n",
       "33  [tensor(9493), tensor(1550), tensor(9257), ten...   \n",
       "\n",
       "                                       attention_mask  \\\n",
       "29  [tensor(1), tensor(1), tensor(1), tensor(1), t...   \n",
       "30  [tensor(1), tensor(1), tensor(1), tensor(1), t...   \n",
       "31  [tensor(1), tensor(1), tensor(1), tensor(1), t...   \n",
       "32  [tensor(1), tensor(1), tensor(1), tensor(1), t...   \n",
       "33  [tensor(1), tensor(1), tensor(1), tensor(1), t...   \n",
       "\n",
       "                                           hidden_raw  \\\n",
       "29  [[tensor(0.0686), tensor(0.1682), tensor(0.047...   \n",
       "30  [[tensor(0.1700), tensor(0.1889), tensor(0.050...   \n",
       "31  [[tensor(0.1513), tensor(0.2639), tensor(0.072...   \n",
       "32  [[tensor(1.0524), tensor(-0.0069), tensor(-0.2...   \n",
       "33  [[tensor(4.3862), tensor(-0.0278), tensor(-1.0...   \n",
       "\n",
       "                                      hidden_unit_rms  \\\n",
       "29  [[tensor(0.0114), tensor(0.0280), tensor(0.007...   \n",
       "30  [[tensor(0.0283), tensor(0.0314), tensor(0.008...   \n",
       "31  [[tensor(0.0254), tensor(0.0443), tensor(0.012...   \n",
       "32  [[tensor(1.6513), tensor(-0.0108), tensor(-0.3...   \n",
       "33  [[tensor(4.3862), tensor(-0.0278), tensor(-1.0...   \n",
       "\n",
       "                                      hidden_norm_rms  \\\n",
       "29  [[tensor(0.0303), tensor(0.0721), tensor(0.020...   \n",
       "30  [[tensor(0.0751), tensor(0.0811), tensor(0.021...   \n",
       "31  [[tensor(0.0675), tensor(0.1142), tensor(0.031...   \n",
       "32  [[tensor(4.3862), tensor(-0.0278), tensor(-1.0...   \n",
       "33  [[tensor(4.3862), tensor(-0.0278), tensor(-1.0...   \n",
       "\n",
       "                                           logits_raw  \\\n",
       "29  [[tensor(-6.2383), tensor(-12.7422), tensor(-8...   \n",
       "30  [[tensor(-5.3750), tensor(-12.2188), tensor(-7...   \n",
       "31  [[tensor(-2.8730), tensor(-10.8047), tensor(-6...   \n",
       "32  [[tensor(1.6826), tensor(2.3926), tensor(3.320...   \n",
       "33  [[tensor(4.7617), tensor(6.1094), tensor(10.72...   \n",
       "\n",
       "                                      logits_unit_rms  \\\n",
       "29  [[tensor(-1.0371), tensor(-2.1172), tensor(-1....   \n",
       "30  [[tensor(-0.8945), tensor(-2.0332), tensor(-1....   \n",
       "31  [[tensor(-0.4824), tensor(-1.8154), tensor(-1....   \n",
       "32  [[tensor(2.6406), tensor(3.7539), tensor(5.210...   \n",
       "33  [[tensor(4.7617), tensor(6.1094), tensor(10.72...   \n",
       "\n",
       "                                      logits_norm_rms  \n",
       "29  [[tensor(-1.1064), tensor(-2.1855), tensor(-1....  \n",
       "30  [[tensor(-0.8179), tensor(-2.0156), tensor(-1....  \n",
       "31  [[tensor(0.0625), tensor(-1.5752), tensor(-1.0...  \n",
       "32  [[tensor(4.7617), tensor(6.1094), tensor(10.72...  \n",
       "33  [[tensor(4.7617), tensor(6.1094), tensor(10.72...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8fb55a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['prompt_id', 'prompt_text', 'batch_index', 'vocab_size', 'layer_index',\n",
       "       'layer_name', 'input_ids', 'target_ids', 'attention_mask', 'hidden_raw',\n",
       "       'hidden_unit_rms', 'hidden_norm_rms', 'logits_raw', 'logits_unit_rms',\n",
       "       'logits_norm_rms'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26700501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prompt_id          0\n",
       "prompt_text        0\n",
       "batch_index        0\n",
       "vocab_size         0\n",
       "layer_index        0\n",
       "layer_name         0\n",
       "input_ids          0\n",
       "target_ids         0\n",
       "attention_mask     0\n",
       "hidden_raw         0\n",
       "hidden_unit_rms    0\n",
       "hidden_norm_rms    0\n",
       "logits_raw         0\n",
       "logits_unit_rms    0\n",
       "logits_norm_rms    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0f33a9",
   "metadata": {},
   "source": [
    "# ==============================================\n",
    "# TopK Comparison ==============================\n",
    "# =============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10f9947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from scipy.special import kl_div\n",
    "from scipy.spatial.distance import jensenshannon, jaccard\n",
    "from scipy.stats import entropy\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def full_jaccard_over_positions(tkA, tkB, eps=1e-9, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Compute Jaccard similarity across *all positions* for each sequence.\n",
    "    Treats all top-k tokens across positions as one set per model.\n",
    "    Returns tensor of shape [batch_size].\n",
    "    Always finite (no NaNs/Infs).\n",
    "    \"\"\"\n",
    "    batch_scores = []\n",
    "    for i in range(tkA.size(0)):\n",
    "        setA = set(tkA[i].flatten().tolist())\n",
    "        setB = set(tkB[i].flatten().tolist())\n",
    "\n",
    "        if len(setA) == 0 and len(setB) == 0:\n",
    "            score = torch.tensor(1.0, device=device)\n",
    "        elif len(setA | setB) == 0:\n",
    "            score = torch.tensor(0.0, device=device)\n",
    "        else:\n",
    "            inter = len(setA & setB)\n",
    "            union = len(setA | setB)\n",
    "            val = inter / (union + eps)\n",
    "            score = torch.tensor(val, device=device)\n",
    "            if not torch.isfinite(score):\n",
    "                score = torch.tensor(0.0, device=device)\n",
    "            score = torch.clamp(score, 0.0, 1.0)\n",
    "        batch_scores.append(score)\n",
    "\n",
    "    out = torch.stack(batch_scores)\n",
    "    out = torch.nan_to_num(out, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    return out\n",
    "\n",
    "def safe_mean(x):\n",
    "    \"\"\"Robust mean: always returns a finite float (never NaN or None).\"\"\"\n",
    "    if x is None:\n",
    "        return 0.0\n",
    "    if torch.is_tensor(x):\n",
    "        if x.numel() == 0:\n",
    "            return 0.0\n",
    "        x = torch.nan_to_num(x.detach().float(), nan=0.0, posinf=0.0, neginf=0.0).flatten()\n",
    "        if x.numel() == 0:\n",
    "            return 0.0\n",
    "        return float(x.mean().item())\n",
    "    if isinstance(x, (list, tuple, np.ndarray)):\n",
    "        arr = np.asarray(x, dtype=np.float64).ravel()\n",
    "        if arr.size == 0:\n",
    "            return 0.0\n",
    "        arr = np.nan_to_num(arr, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        return float(np.mean(arr))\n",
    "    try:\n",
    "        val = float(x)\n",
    "        if not np.isfinite(val):\n",
    "            return 0.0\n",
    "        return val\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_divergence(\n",
    "    metrics_A,\n",
    "    metrics_B,\n",
    "    topk=(1, 5, 10, 20),\n",
    "    eps=1e-9,\n",
    "    mode=\"aligned\",\n",
    "    batch_num=0,\n",
    "    lens_type=\"raw\",\n",
    "    device=None,\n",
    "    tokenizer=None,\n",
    "    debug_checks=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare metrics between two model outputs with full numerical safety.\n",
    "    Masked probabilities are renormalized; NaNs/Infs are handled everywhere.\n",
    "    \"\"\"\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    topk = sorted(set([1] + list(topk)))\n",
    "    max_k = max(topk)\n",
    "    detailed = []\n",
    "\n",
    "    def safe(x, default=None, eps=1e-9):\n",
    "        \"\"\"\n",
    "        Numerically safe utility:\n",
    "        - replaces NaN with 0\n",
    "        - clamps extreme values to avoid destroying magnitude\n",
    "        - keeps log-like tensors in [-30, 30] range\n",
    "        \"\"\"\n",
    "        if x is None:\n",
    "            return torch.tensor(0.0)\n",
    "\n",
    "        x = torch.nan_to_num(x, nan=0.0, posinf=30.0, neginf=-30.0)\n",
    "\n",
    "        if torch.is_floating_point(x):\n",
    "            mean_val = x.mean().item() if x.numel() > 0 else 0.0\n",
    "            if mean_val < 1.0:  # looks like log-probs\n",
    "                x = torch.clamp(x, min=-30.0, max=30.0)\n",
    "            else:\n",
    "                x = torch.clamp(x, min=0.0, max=1e6)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    def pad_vocab_dim(logits, target_vocab):\n",
    "        pad = target_vocab - logits.size(-1)\n",
    "        if pad > 0:\n",
    "            logits = F.pad(logits, (0, pad))\n",
    "        return logits\n",
    "\n",
    "    # Pair rows depending on mode\n",
    "    if mode == \"aligned\":\n",
    "        #Layer-by-layer (#layers × #prompts) Deep interpretability, divergence over depth\n",
    "        pairs = list(zip(metrics_A, metrics_B))\n",
    "    elif mode == \"position_final\":\n",
    "        \"position_final\"\n",
    "        #Final-layer only (#prompts) Final behavior agreement (accuracy, top-k, disagreement)\n",
    "        def last_by_prompt(rows):\n",
    "            best = {}\n",
    "            for r in rows:\n",
    "                pid = r[\"prompt_id\"]\n",
    "                if pid not in best or r[\"layer_index\"] > best[pid][\"layer_index\"]:\n",
    "                    best[pid] = r\n",
    "            return best\n",
    "        last_A = last_by_prompt(metrics_A)\n",
    "        last_B = last_by_prompt(metrics_B)\n",
    "        common_pids = sorted(set(last_A) & set(last_B))\n",
    "        pairs = [(last_A[p], last_B[p]) for p in common_pids]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown mode: {mode}\")\n",
    "\n",
    "\n",
    "    # ============================================================\n",
    "    # === MAIN LOOP ==============================================\n",
    "    # ============================================================\n",
    "    for row_A, row_B in pairs:\n",
    "        assert row_A[\"prompt_id\"] == row_B[\"prompt_id\"]\n",
    "        if mode == \"aligned\":\n",
    "            assert row_A[\"layer_index\"] == row_B[\"layer_index\"]\n",
    "\n",
    "        logits_A = safe(row_A[\"logits\"].clone().float().to(device))\n",
    "        logits_B = safe(row_B[\"logits\"].clone().float().to(device))\n",
    "        if logits_A.ndim == 2: logits_A = logits_A.unsqueeze(0)\n",
    "        if logits_B.ndim == 2: logits_B = logits_B.unsqueeze(0)\n",
    "        vocab_target = max(logits_A.size(-1), logits_B.size(-1))\n",
    "        logits_A, logits_B = pad_vocab_dim(logits_A, vocab_target), pad_vocab_dim(logits_B, vocab_target)\n",
    "\n",
    "        # --- Stable log-softmax ---\n",
    "        logp_A_clean = safe(F.log_softmax(logits_A, dim=-1), -30.0)\n",
    "        logp_B_clean = safe(F.log_softmax(logits_B, dim=-1), -30.0)\n",
    "        probs_A_clean, probs_B_clean = logp_A_clean.exp(), logp_B_clean.exp()\n",
    "\n",
    "        # ============================================================\n",
    "        # === FULL-VOCAB DIVERGENCES (before masking) ================\n",
    "        # ============================================================\n",
    "        kl_ab_full = safe(torch.sum(probs_A_clean * (logp_A_clean - logp_B_clean), dim=-1))\n",
    "        kl_ba_full = safe(torch.sum(probs_B_clean * (logp_B_clean - logp_A_clean), dim=-1))\n",
    "        kl_ab_token_full, kl_ba_token_full = float(kl_ab_full.mean()), float(kl_ba_full.mean())\n",
    "\n",
    "        try:\n",
    "            jsd_dist_full = torch.tensor(\n",
    "                jensenshannon(\n",
    "                    probs_A_clean.detach().cpu().numpy(),\n",
    "                    probs_B_clean.detach().cpu().numpy(),\n",
    "                    axis=-1,\n",
    "                ),\n",
    "                device=device,\n",
    "            )\n",
    "        except Exception:\n",
    "            jsd_dist_full = torch.zeros_like(kl_ab_full)\n",
    "\n",
    "\n",
    "        jsd_div_full = safe(jsd_dist_full.pow(2))\n",
    "        vocab_tvd_full = safe(0.5 * torch.sum(torch.abs(probs_A_clean - probs_B_clean), dim=-1))\n",
    "        heat_A_full = safe(-torch.sum(probs_A_clean * logp_A_clean, dim=-1))\n",
    "        heat_B_full = safe(-torch.sum(probs_B_clean * logp_B_clean, dim=-1))\n",
    "\n",
    "        # ============================================================\n",
    "        # === GROUND-TRUTH LOG-PROBABILITIES (FULL VOCAB, UNMASKED) ===\n",
    "        # ============================================================\n",
    "        targets = row_A.get(\"target_ids\")\n",
    "        if targets is not None:\n",
    "            if targets.ndim == 1:\n",
    "                targets = targets.unsqueeze(0)\n",
    "\n",
    "            # Align sequence lengths (decoder shift handling)\n",
    "            if logp_A_clean.size(1) == targets.size(1) + 1:\n",
    "                logp_A_clean = logp_A_clean[:, :-1, :]\n",
    "                logp_B_clean = logp_B_clean[:, :-1, :]\n",
    "            elif logp_A_clean.size(1) + 1 == targets.size(1):\n",
    "                targets = targets[:, 1:]\n",
    "\n",
    "            gather_idx = targets.unsqueeze(-1).clamp(max=logp_A_clean.size(-1) - 1)\n",
    "            logp_gt_A_full = logp_A_clean.gather(-1, gather_idx).squeeze(-1)\n",
    "            logp_gt_B_full = logp_B_clean.gather(-1, gather_idx).squeeze(-1)\n",
    "            logp_gt_diff_full = logp_gt_A_full - logp_gt_B_full\n",
    "\n",
    "            mean_logp_gt_A_full = float(logp_gt_A_full.mean().item())\n",
    "            mean_logp_gt_B_full = float(logp_gt_B_full.mean().item())\n",
    "            mean_logp_gt_diff_full = float(logp_gt_diff_full.mean().item())\n",
    "        else:\n",
    "            logp_gt_A_full = logp_gt_B_full = logp_gt_diff_full = torch.empty(0)\n",
    "            mean_logp_gt_A_full = mean_logp_gt_B_full = mean_logp_gt_diff_full = float(\"nan\")\n",
    "\n",
    "        # ============================================================\n",
    "        # === DISPERSION + QUANTILES ================\n",
    "        # ============================================================\n",
    "        sorted_A, _ = torch.sort(probs_A_clean, dim=-1)\n",
    "        sorted_B, _ = torch.sort(probs_B_clean, dim=-1)\n",
    "        q25_A, q75_A = torch.quantile(sorted_A, 0.25, dim=-1), torch.quantile(sorted_A, 0.75, dim=-1)\n",
    "        q25_B, q75_B = torch.quantile(sorted_B, 0.25, dim=-1), torch.quantile(sorted_B, 0.75, dim=-1)\n",
    "        iqr_A, iqr_B = q75_A - q25_A, q75_B - q25_B\n",
    "\n",
    "\n",
    "        # ============================================================\n",
    "        # === FINAL MODEL PERPLEXITY =================================\n",
    "        # ============================================================\n",
    "        def compute_final_perplexity(final_logits, labels, ignore_index=-100, eps=1e-9):\n",
    "            \"\"\"Compute overall model perplexity = exp(mean cross-entropy loss)\"\"\"\n",
    "            if final_logits.ndim == 2:\n",
    "                final_logits = final_logits.unsqueeze(0)\n",
    "            if labels.ndim == 1:\n",
    "                labels = labels.unsqueeze(0)\n",
    "\n",
    "            # Align logits and labels if off by one (common for decoder models)\n",
    "            if final_logits.size(1) == labels.size(1) + 1:\n",
    "                final_logits = final_logits[:, :-1, :]\n",
    "            elif final_logits.size(1) + 1 == labels.size(1):\n",
    "                labels = labels[:, 1:]\n",
    "\n",
    "            logits_flat = final_logits.reshape(-1, final_logits.size(-1))\n",
    "            labels_flat = labels.reshape(-1)\n",
    "\n",
    "            ce_loss = F.cross_entropy(\n",
    "                logits_flat, labels_flat,\n",
    "                ignore_index=ignore_index, reduction=\"mean\"\n",
    "            )\n",
    "\n",
    "            # --- Numeric safety but *faithful* - hopefully :) ---\n",
    "            if torch.isnan(ce_loss) or torch.isinf(ce_loss):\n",
    "                safe_ce = torch.tensor(30.0, device=ce_loss.device)\n",
    "            else:\n",
    "                safe_ce = ce_loss.clamp(min=0.0, max=30.0)\n",
    "\n",
    "            # Perplexity is *unsigned*\n",
    "            ppl = float(torch.exp(safe_ce))\n",
    "            return ppl, float(ce_loss)\n",
    "            \n",
    "        if targets is not None:\n",
    "            final_logits_A = row_A[\"logits\"].to(device)\n",
    "            final_logits_B = row_B[\"logits\"].to(device)\n",
    "            final_ppl_A, ce_A = compute_final_perplexity(final_logits_A, targets)\n",
    "            final_ppl_B, ce_B = compute_final_perplexity(final_logits_B, targets)\n",
    "\n",
    "            # Signed difference (directional drift)\n",
    "            final_ppl_diff = float(final_ppl_A - final_ppl_B)\n",
    "        else:\n",
    "            final_ppl_A = final_ppl_B = final_ppl_diff = float(\"nan\")\n",
    "            ce_A = ce_B = float(\"nan\")\n",
    "\n",
    "        # ============================================================\n",
    "        # === TOP-K METRICS (non-masked divergence version) ==========\n",
    "        # ============================================================\n",
    "        top_vals_A, top_idx_A = torch.topk(probs_A_clean, max_k, dim=-1)\n",
    "        top_vals_B, top_idx_B = torch.topk(probs_B_clean, max_k, dim=-1)\n",
    "\n",
    "        # --- initialize all containers ---\n",
    "        acc_A_topk, acc_B_topk = {}, {}\n",
    "        agree_topk, jaccard_topk = {}, {}\n",
    "        disagree_topk = {}\n",
    "        disagree_correct_topk, agree_correct_topk, agree_wrong_topk = {}, {}, {}\n",
    "        full_jaccard_topk = {}\n",
    "        prob_mass_A_topk, prob_mass_B_topk = {}, {}\n",
    "        shared_mass_topk, tail_mass_A_topk, tail_mass_B_topk = {}, {}, {}\n",
    "        prob_overlap_topk, prob_mass_overlap_topk = {}, {}\n",
    "\n",
    "        for k in topk:\n",
    "            tkA, tkB = top_idx_A[:, :, :k], top_idx_B[:, :, :k]\n",
    "            tvA, tvB = top_vals_A[:, :, :k], top_vals_B[:, :, :k]\n",
    "\n",
    "            # --- probability & overlap metrics ---\n",
    "            prob_mass_A_topk[k], prob_mass_B_topk[k] = tvA.sum(dim=-1), tvB.sum(dim=-1)\n",
    "            tail_mass_A_topk[k], tail_mass_B_topk[k] = 1 - prob_mass_A_topk[k], 1 - prob_mass_B_topk[k]\n",
    "\n",
    "            inter_mask = (tkA.unsqueeze(-1) == tkB.unsqueeze(-2))\n",
    "            inter_counts = inter_mask.any(dim=-1).sum(dim=2).float()\n",
    "            jaccard_topk[k] = inter_counts / (2 * k - inter_counts + eps)\n",
    "            agree_topk[k] = (inter_counts == k).float()\n",
    "            full_jaccard_topk[k] = full_jaccard_over_positions(tkA, tkB, eps, device)\n",
    "\n",
    "            # --- shared probability mass ---\n",
    "            shared_mass = torch.zeros_like(prob_mass_A_topk[k])\n",
    "            for i in range(tkA.size(0)):\n",
    "                shared_tokens = set(tkA[i].reshape(-1).tolist()) & set(tkB[i].reshape(-1).tolist())\n",
    "                if shared_tokens:\n",
    "                    st = torch.tensor(list(shared_tokens), device=device)\n",
    "                    shared_mass[i] = 0.5 * (\n",
    "                        probs_A_clean[i, :, st].sum() + probs_B_clean[i, :, st].sum()\n",
    "                    )\n",
    "            shared_mass_topk[k] = shared_mass\n",
    "            prob_mass_overlap_topk[k] = prob_mass_A_topk[k] * prob_mass_B_topk[k]\n",
    "            prob_overlap_topk[k] = shared_mass / (\n",
    "                0.5 * (prob_mass_A_topk[k] + prob_mass_B_topk[k]) + eps\n",
    "            )\n",
    "\n",
    "            # --- general set disagreement (always defined) ---\n",
    "            disagree_topk[k] = 1.0 - jaccard_topk[k]\n",
    "\n",
    "            # --- accuracy & correctness metrics ---\n",
    "            if targets is not None:\n",
    "                tgt_expand = targets.unsqueeze(0) if targets.ndim == 1 else targets\n",
    "                acc_A = (tkA == tgt_expand.unsqueeze(-1)).any(dim=-1).float()\n",
    "                acc_B = (tkB == tgt_expand.unsqueeze(-1)).any(dim=-1).float()\n",
    "\n",
    "                acc_A_topk[k], acc_B_topk[k] = acc_A, acc_B\n",
    "\n",
    "                # --- correctness-based disagreement metrics ---\n",
    "                disagree_correct_topk[k] = (acc_A + acc_B == 1).float()   # exactly one correct\n",
    "                agree_correct_topk[k]   = (acc_A * acc_B).float()         # both correct\n",
    "                agree_wrong_topk[k]     = ((1 - acc_A) * (1 - acc_B)).float()  # both wrong\n",
    "            else:\n",
    "                acc_A_topk[k] = acc_B_topk[k] = None\n",
    "                disagree_correct_topk[k] = None\n",
    "                agree_correct_topk[k] = None\n",
    "                agree_wrong_topk[k] = None\n",
    "\n",
    "\n",
    "        # ============================================================\n",
    "        # === PREDICTED TOKENS (optional for qualitative analysis) ===\n",
    "        # ============================================================\n",
    "        # Save top-1 predictions (token IDs)\n",
    "        pred_top1_A = top_idx_A[:, :, 0].detach().cpu()\n",
    "        pred_top1_B = top_idx_B[:, :, 0].detach().cpu()\n",
    "\n",
    "        # Optionally, decode them if tokenizer is available\n",
    "        if tokenizer is not None:\n",
    "            decoded_preds_A = [tokenizer.decode(seq, skip_special_tokens=False) for seq in pred_top1_A]\n",
    "            decoded_preds_B = [tokenizer.decode(seq, skip_special_tokens=False) for seq in pred_top1_B]\n",
    "        else:\n",
    "            decoded_preds_A = decoded_preds_B = None\n",
    "\n",
    "\n",
    "        # ============================================================\n",
    "        # === DETAILED ROW ===========================================\n",
    "        # ============================================================\n",
    "        detailed_row = {\n",
    "            \"batch\": batch_num,\n",
    "            \"prompt_id\": row_A[\"prompt_id\"],\n",
    "            \"prompt_text\": row_A.get(\"prompt_text\"),\n",
    "            \"layer_index\": row_A[\"layer_index\"],\n",
    "            \"layer_name\": row_A[\"layer_name\"],\n",
    "            \"vocab_size\": vocab_target,\n",
    "            \"input_ids\": row_A.get(\"input_ids\"),\n",
    "            \"targets\": row_A.get(\"target_ids\"),\n",
    "            \"pred_top1_A\": pred_top1_A,\n",
    "            \"pred_top1_B\": pred_top1_B,\n",
    "            \"decoded_top1_A\": decoded_preds_A,\n",
    "            \"decoded_top1_B\": decoded_preds_B,\n",
    "            \"kl_ab_full\": kl_ab_full.cpu(), \n",
    "            \"kl_ba_full\": kl_ba_full.cpu(), \n",
    "            \"kl_ab_token_full\": kl_ab_token_full,\n",
    "            \"kl_ba_token_full\": kl_ba_token_full,\n",
    "            \"jsd_dist_full\": jsd_dist_full.cpu(), \n",
    "            \"jsd_div_full\": jsd_div_full.cpu(), \n",
    "            \"vocab_tvd_full\": vocab_tvd_full.cpu(), \n",
    "            \"heat_A_full\": heat_A_full.cpu(),\n",
    "            \"heat_B_full\": heat_B_full.cpu(),\n",
    "            \"iqr_A\": iqr_A.cpu(),\n",
    "            \"iqr_B\": iqr_B.cpu(),\n",
    "            \"final_ce_A\": ce_A,\n",
    "            \"final_ce_B\": ce_B,\n",
    "            \"final_ppl_A\": final_ppl_A, \n",
    "            \"final_ppl_B\": final_ppl_B, \n",
    "            \"final_ppl_diff\": final_ppl_diff, \n",
    "            #\"final_ppl_absdiff\": final_ppl_absdiff,\n",
    "            \"acc_A_topk\": acc_A_topk,\n",
    "            \"acc_B_topk\": acc_B_topk,\n",
    "            \"agree_topk\": agree_topk,\n",
    "            \"jaccard_topk\": jaccard_topk,\n",
    "            \"disagree_topk\": disagree_topk,\n",
    "            \"disagree_correct_topk\": disagree_correct_topk,\n",
    "            \"agree_correct_topk\": agree_correct_topk,\n",
    "            \"agree_wrong_topk\": agree_wrong_topk,\n",
    "            \"full_jaccard_topk\": full_jaccard_topk,\n",
    "            \"prob_mass_A_topk\": prob_mass_A_topk,\n",
    "            \"prob_mass_B_topk\": prob_mass_B_topk,\n",
    "            \"tail_mass_A_topk\": tail_mass_A_topk,\n",
    "            \"tail_mass_B_topk\": tail_mass_B_topk,\n",
    "            \"shared_mass_topk\": shared_mass_topk,\n",
    "            \"prob_overlap_topk\": prob_overlap_topk,\n",
    "            \"prob_mass_overlap_topk\": prob_mass_overlap_topk,\n",
    "            \"logp_gt_A_full\": logp_gt_A_full.cpu(),\n",
    "            \"logp_gt_B_full\": logp_gt_B_full.cpu(),\n",
    "            \"logp_gt_diff_full\": logp_gt_diff_full.cpu(),\n",
    "            \"mean_logp_gt_A_full\": mean_logp_gt_A_full,\n",
    "            \"mean_logp_gt_B_full\": mean_logp_gt_B_full,\n",
    "            \"mean_logp_gt_diff_full\": mean_logp_gt_diff_full,\n",
    "\n",
    "        }\n",
    "        detailed.append(detailed_row)\n",
    "\n",
    "    print(f\"[ok] Compared {len(detailed)} pairs (vocab padded safely).\")\n",
    "\n",
    "    return detailed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d134b1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "valid_positions = record[\"attention_mask\"][:-1].bool()\n",
    "logits = record[\"logits\"][valid_positions]\n",
    "targets = record[\"target_ids\"][valid_positions]\n",
    "\n",
    "bos_id, eos_id = tokenizer.bos_token_id, tokenizer.eos_token_id\n",
    "mask = (record[\"attention_mask\"][:-1].bool()) '\\'\n",
    "        & (record[\"input_ids\"][:-1] != bos_id) '\\'\n",
    "        & (record[\"input_ids\"][:-1] != eos_id)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94b50b1",
   "metadata": {},
   "source": [
    "# ==============================================\n",
    "# Hidden Acts Similarity & PPL =================\n",
    "# =============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c298e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import math\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_hidden_batches(folder, pattern=\"*.pt\"):\n",
    "    \"\"\"Load all saved hidden-state batches collected with collect_hidden_states_full().\"\"\"\n",
    "    files = sorted(glob.glob(os.path.join(folder, pattern)))\n",
    "    all_rows = []\n",
    "    for f in files:\n",
    "        print(f\"[load] {f}\")\n",
    "        rows = torch.load(f, map_location=\"cpu\")\n",
    "        all_rows.extend(rows)\n",
    "    print(f\"[ok] Loaded {len(all_rows)} rows from {len(files)} files.\")\n",
    "    return all_rows\n",
    "\n",
    "\n",
    "def analyze_hidden_similarity_batched(rows_A, rows_B, compute_perplexity=True):\n",
    "    \"\"\"\n",
    "    Compare hidden activations from two models (A vs B).\n",
    "    Computes:\n",
    "      - L2 distance (positional, sequence, layer)\n",
    "      - Cosine similarity (positional, sequence, layer)\n",
    "      - Optional: perplexity per model if logits available\n",
    "\n",
    "    Returns:\n",
    "        df_detailed : detailed per-prompt/layer/position metrics\n",
    "    \"\"\"\n",
    "\n",
    "    def safe(x, default=None, eps=1e-9):\n",
    "        \"\"\"Clamp and sanitize tensor values.\"\"\"\n",
    "        if x is None:\n",
    "            return torch.tensor(default if default is not None else 0.0)\n",
    "        x = torch.nan_to_num(x, nan=0.0, posinf=30.0, neginf=-30.0)\n",
    "        if torch.is_floating_point(x):\n",
    "            mean_val = x.mean().item() if x.numel() > 0 else 0.0\n",
    "            if mean_val < 1.0:  # looks like log-probs\n",
    "                x = torch.clamp(x, min=-30.0, max=30.0)\n",
    "            else:\n",
    "                x = torch.clamp(x, min=0.0, max=1e6)\n",
    "        return x\n",
    "\n",
    "    detailed = []\n",
    "    index_B = {(r[\"prompt_id\"], r[\"layer_name\"]): r for r in rows_B if \"hidden\" in r}\n",
    "\n",
    "    for rA in tqdm(rows_A, desc=\"Comparing hidden states\"):\n",
    "        key = (rA[\"prompt_id\"], rA[\"layer_name\"])\n",
    "        rB = index_B.get(key)\n",
    "        if not rB or \"hidden\" not in rA or \"hidden\" not in rB:\n",
    "            continue\n",
    "\n",
    "        hA, hB = rA[\"hidden\"], rB[\"hidden\"]\n",
    "        if not isinstance(hA, torch.Tensor) or not isinstance(hB, torch.Tensor):\n",
    "            continue\n",
    "        if hA.shape != hB.shape:\n",
    "            continue\n",
    "\n",
    "        # === Hidden-state metrics ===\n",
    "        diff = hA - hB\n",
    "        l2_pos = torch.norm(diff, dim=-1)\n",
    "        cos_pos = F.cosine_similarity(hA, hB, dim=-1)\n",
    "        l2_seq = l2_pos.mean().item()\n",
    "        cos_seq = cos_pos.mean().item()\n",
    "\n",
    "        # === Optional perplexity ===\n",
    "        pplA = pplB = ppl_diff_signed = None\n",
    "        if compute_perplexity and \"logits\" in rA and \"logits\" in rB:\n",
    "            for label, logits in zip((\"A\", \"B\"), (rA[\"logits\"], rB[\"logits\"])):\n",
    "                if logits is not None and \"target_ids\" in rA:\n",
    "                    log_probs = safe(F.log_softmax(logits, dim=-1))\n",
    "                    target = rA[\"target_ids\"]\n",
    "                    nll = -log_probs.gather(-1, target.unsqueeze(-1)).squeeze(-1)\n",
    "                    mask = (target != 0).float()\n",
    "                    mean_nll = (nll * mask).sum() / mask.sum()\n",
    "                    ppl = math.exp(mean_nll.item())\n",
    "                    if label == \"A\":\n",
    "                        pplA = ppl\n",
    "                    else:\n",
    "                        pplB = ppl\n",
    "\n",
    "            # signed PPL difference (log-scale for stability)\n",
    "            if pplA is not None and pplB is not None:\n",
    "                ppl_diff_signed = math.log(pplB + 1e-9) - math.log(pplA + 1e-9)\n",
    "\n",
    "        detailed.append({\n",
    "            \"prompt_id\": rA[\"prompt_id\"],\n",
    "            \"batch_index\": rA.get(\"batch_index\"),\n",
    "            \"layer_index\": rA[\"layer_index\"],\n",
    "            \"layer_name\": rA[\"layer_name\"],\n",
    "            \"mean_l2_seq\": l2_seq,\n",
    "            \"mean_cos_seq\": cos_seq,\n",
    "            \"l2_pos\": l2_pos.cpu(),\n",
    "            \"cos_pos\": cos_pos.cpu(),\n",
    "            \"ppl_A\": pplA,\n",
    "            \"ppl_B\": pplB,\n",
    "            \"ppl_diff_signed\": ppl_diff_signed,\n",
    "        })\n",
    "\n",
    "    if not detailed:\n",
    "        raise ValueError(\"No valid pairs found. Check layer alignment and hidden data.\")\n",
    "\n",
    "    df_detailed = pd.DataFrame(detailed)\n",
    "    print(f\"[ok] Computed similarity metrics for {df_detailed['layer_name'].nunique()} layers.\")\n",
    "    return df_detailed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507dc426",
   "metadata": {},
   "source": [
    "# ==============================================\n",
    "# Head Semantics ===============================\n",
    "# =============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e63653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# orig→quant: orig_quant\n",
    "# quant→orig quant_orig\n",
    "@torch.no_grad()\n",
    "def project_hidden_through_other_head(\n",
    "    projector_model,\n",
    "    hidden_file,\n",
    "    batch_num=0,\n",
    "    save_prefix=\"saved_data/projections\",\n",
    "    direction_tag=\"orig_quant\",\n",
    "    device=\"cpu\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Projects pre-saved hidden activations (from collect_hidden_states_full)\n",
    "    through ANOTHER model's LM head (cross-model projection).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Ensure model + device setup ---\n",
    "    projector_model = projector_model.to(device).eval()\n",
    "    Path(save_prefix).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # --- Handle batch number formatting ---\n",
    "    if isinstance(batch_num, str) and not batch_num.isdigit():\n",
    "        batch_str = batch_num\n",
    "    else:\n",
    "        try:\n",
    "            batch_str = f\"{int(batch_num):03d}\"\n",
    "        except Exception:\n",
    "            batch_str = str(batch_num)\n",
    "\n",
    "    # --- Define save path ---\n",
    "    save_path = f\"{save_prefix}/proj_{direction_tag}_batch{batch_str}.pt\"\n",
    "    print(f\"[run] Projecting hidden activations {direction_tag} → {save_path}\")\n",
    "\n",
    "    # --- Load pre-saved activations ---\n",
    "    rows = torch.load(hidden_file, map_location=\"cpu\", weights_only=False)\n",
    "    results = []\n",
    "\n",
    "    # --- Main projection loop ---\n",
    "    for r in tqdm(rows, desc=f\"[batch {batch_str}] {direction_tag} projection\"):\n",
    "        if \"hidden\" not in r:\n",
    "            continue\n",
    "\n",
    "        h = r[\"hidden\"].to(device)\n",
    "        logits_cross = projector_model.lm_head(h).cpu()\n",
    "\n",
    "        # Preserve all meta info\n",
    "        results.append({\n",
    "            \"prompt_id\": r.get(\"prompt_id\"),\n",
    "            \"prompt_text\": r.get(\"prompt_text\"),\n",
    "            \"batch_index\": r.get(\"batch_index\", batch_num),\n",
    "            \"layer_index\": r.get(\"layer_index\"),\n",
    "            \"layer_name\": r.get(\"layer_name\"),\n",
    "            \"input_ids\": r.get(\"input_ids\"),\n",
    "            \"target_ids\": r.get(\"target_ids\"),\n",
    "            \"logits_crossproj\": logits_cross,\n",
    "        })\n",
    "\n",
    "        # Free memory\n",
    "        del h, logits_cross\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    # --- Save the result ---\n",
    "    torch.save(results, save_path)\n",
    "    print(f\"[saved] → {save_path} ({len(results)} entries, batch_index={batch_num})\")\n",
    "    return save_path\n",
    "\n",
    "batch_num = \"009\"\n",
    "\n",
    "# (1) Project original model’s hidden states through quantized model’s head (quant→orig)\n",
    "project_hidden_through_other_head(\n",
    "    projector_model=model_quant,\n",
    "    hidden_file=f\"saved_data/hidden_acts/m_orig_batch{batch_num}.pt\",\n",
    "    batch_num=batch_num,\n",
    "    save_prefix=\"saved_data/projections\",\n",
    "    direction_tag=\"orig_quant\",\n",
    "    device=\"cpu\",\n",
    ")\n",
    "\n",
    "batch_num = \"009\"\n",
    "\n",
    "# (2) Project quantized model’s hidden states through original model’s head\n",
    "project_hidden_through_other_head(\n",
    "    projector_model=model_orig,\n",
    "    hidden_file=f\"saved_data/hidden_acts/m_quant_batch{batch_num}.pt\",\n",
    "    batch_num=batch_num,\n",
    "    save_prefix=\"saved_data/projections\",\n",
    "    direction_tag=\"quant_orig\",\n",
    "    device=\"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a6f17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "@torch.no_grad()\n",
    "def run_projection_comparison_single_batch(\n",
    "    file_A,\n",
    "    file_B,\n",
    "    tokenizer,\n",
    "    batch_num=0,\n",
    "    save_prefix=\"saved_data/head_semantics/semantics_\",\n",
    "    topk_levels=(1, 5, 10, 20),\n",
    "    device=\"cpu\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare *already projected* logits from two models (e.g., orig→quant vs quant→orig).\n",
    "    Computes:\n",
    "      • cosine & L2 distances between logits (sequence-level + per-position)\n",
    "      • Gini coefficients (sequence-level + per-position)\n",
    "      • top-k Jaccard overlaps (per-position + sequence-level)\n",
    "      • decoded top-k tokens for interpretability\n",
    "    \"\"\"\n",
    "\n",
    "    Path(save_prefix).parent.mkdir(parents=True, exist_ok=True)\n",
    "    save_path = f\"{save_prefix}batch{int(batch_num):03d}.pt\"\n",
    "\n",
    "    rows_A = torch.load(file_A, map_location=device, weights_only=False)\n",
    "    rows_B = torch.load(file_B, map_location=device, weights_only=False)\n",
    "\n",
    "    # --- Helper for Gini coefficient ---\n",
    "    def gini_coefficient(x):\n",
    "        \"\"\"Compute Gini per position (for logits → probs).\"\"\"\n",
    "        probs = torch.softmax(x, dim=-1)\n",
    "        n = probs.shape[-1]\n",
    "        sorted_p, _ = torch.sort(probs, dim=-1)\n",
    "        cum_p = torch.cumsum(sorted_p, dim=-1)\n",
    "        gini = 1 - 2 * cum_p.sum(dim=-1) / (n * cum_p[..., -1]) + 1 / n\n",
    "        return gini\n",
    "\n",
    "    index_B = {(r[\"prompt_id\"], r[\"layer_name\"]): r for r in rows_B}\n",
    "    results = []\n",
    "\n",
    "    for rA in tqdm(rows_A, desc=f\"[batch {batch_num}] Comparing projected logits\"):\n",
    "        key = (rA[\"prompt_id\"], rA[\"layer_name\"])\n",
    "        rB = index_B.get(key)\n",
    "        if not rB or \"logits_crossproj\" not in rA or \"logits_crossproj\" not in rB:\n",
    "            continue\n",
    "\n",
    "        logits_A = rA[\"logits_crossproj\"].to(device)   # [T, V]\n",
    "        logits_B = rB[\"logits_crossproj\"].to(device)   # [T, V]\n",
    "        vocab_dim = logits_A.shape[-1]\n",
    "        seq_len = logits_A.shape[0]\n",
    "\n",
    "        # --- Per-position metrics ---\n",
    "        cos_pos = F.cosine_similarity(logits_A, logits_B, dim=-1)           # [T]\n",
    "        l2_pos = torch.norm(logits_A - logits_B, dim=-1)                    # [T]\n",
    "        gini_A_pos = gini_coefficient(logits_A)                             # [T]\n",
    "        gini_B_pos = gini_coefficient(logits_B)                             # [T]\n",
    "        delta_gini_pos = gini_B_pos - gini_A_pos\n",
    "\n",
    "        # --- Sequence-level summaries ---\n",
    "        cos_seq = cos_pos.mean().item()\n",
    "        l2_seq = l2_pos.mean().item()\n",
    "        gini_A_seq = gini_A_pos.mean().item()\n",
    "        gini_B_seq = gini_B_pos.mean().item()\n",
    "        delta_gini_seq = gini_B_seq - gini_A_seq\n",
    "\n",
    "        # --- Top-k Jaccard overlaps ---\n",
    "        jaccard_pos_dict = {}\n",
    "        jaccard_seq_dict = {}\n",
    "        decoded_shift = {}\n",
    "\n",
    "        for k in topk_levels:\n",
    "            k_safe = min(k, vocab_dim)\n",
    "            jaccard_pos = []\n",
    "            for t in range(seq_len):\n",
    "                topA_t = torch.topk(logits_A[t], k_safe).indices.tolist()\n",
    "                topB_t = torch.topk(logits_B[t], k_safe).indices.tolist()\n",
    "                inter = len(set(topA_t) & set(topB_t))\n",
    "                union = len(set(topA_t) | set(topB_t))\n",
    "                jaccard_pos.append(inter / union if union > 0 else 0.0)\n",
    "            jaccard_pos_tensor = torch.tensor(jaccard_pos)\n",
    "            jaccard_pos_dict[f\"jaccard_top{k}_pos\"] = jaccard_pos_tensor.cpu()\n",
    "            jaccard_seq_dict[f\"jaccard_top{k}_seq\"] = jaccard_pos_tensor.mean().item()\n",
    "\n",
    "            # Decode top-k tokens for mean logits (for readability)\n",
    "            mean_A = logits_A.mean(dim=0)\n",
    "            mean_B = logits_B.mean(dim=0)\n",
    "            topA_k = torch.topk(mean_A, k_safe).indices.tolist()\n",
    "            topB_k = torch.topk(mean_B, k_safe).indices.tolist()\n",
    "            decoded_shift[f\"top{k}_A\"] = [tokenizer.decode([i]) for i in topA_k]\n",
    "            decoded_shift[f\"top{k}_B\"] = [tokenizer.decode([i]) for i in topB_k]\n",
    "\n",
    "        # --- Aggregate everything ---\n",
    "        result_entry = {\n",
    "            \"prompt_id\": rA[\"prompt_id\"],\n",
    "            \"batch_index\": rA.get(\"batch_index\", batch_num),\n",
    "            \"layer_index\": rA[\"layer_index\"],\n",
    "            \"layer_name\": rA[\"layer_name\"],\n",
    "            \"input_ids\": rA.get(\"input_ids\"),\n",
    "            \"target_ids\": rA.get(\"target_ids\"),\n",
    "\n",
    "            # --- sequence-level summary ---\n",
    "            \"cosine_seq\": cos_seq,\n",
    "            \"l2_seq\": l2_seq,\n",
    "            \"gini_A_seq\": gini_A_seq,\n",
    "            \"gini_B_seq\": gini_B_seq,\n",
    "            \"delta_gini_seq\": delta_gini_seq,\n",
    "            **jaccard_seq_dict,\n",
    "\n",
    "            # --- detailed per-position tensors ---\n",
    "            \"cosine_pos\": cos_pos.cpu(),\n",
    "            \"l2_pos\": l2_pos.cpu(),\n",
    "            \"gini_A_pos\": gini_A_pos.cpu(),\n",
    "            \"gini_B_pos\": gini_B_pos.cpu(),\n",
    "            \"delta_gini_pos\": delta_gini_pos.cpu(),\n",
    "            **jaccard_pos_dict,\n",
    "\n",
    "            \"decoded_shift\": decoded_shift,\n",
    "        }\n",
    "\n",
    "        results.append(result_entry)\n",
    "        del logits_A, logits_B\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    torch.save(results, save_path)\n",
    "    print(f\"[saved] → {save_path} ({len(results)} entries)\")\n",
    "    return results\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "orig_tokenizer = AutoTokenizer.from_pretrained(\"Models/LLaMA3Instruct\")\n",
    "\n",
    "batch_num = \"002\"\n",
    "\n",
    "run_projection_comparison_single_batch(\n",
    "    file_A=f\"saved_data/projections/proj_orig_quant_batch{batch_num}.pt\",\n",
    "    file_B=f\"saved_data/projections/proj_quant_orig_batch{batch_num}.pt\",\n",
    "    tokenizer=orig_tokenizer,\n",
    "    batch_num=batch_num,\n",
    "    save_prefix=\"saved_data/projection_comparisons/semantics_\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logit-lens-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
