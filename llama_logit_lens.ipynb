{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e63148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datasets import load_dataset, DownloadMode\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from llama_wrapper import LlamaPromptLens, run_logit_lens_batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21e09c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class Models(Enum):\n",
    "    LAIN8B = \"Models/LLaMA3Instruct\"\n",
    "    HF100B = \"Models/HF1BitLLM100Btokens\"\n",
    "\n",
    "\n",
    "class Names(Enum):\n",
    "    LAIN8B = \"Meta-Llama-3-8B-Instruct-fp\"\n",
    "    HF100B = \"Llama3-8B-1.58-100B-tokens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93dfb13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r'D:\\LogitLensData\\nq'\n",
    "\n",
    "destination_path = str(Path(filepath))\n",
    "nq_dataset = load_dataset(\n",
    "    'sentence-transformers/natural-questions',\n",
    "    split={\n",
    "        'train': 'train[:1000]'\n",
    "    },\n",
    "    cache_dir=destination_path,\n",
    "    download_mode=DownloadMode.REUSE_DATASET_IF_EXISTS,\n",
    "    keep_in_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2f9ffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nq_queries = nq_dataset['train']['query']\n",
    "nq_answers = nq_dataset['train']['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c460b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "nq_queries = nq_dataset['train']['query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "253c2a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nq_queries_200 = nq_queries[:200]\n",
    "nq_queries_400 = nq_queries[200:400]\n",
    "nq_queries_600 = nq_queries[400:600]\n",
    "nq_queries_800 = nq_queries[600:800]\n",
    "nq_queries_1000 = nq_queries[800:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9d68e7",
   "metadata": {},
   "source": [
    "### LLaMA FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d5b7865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a34e8a7b7d5341c19c83161eda16b900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture detected: llama\n",
      "Standard FP16 or FP32 model.\n"
     ]
    }
   ],
   "source": [
    "llama8b_fp = LlamaPromptLens(\n",
    "    model_id=Models.LAIN8B.value,\n",
    "    apply_per_layer_norm=True,\n",
    "    include_subblocks=False,\n",
    "    device=\"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c340bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Saved batch 0: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch0.pt\n",
      "[✓] Saved batch 1: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch1.pt\n",
      "[✓] Saved batch 2: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch2.pt\n",
      "[✓] Saved batch 3: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch3.pt\n",
      "[✓] Saved batch 4: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch4.pt\n",
      "[✓] Saved batch 5: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch5.pt\n",
      "[✓] Saved batch 6: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch6.pt\n",
      "[✓] Saved batch 7: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch7.pt\n",
      "[✓] Saved batch 8: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch8.pt\n",
      "[✓] Saved batch 9: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch9.pt\n",
      "[✓] Saved batch 10: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch10.pt\n",
      "[✓] Saved batch 11: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch11.pt\n",
      "[✓] Saved batch 12: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch12.pt\n",
      "[✓] Saved batch 13: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch13.pt\n",
      "[✓] Saved batch 14: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch14.pt\n",
      "[✓] Saved batch 15: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch15.pt\n",
      "[✓] Saved batch 16: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch16.pt\n",
      "[✓] Saved batch 17: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch17.pt\n",
      "[✓] Saved batch 18: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch18.pt\n",
      "[✓] Saved batch 19: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch19.pt\n",
      "All 200 prompts processed.\n"
     ]
    }
   ],
   "source": [
    "run_logit_lens_batched(\n",
    "    lens=llama8b_fp,\n",
    "    prompts=nq_queries_200,\n",
    "    dataset_name=\"nq_query_200\",\n",
    "    model_name=\"llama8b_fp\",\n",
    "    save_dir=\"logs/lens_batches_norm/llama8b_fp/nq_200\",\n",
    "    proj_precision=None,\n",
    "    batch_size=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "638cf34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.load(\n",
    "    \"logs/lens_batches/nq_query_llama8b_fp_batch0.pt\",\n",
    "    weights_only=False \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f5d34f",
   "metadata": {},
   "source": [
    "### HF1BitLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "012916bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture detected: bitnet\n",
      "BitNet model (BitLinear layers).\n"
     ]
    }
   ],
   "source": [
    "llama8b_hf100b = LlamaPromptLens(\n",
    "    model_id=Models.HF100B.value,\n",
    "    apply_per_layer_norm=True,\n",
    "    include_subblocks=False,\n",
    "    device=\"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95050386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Saved batch 0: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch0.pt\n",
      "[✓] Saved batch 1: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch1.pt\n",
      "[✓] Saved batch 2: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch2.pt\n",
      "[✓] Saved batch 3: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch3.pt\n",
      "[✓] Saved batch 4: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch4.pt\n",
      "[✓] Saved batch 5: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch5.pt\n",
      "[✓] Saved batch 6: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch6.pt\n",
      "[✓] Saved batch 7: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch7.pt\n",
      "[✓] Saved batch 8: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch8.pt\n",
      "[✓] Saved batch 9: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch9.pt\n",
      "[✓] Saved batch 10: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch10.pt\n",
      "[✓] Saved batch 11: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch11.pt\n",
      "[✓] Saved batch 12: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch12.pt\n",
      "[✓] Saved batch 13: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch13.pt\n",
      "[✓] Saved batch 14: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch14.pt\n",
      "[✓] Saved batch 15: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch15.pt\n",
      "[✓] Saved batch 16: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch16.pt\n",
      "[✓] Saved batch 17: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch17.pt\n",
      "[✓] Saved batch 18: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch18.pt\n",
      "[✓] Saved batch 19: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch19.pt\n",
      "All 200 prompts processed.\n"
     ]
    }
   ],
   "source": [
    "run_logit_lens_batched(\n",
    "    lens=llama8b_hf100b,\n",
    "    prompts=nq_queries_200,\n",
    "    dataset_name=\"nq_query_200\",\n",
    "    model_name=\"llama8b_hf100b\",\n",
    "    save_dir=\"logs/lens_batches_norm/llama8b_hf100b/nq_200\",\n",
    "    proj_precision=None,\n",
    "    batch_size=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfbe3455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.load(\n",
    "    \"logs/lens_batches/nq_query_norm_llama8b_hf100b_batch0.pt\",\n",
    "    weights_only=False \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6544c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>dataset</th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>layer_index</th>\n",
       "      <th>layer_name</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>target_ids</th>\n",
       "      <th>logits</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>9</td>\n",
       "      <td>when did fosters home for imaginary friends start</td>\n",
       "      <td>nq_query_norm</td>\n",
       "      <td>128000</td>\n",
       "      <td>28</td>\n",
       "      <td>layer_27</td>\n",
       "      <td>[tensor(128000), tensor(9493), tensor(1550), t...</td>\n",
       "      <td>[tensor(9493), tensor(1550), tensor(37413), te...</td>\n",
       "      <td>[[tensor(0.6027), tensor(0.5580), tensor(0.581...</td>\n",
       "      <td>[tensor(0), tensor(1), tensor(2), tensor(3), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>9</td>\n",
       "      <td>when did fosters home for imaginary friends start</td>\n",
       "      <td>nq_query_norm</td>\n",
       "      <td>128000</td>\n",
       "      <td>29</td>\n",
       "      <td>layer_28</td>\n",
       "      <td>[tensor(128000), tensor(9493), tensor(1550), t...</td>\n",
       "      <td>[tensor(9493), tensor(1550), tensor(37413), te...</td>\n",
       "      <td>[[tensor(0.3937), tensor(0.6215), tensor(0.407...</td>\n",
       "      <td>[tensor(0), tensor(1), tensor(2), tensor(3), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>9</td>\n",
       "      <td>when did fosters home for imaginary friends start</td>\n",
       "      <td>nq_query_norm</td>\n",
       "      <td>128000</td>\n",
       "      <td>30</td>\n",
       "      <td>layer_29</td>\n",
       "      <td>[tensor(128000), tensor(9493), tensor(1550), t...</td>\n",
       "      <td>[tensor(9493), tensor(1550), tensor(37413), te...</td>\n",
       "      <td>[[tensor(0.3690), tensor(1.1385), tensor(0.828...</td>\n",
       "      <td>[tensor(0), tensor(1), tensor(2), tensor(3), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>9</td>\n",
       "      <td>when did fosters home for imaginary friends start</td>\n",
       "      <td>nq_query_norm</td>\n",
       "      <td>128000</td>\n",
       "      <td>31</td>\n",
       "      <td>layer_30</td>\n",
       "      <td>[tensor(128000), tensor(9493), tensor(1550), t...</td>\n",
       "      <td>[tensor(9493), tensor(1550), tensor(37413), te...</td>\n",
       "      <td>[[tensor(1.3250), tensor(2.6986), tensor(1.801...</td>\n",
       "      <td>[tensor(0), tensor(1), tensor(2), tensor(3), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>9</td>\n",
       "      <td>when did fosters home for imaginary friends start</td>\n",
       "      <td>nq_query_norm</td>\n",
       "      <td>128000</td>\n",
       "      <td>32</td>\n",
       "      <td>layer_31</td>\n",
       "      <td>[tensor(128000), tensor(9493), tensor(1550), t...</td>\n",
       "      <td>[tensor(9493), tensor(1550), tensor(37413), te...</td>\n",
       "      <td>[[tensor(0.7254), tensor(1.6154), tensor(0.954...</td>\n",
       "      <td>[tensor(0), tensor(1), tensor(2), tensor(3), t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     prompt_id                                        prompt_text  \\\n",
       "325          9  when did fosters home for imaginary friends start   \n",
       "326          9  when did fosters home for imaginary friends start   \n",
       "327          9  when did fosters home for imaginary friends start   \n",
       "328          9  when did fosters home for imaginary friends start   \n",
       "329          9  when did fosters home for imaginary friends start   \n",
       "\n",
       "           dataset  vocab_size  layer_index layer_name  \\\n",
       "325  nq_query_norm      128000           28   layer_27   \n",
       "326  nq_query_norm      128000           29   layer_28   \n",
       "327  nq_query_norm      128000           30   layer_29   \n",
       "328  nq_query_norm      128000           31   layer_30   \n",
       "329  nq_query_norm      128000           32   layer_31   \n",
       "\n",
       "                                             input_ids  \\\n",
       "325  [tensor(128000), tensor(9493), tensor(1550), t...   \n",
       "326  [tensor(128000), tensor(9493), tensor(1550), t...   \n",
       "327  [tensor(128000), tensor(9493), tensor(1550), t...   \n",
       "328  [tensor(128000), tensor(9493), tensor(1550), t...   \n",
       "329  [tensor(128000), tensor(9493), tensor(1550), t...   \n",
       "\n",
       "                                            target_ids  \\\n",
       "325  [tensor(9493), tensor(1550), tensor(37413), te...   \n",
       "326  [tensor(9493), tensor(1550), tensor(37413), te...   \n",
       "327  [tensor(9493), tensor(1550), tensor(37413), te...   \n",
       "328  [tensor(9493), tensor(1550), tensor(37413), te...   \n",
       "329  [tensor(9493), tensor(1550), tensor(37413), te...   \n",
       "\n",
       "                                                logits  \\\n",
       "325  [[tensor(0.6027), tensor(0.5580), tensor(0.581...   \n",
       "326  [[tensor(0.3937), tensor(0.6215), tensor(0.407...   \n",
       "327  [[tensor(0.3690), tensor(1.1385), tensor(0.828...   \n",
       "328  [[tensor(1.3250), tensor(2.6986), tensor(1.801...   \n",
       "329  [[tensor(0.7254), tensor(1.6154), tensor(0.954...   \n",
       "\n",
       "                                              position  \n",
       "325  [tensor(0), tensor(1), tensor(2), tensor(3), t...  \n",
       "326  [tensor(0), tensor(1), tensor(2), tensor(3), t...  \n",
       "327  [tensor(0), tensor(1), tensor(2), tensor(3), t...  \n",
       "328  [tensor(0), tensor(1), tensor(2), tensor(3), t...  \n",
       "329  [tensor(0), tensor(1), tensor(2), tensor(3), t...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a4349c",
   "metadata": {},
   "source": [
    "# Softmax and Single Model Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ff482d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 109\u001b[0m\n\u001b[1;32m    106\u001b[0m model_logits \u001b[38;5;241m=\u001b[39m raw_logits_data\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# Extract topk metrics:\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m extracted_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mextract_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_logits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# Saving as a torch file:\u001b[39;00m\n\u001b[1;32m    112\u001b[0m save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogs/batch_probs_raw/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch0.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m, in \u001b[0;36mextract_metrics\u001b[0;34m(data, topk, mask_ids)\u001b[0m\n\u001b[1;32m     12\u001b[0m max_k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(all_k)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m---> 15\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogits\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# [seq_len, vocab]\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     targets \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# --- shape normalization ---\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def extract_metrics(\n",
    "    data,\n",
    "    topk=[1, 5, 10, 20],\n",
    "    mask_ids=[128000, 128009],\n",
    "    device=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Extract top-k accuracy, log-probs, and NLL metrics from logit lens outputs.\n",
    "    Works with both a list of dicts and a pandas DataFrame (as produced by _run_logit_lens_batch).\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        data = data.to_dict(orient=\"records\")\n",
    "\n",
    "    results = []\n",
    "    all_k = sorted(set([1] + list(topk)))  # always include top-1\n",
    "    max_k = max(all_k)\n",
    "\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    mask_ids = torch.tensor(mask_ids, device=device)\n",
    "\n",
    "    for row in data:\n",
    "        logits = row[\"logits\"].to(device)  # [seq_len, vocab]\n",
    "        targets = row.get(\"target_ids\", None)\n",
    "        if targets is not None:\n",
    "            targets = targets.to(device)\n",
    "\n",
    "        # --- normalize shapes ---\n",
    "        if logits.dim() == 3 and logits.size(0) == 1:\n",
    "            logits = logits.squeeze(0)\n",
    "        if targets is not None and targets.dim() == 2 and targets.size(0) == 1:\n",
    "            targets = targets.squeeze(0)\n",
    "\n",
    "        seq_len, vocab_size = logits.shape\n",
    "\n",
    "        # --- stable softmax ---\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "        probs = log_probs.exp()\n",
    "\n",
    "        # --- top-k predictions ---\n",
    "        top_vals, top_idx = torch.topk(probs, max_k, dim=-1)\n",
    "        topk_preds = {k: top_idx[:, :k] for k in all_k}\n",
    "        topk_vals = {k: top_vals[:, :k] for k in all_k}\n",
    "\n",
    "        # --- metrics if targets exist ---\n",
    "        if targets is not None:\n",
    "            # mask out special tokens\n",
    "            mask = ~torch.isin(targets, mask_ids)\n",
    "\n",
    "            # target log probs and nll\n",
    "            target_logprobs = log_probs[torch.arange(seq_len, device=device), targets]\n",
    "            target_probs = target_logprobs.exp()\n",
    "            nll = -target_logprobs\n",
    "\n",
    "            # accuracy metrics\n",
    "            correct_topk, acc_topk = {}, {}\n",
    "            for k in all_k:\n",
    "                correct = (targets.unsqueeze(-1) == topk_preds[k]).any(dim=-1).int()\n",
    "                correct_topk[k] = correct\n",
    "                valid_correct = correct[mask]\n",
    "                acc_mean = valid_correct.float().mean().item() if valid_correct.numel() > 0 else float(\"nan\")\n",
    "                acc_topk[k] = {\"mean\": acc_mean, \"per_token\": correct.tolist()}\n",
    "\n",
    "            # monotonicity sanity check\n",
    "            for k1, k2 in zip(all_k[:-1], all_k[1:]):\n",
    "                assert (correct_topk[k1] <= correct_topk[k2]).all(), f\"Top-{k1} not subset of top-{k2}\"\n",
    "\n",
    "        else:\n",
    "            mask = target_probs = target_logprobs = nll = correct_topk = acc_topk = None\n",
    "\n",
    "        results.append({\n",
    "            \"prompt_id\": row.get(\"prompt_id\"),\n",
    "            \"prompt_text\": row.get(\"prompt_text\"),\n",
    "            \"layer_index\": row.get(\"layer_index\"),\n",
    "            \"layer_name\": row.get(\"layer_name\"),\n",
    "            \"dataset\": row.get(\"dataset\"),\n",
    "            \"vocab_size\": vocab_size,\n",
    "            \"input_ids\": row.get(\"input_ids\"),\n",
    "            \"position\": row.get(\"position\"),\n",
    "            \"targets\": targets,\n",
    "            \"mask\": mask,\n",
    "            \"logits\": logits.cpu(),\n",
    "            \"log_probs\": log_probs.cpu(),\n",
    "            \"probs\": probs.cpu(),\n",
    "            \"nll\": nll.cpu() if nll is not None else None,\n",
    "            \"target_probs\": target_probs.cpu() if target_probs is not None else None,\n",
    "            \"target_logprobs\": target_logprobs.cpu() if target_logprobs is not None else None,\n",
    "            \"topk_preds\": {k: v.cpu() for k, v in topk_preds.items()},\n",
    "            \"topk_vals\": {k: v.cpu() for k, v in topk_vals.items()},\n",
    "            \"correct_topk\": {k: v.cpu() for k, v in correct_topk.items()} if correct_topk else None,\n",
    "            \"acc_topk\": acc_topk,\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Load logits:\n",
    "\"\"\"norm_logits_data = torch.load(\n",
    "    \"logs/lens_batches/nq_query_norm_llama8b_hf100b_batch0.pt\",\n",
    "    weights_only=False \n",
    ")\"\"\"\n",
    "\n",
    "raw_logits_data = torch.load(\n",
    "    \"logs/lens_batches_raw/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch0.pt\",\n",
    "    weights_only=False \n",
    ")\n",
    "\n",
    "model_logits = raw_logits_data\n",
    "\n",
    "# Extract topk metrics:\n",
    "extracted_metrics = extract_metrics(model_logits)\n",
    "\n",
    "# Saving as a torch file:\n",
    "save_path = \"logs/batch_probs_raw/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch0.pt\"\n",
    "torch.save(extracted_metrics, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logit-lens-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
