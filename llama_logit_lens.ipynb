{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e63148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datasets import load_dataset, DownloadMode\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from mi_utils.util.logit_lens_utils.llama_wrapper import LlamaPromptLens, run_logit_lens_batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21e09c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class Models(Enum):\n",
    "    LAIN8B = \"Models/LLaMA3Instruct\"\n",
    "    HF100B = \"Models/HF1BitLLM100Btokens\"\n",
    "\n",
    "\n",
    "class Names(Enum):\n",
    "    LAIN8B = \"Meta-Llama-3-8B-Instruct-fp\"\n",
    "    HF100B = \"Llama3-8B-1.58-100B-tokens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93dfb13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r'D:\\LogitLensData\\nq'\n",
    "\n",
    "destination_path = str(Path(filepath))\n",
    "nq_dataset = load_dataset(\n",
    "    'sentence-transformers/natural-questions',\n",
    "    split={\n",
    "        'train': 'train[:10]'\n",
    "    },\n",
    "    cache_dir=destination_path,\n",
    "    download_mode=DownloadMode.REUSE_DATASET_IF_EXISTS,\n",
    "    keep_in_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2f9ffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nq_queries = nq_dataset['train']['query']\n",
    "nq_answers = nq_dataset['train']['answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9d68e7",
   "metadata": {},
   "source": [
    "### LLaMA FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d5b7865",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/am/AM/LogitDiffLens/logit-lens-env/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:777: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_attentions` is. When `return_dict_in_generate` is not `True`, `output_attentions` is ignored.\n",
      "  warnings.warn(\n",
      "/media/am/AM/LogitDiffLens/logit-lens-env/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:777: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_hidden_states` is. When `return_dict_in_generate` is not `True`, `output_hidden_states` is ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea6921731b6043ceaecdc4d59e2ced3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture detected: llama\n",
      "Standard FP16 or FP32 model.\n"
     ]
    }
   ],
   "source": [
    "llama8b_fp = LlamaPromptLens(\n",
    "    model_id=Models.LAIN8B.value,\n",
    "    apply_per_layer_norm=False,\n",
    "    include_subblocks=False,\n",
    "    device=\"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c340bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[âœ“] Saved batch 0: logs/lens_batches/nq_query_llama8b_fp_batch0.pt\n",
      "All 10 prompts processed.\n"
     ]
    }
   ],
   "source": [
    "run_logit_lens_batched(\n",
    "    lens=llama8b_fp,\n",
    "    prompts=nq_queries,\n",
    "    dataset_name=\"nq_query\",\n",
    "    model_name=\"llama8b_fp\",\n",
    "    proj_precision=None,\n",
    "    batch_size=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "638cf34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.load(\n",
    "    \"logs/lens_batches/nq_query_llama8b_fp_batch0.pt\",\n",
    "    weights_only=False \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "885d7db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>dataset</th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>layer_index</th>\n",
       "      <th>layer_name</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>target_ids</th>\n",
       "      <th>logits</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>9</td>\n",
       "      <td>when did fosters home for imaginary friends start</td>\n",
       "      <td>nq_query</td>\n",
       "      <td>128000</td>\n",
       "      <td>29</td>\n",
       "      <td>layer_28</td>\n",
       "      <td>[tensor(128000), tensor(9493), tensor(1550), t...</td>\n",
       "      <td>[tensor(9493), tensor(1550), tensor(37413), te...</td>\n",
       "      <td>[[tensor(-0.1089), tensor(-0.7619), tensor(-0....</td>\n",
       "      <td>[tensor(0), tensor(1), tensor(2), tensor(3), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>9</td>\n",
       "      <td>when did fosters home for imaginary friends start</td>\n",
       "      <td>nq_query</td>\n",
       "      <td>128000</td>\n",
       "      <td>30</td>\n",
       "      <td>layer_29</td>\n",
       "      <td>[tensor(128000), tensor(9493), tensor(1550), t...</td>\n",
       "      <td>[tensor(9493), tensor(1550), tensor(37413), te...</td>\n",
       "      <td>[[tensor(-0.5514), tensor(-0.4113), tensor(-0....</td>\n",
       "      <td>[tensor(0), tensor(1), tensor(2), tensor(3), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>9</td>\n",
       "      <td>when did fosters home for imaginary friends start</td>\n",
       "      <td>nq_query</td>\n",
       "      <td>128000</td>\n",
       "      <td>31</td>\n",
       "      <td>layer_30</td>\n",
       "      <td>[tensor(128000), tensor(9493), tensor(1550), t...</td>\n",
       "      <td>[tensor(9493), tensor(1550), tensor(37413), te...</td>\n",
       "      <td>[[tensor(-2.1905), tensor(-1.0497), tensor(-1....</td>\n",
       "      <td>[tensor(0), tensor(1), tensor(2), tensor(3), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>9</td>\n",
       "      <td>when did fosters home for imaginary friends start</td>\n",
       "      <td>nq_query</td>\n",
       "      <td>128000</td>\n",
       "      <td>32</td>\n",
       "      <td>layer_31</td>\n",
       "      <td>[tensor(128000), tensor(9493), tensor(1550), t...</td>\n",
       "      <td>[tensor(9493), tensor(1550), tensor(37413), te...</td>\n",
       "      <td>[[tensor(6.7354), tensor(7.3383), tensor(5.922...</td>\n",
       "      <td>[tensor(0), tensor(1), tensor(2), tensor(3), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>9</td>\n",
       "      <td>when did fosters home for imaginary friends start</td>\n",
       "      <td>nq_query</td>\n",
       "      <td>128000</td>\n",
       "      <td>33</td>\n",
       "      <td>output</td>\n",
       "      <td>[tensor(128000), tensor(9493), tensor(1550), t...</td>\n",
       "      <td>[tensor(9493), tensor(1550), tensor(37413), te...</td>\n",
       "      <td>[[tensor(2.7837), tensor(4.3844), tensor(3.649...</td>\n",
       "      <td>[tensor(0), tensor(1), tensor(2), tensor(3), t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     prompt_id                                        prompt_text   dataset  \\\n",
       "335          9  when did fosters home for imaginary friends start  nq_query   \n",
       "336          9  when did fosters home for imaginary friends start  nq_query   \n",
       "337          9  when did fosters home for imaginary friends start  nq_query   \n",
       "338          9  when did fosters home for imaginary friends start  nq_query   \n",
       "339          9  when did fosters home for imaginary friends start  nq_query   \n",
       "\n",
       "     vocab_size  layer_index layer_name  \\\n",
       "335      128000           29   layer_28   \n",
       "336      128000           30   layer_29   \n",
       "337      128000           31   layer_30   \n",
       "338      128000           32   layer_31   \n",
       "339      128000           33     output   \n",
       "\n",
       "                                             input_ids  \\\n",
       "335  [tensor(128000), tensor(9493), tensor(1550), t...   \n",
       "336  [tensor(128000), tensor(9493), tensor(1550), t...   \n",
       "337  [tensor(128000), tensor(9493), tensor(1550), t...   \n",
       "338  [tensor(128000), tensor(9493), tensor(1550), t...   \n",
       "339  [tensor(128000), tensor(9493), tensor(1550), t...   \n",
       "\n",
       "                                            target_ids  \\\n",
       "335  [tensor(9493), tensor(1550), tensor(37413), te...   \n",
       "336  [tensor(9493), tensor(1550), tensor(37413), te...   \n",
       "337  [tensor(9493), tensor(1550), tensor(37413), te...   \n",
       "338  [tensor(9493), tensor(1550), tensor(37413), te...   \n",
       "339  [tensor(9493), tensor(1550), tensor(37413), te...   \n",
       "\n",
       "                                                logits  \\\n",
       "335  [[tensor(-0.1089), tensor(-0.7619), tensor(-0....   \n",
       "336  [[tensor(-0.5514), tensor(-0.4113), tensor(-0....   \n",
       "337  [[tensor(-2.1905), tensor(-1.0497), tensor(-1....   \n",
       "338  [[tensor(6.7354), tensor(7.3383), tensor(5.922...   \n",
       "339  [[tensor(2.7837), tensor(4.3844), tensor(3.649...   \n",
       "\n",
       "                                              position  \n",
       "335  [tensor(0), tensor(1), tensor(2), tensor(3), t...  \n",
       "336  [tensor(0), tensor(1), tensor(2), tensor(3), t...  \n",
       "337  [tensor(0), tensor(1), tensor(2), tensor(3), t...  \n",
       "338  [tensor(0), tensor(1), tensor(2), tensor(3), t...  \n",
       "339  [tensor(0), tensor(1), tensor(2), tensor(3), t...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f5d34f",
   "metadata": {},
   "source": [
    "### HF1BitLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "012916bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/am/AM/LogitDiffLens/logit-lens-env/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:777: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_attentions` is. When `return_dict_in_generate` is not `True`, `output_attentions` is ignored.\n",
      "  warnings.warn(\n",
      "/media/am/AM/LogitDiffLens/logit-lens-env/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:777: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_hidden_states` is. When `return_dict_in_generate` is not `True`, `output_hidden_states` is ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture detected: bitnet\n",
      "BitNet model (BitLinear layers).\n"
     ]
    }
   ],
   "source": [
    "llama8b_hf100b = LlamaPromptLens(\n",
    "    model_id=Models.HF100B.value,\n",
    "    apply_per_layer_norm=False,\n",
    "    include_subblocks=False,\n",
    "    device=\"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95050386",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logit_lens_batched(\n",
    "    lens=llama8b_hf100b,\n",
    "    prompts=nq_queries,\n",
    "    dataset_name=\"nq_query\",\n",
    "    model_name=\"llama8b_hf100b\",\n",
    "    proj_precision=None,\n",
    "    batch_size=10,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logit-lens-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
