{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e63148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datasets import load_dataset, DownloadMode\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from llama_wrapper import LlamaPromptLens, run_logit_lens_batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21e09c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class Models(Enum):\n",
    "    LAIN8B = \"Models/LLaMA3Instruct\"\n",
    "    HF100B = \"Models/HF1BitLLM100Btokens\"\n",
    "\n",
    "\n",
    "class Names(Enum):\n",
    "    LAIN8B = \"Meta-Llama-3-8B-Instruct-fp\"\n",
    "    HF100B = \"Llama3-8B-1.58-100B-tokens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93dfb13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r'D:\\LogitLensData\\nq'\n",
    "\n",
    "destination_path = str(Path(filepath))\n",
    "nq_dataset = load_dataset(\n",
    "    'sentence-transformers/natural-questions',\n",
    "    split={\n",
    "        'train': 'train[:1000]'\n",
    "    },\n",
    "    cache_dir=destination_path,\n",
    "    download_mode=DownloadMode.REUSE_DATASET_IF_EXISTS,\n",
    "    keep_in_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2f9ffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nq_queries = nq_dataset['train']['query']\n",
    "nq_answers = nq_dataset['train']['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "253c2a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nq_queries_200 = nq_queries[:200]\n",
    "nq_queries_400 = nq_queries[200:400]\n",
    "nq_queries_600 = nq_queries[400:600]\n",
    "nq_queries_800 = nq_queries[600:800]\n",
    "nq_queries_1000 = nq_queries[800:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9d68e7",
   "metadata": {},
   "source": [
    "### LLaMA FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d5b7865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a34e8a7b7d5341c19c83161eda16b900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture detected: llama\n",
      "Standard FP16 or FP32 model.\n"
     ]
    }
   ],
   "source": [
    "llama8b_fp = LlamaPromptLens(\n",
    "    model_id=Models.LAIN8B.value,\n",
    "    apply_per_layer_norm=True,\n",
    "    include_subblocks=False,\n",
    "    device=\"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c340bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Saved batch 0: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch0.pt\n",
      "[✓] Saved batch 1: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch1.pt\n",
      "[✓] Saved batch 2: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch2.pt\n",
      "[✓] Saved batch 3: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch3.pt\n",
      "[✓] Saved batch 4: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch4.pt\n",
      "[✓] Saved batch 5: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch5.pt\n",
      "[✓] Saved batch 6: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch6.pt\n",
      "[✓] Saved batch 7: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch7.pt\n",
      "[✓] Saved batch 8: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch8.pt\n",
      "[✓] Saved batch 9: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch9.pt\n",
      "[✓] Saved batch 10: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch10.pt\n",
      "[✓] Saved batch 11: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch11.pt\n",
      "[✓] Saved batch 12: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch12.pt\n",
      "[✓] Saved batch 13: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch13.pt\n",
      "[✓] Saved batch 14: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch14.pt\n",
      "[✓] Saved batch 15: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch15.pt\n",
      "[✓] Saved batch 16: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch16.pt\n",
      "[✓] Saved batch 17: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch17.pt\n",
      "[✓] Saved batch 18: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch18.pt\n",
      "[✓] Saved batch 19: logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch19.pt\n",
      "All 200 prompts processed.\n"
     ]
    }
   ],
   "source": [
    "run_logit_lens_batched(\n",
    "    lens=llama8b_fp,\n",
    "    prompts=nq_queries_200,\n",
    "    dataset_name=\"nq_query_200\",\n",
    "    model_name=\"llama8b_fp\",\n",
    "    save_dir=\"logs/lens_batches_norm/llama8b_fp/nq_200\",\n",
    "    proj_precision=None,\n",
    "    batch_size=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "638cf34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.load(\n",
    "    \"logs/lens_batches/nq_query_llama8b_fp_batch0.pt\",\n",
    "    weights_only=False \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f5d34f",
   "metadata": {},
   "source": [
    "### HF1BitLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "012916bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture detected: bitnet\n",
      "BitNet model (BitLinear layers).\n"
     ]
    }
   ],
   "source": [
    "llama8b_hf100b = LlamaPromptLens(\n",
    "    model_id=Models.HF100B.value,\n",
    "    apply_per_layer_norm=True,\n",
    "    include_subblocks=False,\n",
    "    device=\"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95050386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Saved batch 0: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch0.pt\n",
      "[✓] Saved batch 1: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch1.pt\n",
      "[✓] Saved batch 2: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch2.pt\n",
      "[✓] Saved batch 3: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch3.pt\n",
      "[✓] Saved batch 4: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch4.pt\n",
      "[✓] Saved batch 5: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch5.pt\n",
      "[✓] Saved batch 6: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch6.pt\n",
      "[✓] Saved batch 7: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch7.pt\n",
      "[✓] Saved batch 8: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch8.pt\n",
      "[✓] Saved batch 9: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch9.pt\n",
      "[✓] Saved batch 10: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch10.pt\n",
      "[✓] Saved batch 11: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch11.pt\n",
      "[✓] Saved batch 12: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch12.pt\n",
      "[✓] Saved batch 13: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch13.pt\n",
      "[✓] Saved batch 14: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch14.pt\n",
      "[✓] Saved batch 15: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch15.pt\n",
      "[✓] Saved batch 16: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch16.pt\n",
      "[✓] Saved batch 17: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch17.pt\n",
      "[✓] Saved batch 18: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch18.pt\n",
      "[✓] Saved batch 19: logs/lens_batches_norm/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch19.pt\n",
      "All 200 prompts processed.\n"
     ]
    }
   ],
   "source": [
    "run_logit_lens_batched(\n",
    "    lens=llama8b_hf100b,\n",
    "    prompts=nq_queries_200,\n",
    "    dataset_name=\"nq_query_200\",\n",
    "    model_name=\"llama8b_hf100b\",\n",
    "    save_dir=\"logs/lens_batches_norm/llama8b_hf100b/nq_200\",\n",
    "    proj_precision=None,\n",
    "    batch_size=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfbe3455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.load(\n",
    "    \"logs/lens_batches_raw/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch0.pt\",\n",
    "    weights_only=False \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6544c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>dataset</th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>layer_index</th>\n",
       "      <th>layer_name</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>target_ids</th>\n",
       "      <th>logits</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>19</td>\n",
       "      <td>where was the movie paint your wagon filmed</td>\n",
       "      <td>nq_query_200</td>\n",
       "      <td>128000</td>\n",
       "      <td>29</td>\n",
       "      <td>layer_28</td>\n",
       "      <td>[tensor(128000), tensor(2940), tensor(574), te...</td>\n",
       "      <td>[tensor(2940), tensor(574), tensor(279), tenso...</td>\n",
       "      <td>[[tensor(0.1147), tensor(0.3710), tensor(0.364...</td>\n",
       "      <td>[tensor(0), tensor(1), tensor(2), tensor(3), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>19</td>\n",
       "      <td>where was the movie paint your wagon filmed</td>\n",
       "      <td>nq_query_200</td>\n",
       "      <td>128000</td>\n",
       "      <td>30</td>\n",
       "      <td>layer_29</td>\n",
       "      <td>[tensor(128000), tensor(2940), tensor(574), te...</td>\n",
       "      <td>[tensor(2940), tensor(574), tensor(279), tenso...</td>\n",
       "      <td>[[tensor(0.0390), tensor(0.9849), tensor(0.869...</td>\n",
       "      <td>[tensor(0), tensor(1), tensor(2), tensor(3), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>19</td>\n",
       "      <td>where was the movie paint your wagon filmed</td>\n",
       "      <td>nq_query_200</td>\n",
       "      <td>128000</td>\n",
       "      <td>31</td>\n",
       "      <td>layer_30</td>\n",
       "      <td>[tensor(128000), tensor(2940), tensor(574), te...</td>\n",
       "      <td>[tensor(2940), tensor(574), tensor(279), tenso...</td>\n",
       "      <td>[[tensor(1.9523), tensor(4.6706), tensor(3.442...</td>\n",
       "      <td>[tensor(0), tensor(1), tensor(2), tensor(3), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>19</td>\n",
       "      <td>where was the movie paint your wagon filmed</td>\n",
       "      <td>nq_query_200</td>\n",
       "      <td>128000</td>\n",
       "      <td>32</td>\n",
       "      <td>layer_31</td>\n",
       "      <td>[tensor(128000), tensor(2940), tensor(574), te...</td>\n",
       "      <td>[tensor(2940), tensor(574), tensor(279), tenso...</td>\n",
       "      <td>[[tensor(2.4057), tensor(6.3078), tensor(4.542...</td>\n",
       "      <td>[tensor(0), tensor(1), tensor(2), tensor(3), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>19</td>\n",
       "      <td>where was the movie paint your wagon filmed</td>\n",
       "      <td>nq_query_200</td>\n",
       "      <td>128000</td>\n",
       "      <td>33</td>\n",
       "      <td>output</td>\n",
       "      <td>[tensor(128000), tensor(2940), tensor(574), te...</td>\n",
       "      <td>[tensor(2940), tensor(574), tensor(279), tenso...</td>\n",
       "      <td>[[tensor(3.4929), tensor(8.4756), tensor(5.696...</td>\n",
       "      <td>[tensor(0), tensor(1), tensor(2), tensor(3), t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     prompt_id                                  prompt_text       dataset  \\\n",
       "675         19  where was the movie paint your wagon filmed  nq_query_200   \n",
       "676         19  where was the movie paint your wagon filmed  nq_query_200   \n",
       "677         19  where was the movie paint your wagon filmed  nq_query_200   \n",
       "678         19  where was the movie paint your wagon filmed  nq_query_200   \n",
       "679         19  where was the movie paint your wagon filmed  nq_query_200   \n",
       "\n",
       "     vocab_size  layer_index layer_name  \\\n",
       "675      128000           29   layer_28   \n",
       "676      128000           30   layer_29   \n",
       "677      128000           31   layer_30   \n",
       "678      128000           32   layer_31   \n",
       "679      128000           33     output   \n",
       "\n",
       "                                             input_ids  \\\n",
       "675  [tensor(128000), tensor(2940), tensor(574), te...   \n",
       "676  [tensor(128000), tensor(2940), tensor(574), te...   \n",
       "677  [tensor(128000), tensor(2940), tensor(574), te...   \n",
       "678  [tensor(128000), tensor(2940), tensor(574), te...   \n",
       "679  [tensor(128000), tensor(2940), tensor(574), te...   \n",
       "\n",
       "                                            target_ids  \\\n",
       "675  [tensor(2940), tensor(574), tensor(279), tenso...   \n",
       "676  [tensor(2940), tensor(574), tensor(279), tenso...   \n",
       "677  [tensor(2940), tensor(574), tensor(279), tenso...   \n",
       "678  [tensor(2940), tensor(574), tensor(279), tenso...   \n",
       "679  [tensor(2940), tensor(574), tensor(279), tenso...   \n",
       "\n",
       "                                                logits  \\\n",
       "675  [[tensor(0.1147), tensor(0.3710), tensor(0.364...   \n",
       "676  [[tensor(0.0390), tensor(0.9849), tensor(0.869...   \n",
       "677  [[tensor(1.9523), tensor(4.6706), tensor(3.442...   \n",
       "678  [[tensor(2.4057), tensor(6.3078), tensor(4.542...   \n",
       "679  [[tensor(3.4929), tensor(8.4756), tensor(5.696...   \n",
       "\n",
       "                                              position  \n",
       "675  [tensor(0), tensor(1), tensor(2), tensor(3), t...  \n",
       "676  [tensor(0), tensor(1), tensor(2), tensor(3), t...  \n",
       "677  [tensor(0), tensor(1), tensor(2), tensor(3), t...  \n",
       "678  [tensor(0), tensor(1), tensor(2), tensor(3), t...  \n",
       "679  [tensor(0), tensor(1), tensor(2), tensor(3), t...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95400d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "data_fp = torch.load(\n",
    "    \"logs/lens_batches_raw/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch0.pt\",\n",
    "    weights_only=False \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cf0c359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>dataset</th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>layer_index</th>\n",
       "      <th>layer_name</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>target_ids</th>\n",
       "      <th>logits</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>19</td>\n",
       "      <td>where was the movie paint your wagon filmed</td>\n",
       "      <td>nq_query_200</td>\n",
       "      <td>128000</td>\n",
       "      <td>29</td>\n",
       "      <td>layer_28</td>\n",
       "      <td>[tensor(128000), tensor(2940), tensor(574), te...</td>\n",
       "      <td>[tensor(2940), tensor(574), tensor(279), tenso...</td>\n",
       "      <td>[[tensor(-0.1136), tensor(-0.9532), tensor(-0....</td>\n",
       "      <td>[tensor(0), tensor(1), tensor(2), tensor(3), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>19</td>\n",
       "      <td>where was the movie paint your wagon filmed</td>\n",
       "      <td>nq_query_200</td>\n",
       "      <td>128000</td>\n",
       "      <td>30</td>\n",
       "      <td>layer_29</td>\n",
       "      <td>[tensor(128000), tensor(2940), tensor(574), te...</td>\n",
       "      <td>[tensor(2940), tensor(574), tensor(279), tenso...</td>\n",
       "      <td>[[tensor(-0.6219), tensor(-0.4604), tensor(-0....</td>\n",
       "      <td>[tensor(0), tensor(1), tensor(2), tensor(3), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>19</td>\n",
       "      <td>where was the movie paint your wagon filmed</td>\n",
       "      <td>nq_query_200</td>\n",
       "      <td>128000</td>\n",
       "      <td>31</td>\n",
       "      <td>layer_30</td>\n",
       "      <td>[tensor(128000), tensor(2940), tensor(574), te...</td>\n",
       "      <td>[tensor(2940), tensor(574), tensor(279), tenso...</td>\n",
       "      <td>[[tensor(-3.5245), tensor(-1.0180), tensor(-3....</td>\n",
       "      <td>[tensor(0), tensor(1), tensor(2), tensor(3), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>19</td>\n",
       "      <td>where was the movie paint your wagon filmed</td>\n",
       "      <td>nq_query_200</td>\n",
       "      <td>128000</td>\n",
       "      <td>32</td>\n",
       "      <td>layer_31</td>\n",
       "      <td>[tensor(128000), tensor(2940), tensor(574), te...</td>\n",
       "      <td>[tensor(2940), tensor(574), tensor(279), tenso...</td>\n",
       "      <td>[[tensor(14.7182), tensor(17.2502), tensor(11....</td>\n",
       "      <td>[tensor(0), tensor(1), tensor(2), tensor(3), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>19</td>\n",
       "      <td>where was the movie paint your wagon filmed</td>\n",
       "      <td>nq_query_200</td>\n",
       "      <td>128000</td>\n",
       "      <td>33</td>\n",
       "      <td>output</td>\n",
       "      <td>[tensor(128000), tensor(2940), tensor(574), te...</td>\n",
       "      <td>[tensor(2940), tensor(574), tensor(279), tenso...</td>\n",
       "      <td>[[tensor(4.2573), tensor(7.2598), tensor(4.488...</td>\n",
       "      <td>[tensor(0), tensor(1), tensor(2), tensor(3), t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     prompt_id                                  prompt_text       dataset  \\\n",
       "675         19  where was the movie paint your wagon filmed  nq_query_200   \n",
       "676         19  where was the movie paint your wagon filmed  nq_query_200   \n",
       "677         19  where was the movie paint your wagon filmed  nq_query_200   \n",
       "678         19  where was the movie paint your wagon filmed  nq_query_200   \n",
       "679         19  where was the movie paint your wagon filmed  nq_query_200   \n",
       "\n",
       "     vocab_size  layer_index layer_name  \\\n",
       "675      128000           29   layer_28   \n",
       "676      128000           30   layer_29   \n",
       "677      128000           31   layer_30   \n",
       "678      128000           32   layer_31   \n",
       "679      128000           33     output   \n",
       "\n",
       "                                             input_ids  \\\n",
       "675  [tensor(128000), tensor(2940), tensor(574), te...   \n",
       "676  [tensor(128000), tensor(2940), tensor(574), te...   \n",
       "677  [tensor(128000), tensor(2940), tensor(574), te...   \n",
       "678  [tensor(128000), tensor(2940), tensor(574), te...   \n",
       "679  [tensor(128000), tensor(2940), tensor(574), te...   \n",
       "\n",
       "                                            target_ids  \\\n",
       "675  [tensor(2940), tensor(574), tensor(279), tenso...   \n",
       "676  [tensor(2940), tensor(574), tensor(279), tenso...   \n",
       "677  [tensor(2940), tensor(574), tensor(279), tenso...   \n",
       "678  [tensor(2940), tensor(574), tensor(279), tenso...   \n",
       "679  [tensor(2940), tensor(574), tensor(279), tenso...   \n",
       "\n",
       "                                                logits  \\\n",
       "675  [[tensor(-0.1136), tensor(-0.9532), tensor(-0....   \n",
       "676  [[tensor(-0.6219), tensor(-0.4604), tensor(-0....   \n",
       "677  [[tensor(-3.5245), tensor(-1.0180), tensor(-3....   \n",
       "678  [[tensor(14.7182), tensor(17.2502), tensor(11....   \n",
       "679  [[tensor(4.2573), tensor(7.2598), tensor(4.488...   \n",
       "\n",
       "                                              position  \n",
       "675  [tensor(0), tensor(1), tensor(2), tensor(3), t...  \n",
       "676  [tensor(0), tensor(1), tensor(2), tensor(3), t...  \n",
       "677  [tensor(0), tensor(1), tensor(2), tensor(3), t...  \n",
       "678  [tensor(0), tensor(1), tensor(2), tensor(3), t...  \n",
       "679  [tensor(0), tensor(1), tensor(2), tensor(3), t...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fp.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a4349c",
   "metadata": {},
   "source": [
    "# Softmax and Single Model Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0ff482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def extract_metrics(\n",
    "    data,\n",
    "    topk=[1, 5, 10, 20],\n",
    "    mask_ids=[128000, 128009],\n",
    "    device=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Extract top-k accuracy, log-probs, and NLL metrics from logit lens outputs.\n",
    "    Works with both a list of dicts and a pandas DataFrame (as produced by _run_logit_lens_batch).\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        data = data.to_dict(orient=\"records\")\n",
    "\n",
    "    results = []\n",
    "    all_k = sorted(set([1] + list(topk)))  # always include top-1\n",
    "    max_k = max(all_k)\n",
    "\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    mask_ids = torch.tensor(mask_ids, device=device)\n",
    "\n",
    "    for row in data:\n",
    "        logits = row[\"logits\"].to(device)  # [seq_len, vocab]\n",
    "        targets = row.get(\"target_ids\", None)\n",
    "        if targets is not None:\n",
    "            targets = targets.to(device)\n",
    "\n",
    "        # --- normalize shapes ---\n",
    "        if logits.dim() == 3 and logits.size(0) == 1:\n",
    "            logits = logits.squeeze(0)\n",
    "        if targets is not None and targets.dim() == 2 and targets.size(0) == 1:\n",
    "            targets = targets.squeeze(0)\n",
    "\n",
    "        seq_len, vocab_size = logits.shape\n",
    "\n",
    "        # --- stable softmax ---\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "        probs = log_probs.exp()\n",
    "\n",
    "        # --- top-k predictions ---\n",
    "        top_vals, top_idx = torch.topk(probs, max_k, dim=-1)\n",
    "        topk_preds = {k: top_idx[:, :k] for k in all_k}\n",
    "        topk_vals = {k: top_vals[:, :k] for k in all_k}\n",
    "\n",
    "        # --- metrics if targets exist ---\n",
    "        if targets is not None:\n",
    "            # mask out special tokens\n",
    "            mask = ~torch.isin(targets, mask_ids)\n",
    "\n",
    "            # target log probs and nll\n",
    "            target_logprobs = log_probs[torch.arange(seq_len, device=device), targets]\n",
    "            target_probs = target_logprobs.exp()\n",
    "            nll = -target_logprobs\n",
    "\n",
    "            # accuracy metrics\n",
    "            correct_topk, acc_topk = {}, {}\n",
    "            for k in all_k:\n",
    "                correct = (targets.unsqueeze(-1) == topk_preds[k]).any(dim=-1).int()\n",
    "                correct_topk[k] = correct\n",
    "                valid_correct = correct[mask]\n",
    "                acc_mean = valid_correct.float().mean().item() if valid_correct.numel() > 0 else float(\"nan\")\n",
    "                acc_topk[k] = {\"mean\": acc_mean, \"per_token\": correct.tolist()}\n",
    "\n",
    "            # monotonicity sanity check\n",
    "            for k1, k2 in zip(all_k[:-1], all_k[1:]):\n",
    "                assert (correct_topk[k1] <= correct_topk[k2]).all(), f\"Top-{k1} not subset of top-{k2}\"\n",
    "\n",
    "        else:\n",
    "            mask = target_probs = target_logprobs = nll = correct_topk = acc_topk = None\n",
    "\n",
    "        results.append({\n",
    "            \"prompt_id\": row.get(\"prompt_id\"),\n",
    "            \"prompt_text\": row.get(\"prompt_text\"),\n",
    "            \"layer_index\": row.get(\"layer_index\"),\n",
    "            \"layer_name\": row.get(\"layer_name\"),\n",
    "            \"dataset\": row.get(\"dataset\"),\n",
    "            \"vocab_size\": vocab_size,\n",
    "            \"input_ids\": row.get(\"input_ids\"),\n",
    "            \"position\": row.get(\"position\"),\n",
    "            \"targets\": targets,\n",
    "            \"mask\": mask,\n",
    "            \"logits\": logits.cpu(),\n",
    "            \"log_probs\": log_probs.cpu(),\n",
    "            \"probs\": probs.cpu(),\n",
    "            \"nll\": nll.cpu() if nll is not None else None,\n",
    "            \"target_probs\": target_probs.cpu() if target_probs is not None else None,\n",
    "            \"target_logprobs\": target_logprobs.cpu() if target_logprobs is not None else None,\n",
    "            \"topk_preds\": {k: v.cpu() for k, v in topk_preds.items()},\n",
    "            \"topk_vals\": {k: v.cpu() for k, v in topk_vals.items()},\n",
    "            \"correct_topk\": {k: v.cpu() for k, v in correct_topk.items()} if correct_topk else None,\n",
    "            \"acc_topk\": acc_topk,\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "batch_num = 19\n",
    "lens_type = \"norm\" # raw\n",
    "model_name = \"hf100b\" # \"fp\"\n",
    "\n",
    "# Load logits:\n",
    "model_logits = torch.load(\n",
    "    f\"logs/lens_batches_{lens_type}/llama8b_{model_name}/nq_200/nq_query_200_llama8b_{model_name}_batch{batch_num}.pt\",\n",
    "    weights_only=False \n",
    ")\n",
    "\n",
    "# Extract topk metrics:\n",
    "extracted_metrics = extract_metrics(model_logits)\n",
    "\n",
    "# Saving as a torch file:\n",
    "save_path = f\"logs/batch_probs_{lens_type}/llama8b_{model_name}/nq_200/nq_query_200_llama8b_{model_name}_batch{batch_num}.pt\"\n",
    "torch.save(extracted_metrics, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0074ac96",
   "metadata": {},
   "source": [
    "### [✓] Non-normalized Lens DONE\n",
    "### [✓] Normalized Lens DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046a7c07",
   "metadata": {},
   "source": [
    "# Comparing Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc987bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tok_a = AutoTokenizer.from_pretrained(Models.LAIN8B.value)\n",
    "tok_b = AutoTokenizer.from_pretrained(Models.HF100B.value)\n",
    "\n",
    "print(\"Tokenizer A vocab size:\", len(tok_a))\n",
    "print(\"Tokenizer B vocab size:\", len(tok_b))\n",
    "\n",
    "shared = set(tok_a.get_vocab().keys()) & set(tok_b.get_vocab().keys())\n",
    "unique_a = set(tok_a.get_vocab().keys()) - set(tok_b.get_vocab().keys())\n",
    "unique_b = set(tok_b.get_vocab().keys()) - set(tok_a.get_vocab().keys())\n",
    "\n",
    "print(f\"Shared tokens: {len(shared)}\")\n",
    "print(f\"Unique to A: {len(unique_a)} | Unique to B: {len(unique_b)}\")\n",
    "\n",
    "mismatches = []\n",
    "for token, id_a in tok_a.get_vocab().items():\n",
    "    id_b = tok_b.get_vocab().get(token, None)\n",
    "    if id_b is not None and id_a != id_b:\n",
    "        mismatches.append((token, id_a, id_b))\n",
    "    if len(mismatches) > 10:\n",
    "        break\n",
    "\n",
    "if not mismatches:\n",
    "    print(\"Token IDs aligned between tokenizers!\")\n",
    "else:\n",
    "    print(\"Some token ID mismatches found:\")\n",
    "    for token, id_a, id_b in mismatches[:5]:\n",
    "        print(f\"  '{token}': A={id_a}, B={id_b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dc2defd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def js_divergence_from_logprobs_nats(lp, lq, dim=-1, eps=1e-12, base=\"e\"):\n",
    "    \"\"\"\n",
    "    Jensen–Shannon divergence from log-probabilities.\n",
    "    More stable than using raw probabilities.\n",
    "    Returns divergence in nats (base-e) or bits (base-2).\n",
    "    \"\"\"\n",
    "    lp, lq = lp.float(), lq.float()\n",
    "    p, q = lp.exp(), lq.exp()\n",
    "    m = 0.5 * (p + q)\n",
    "\n",
    "    kl_pm = torch.sum(p * (lp - torch.log(m + eps)), dim=dim)\n",
    "    kl_qm = torch.sum(q * (lq - torch.log(m + eps)), dim=dim)\n",
    "    jsd = 0.5 * (kl_pm + kl_qm)\n",
    "\n",
    "    if base == \"2\":  # convert nats → bits JSD_bits ∈ [0, 1]\n",
    "        jsd = jsd / torch.log(torch.tensor(2.0))\n",
    "    return jsd\n",
    "\n",
    "def js_distance_from_logprobs(lp, lq, dim=-1, eps=1e-12, base=\"e\"):\n",
    "    return torch.sqrt(js_divergence_from_logprobs(lp, lq, dim=dim, eps=eps, base=base))\n",
    "\n",
    "def js_divergence_from_logprobs(lp, lq, dim=-1, eps=1e-12):\n",
    "    \"\"\"Numerically stable Jensen–Shannon divergence from log-probabilities.\"\"\"\n",
    "    lp, lq = lp.float(), lq.float()\n",
    "    p, q = lp.exp(), lq.exp()\n",
    "    m = 0.5 * (p + q)\n",
    "\n",
    "    # KL(P‖M) and KL(Q‖M) in log-space (using lp, lq)\n",
    "    kl_pm = torch.sum(p * (lp - torch.log(m + eps)), dim=dim)\n",
    "    kl_qm = torch.sum(q * (lq - torch.log(m + eps)), dim=dim)\n",
    "    return 0.5 * (kl_pm + kl_qm)\n",
    "\n",
    "def safe_mean(x):\n",
    "    \"\"\"Robust mean helper for torch tensors, lists, or None.\"\"\"\n",
    "    if x is None:\n",
    "        return None\n",
    "    if torch.is_tensor(x):\n",
    "        if x.numel() == 0:\n",
    "            return None\n",
    "        return x.float().mean().item()\n",
    "    if isinstance(x, (list, tuple, np.ndarray)):\n",
    "        if len(x) == 0:\n",
    "            return None\n",
    "        return float(np.nanmean(x))\n",
    "    return float(x)\n",
    "\n",
    "@torch.no_grad()\n",
    "def compare_metrics(\n",
    "    metrics_A,\n",
    "    metrics_B,\n",
    "    topk=(1, 5, 10, 20),\n",
    "    eps=1e-9,\n",
    "    mode=\"aligned\",  # \"aligned\" | \"position_final\"\n",
    "    mask_ids=[128000, 128009],\n",
    "    batch_num=0,\n",
    "    lens_type=\"raw\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare per-token probability distributions between two logit-lens runs.\n",
    "    Returns:\n",
    "        detailed: list[dict] per-prompt/layer\n",
    "        summary: pd.DataFrame aggregated per layer\n",
    "    \"\"\"\n",
    "    topk = sorted(set([1] + list(topk)))\n",
    "    max_k = max(topk)\n",
    "\n",
    "    # --- Pair rows ---\n",
    "    if mode == \"aligned\":\n",
    "        pairs = list(zip(metrics_A, metrics_B))\n",
    "    elif mode == \"position_final\":\n",
    "        def last_by_prompt(rows):\n",
    "            best = {}\n",
    "            for r in rows:\n",
    "                pid = r[\"prompt_id\"]\n",
    "                if pid not in best or r[\"layer_index\"] > best[pid][\"layer_index\"]:\n",
    "                    best[pid] = r\n",
    "            return best\n",
    "        last_A = last_by_prompt(metrics_A)\n",
    "        last_B = last_by_prompt(metrics_B)\n",
    "        common_pids = sorted(set(last_A) & set(last_B))\n",
    "        pairs = [(last_A[pid], last_B[pid]) for pid in common_pids]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown mode: {mode}\")\n",
    "\n",
    "    detailed = []\n",
    "\n",
    "    for row_A, row_B in pairs:\n",
    "        assert row_A[\"prompt_id\"] == row_B[\"prompt_id\"]\n",
    "        if mode == \"aligned\":\n",
    "            assert row_A[\"layer_index\"] == row_B[\"layer_index\"]\n",
    "\n",
    "        probs_A, probs_B = row_A[\"probs\"].float(), row_B[\"probs\"].float()\n",
    "        targets = row_A.get(\"targets\", None)\n",
    "\n",
    "        # --- Normalize ---\n",
    "        probs_A = probs_A / (probs_A.sum(dim=-1, keepdim=True) + eps)\n",
    "        probs_B = probs_B / (probs_B.sum(dim=-1, keepdim=True) + eps)\n",
    "\n",
    "        log_probs_A = torch.log(probs_A + eps)\n",
    "        log_probs_B = torch.log(probs_B + eps)\n",
    "\n",
    "        # --- Divergences over entire vocab ---\n",
    "        kl_ab = torch.sum(probs_A * (log_probs_A - log_probs_B), dim=-1)\n",
    "        kl_ba = torch.sum(probs_B * (log_probs_B - log_probs_A), dim=-1)\n",
    "        jsd_div = js_divergence_from_logprobs_nats(log_probs_A, log_probs_B)\n",
    "        jsd_dist = torch.sqrt(jsd_div)\n",
    "        vocab_tvd = 0.5 * torch.sum(torch.abs(probs_A - probs_B), dim=-1)\n",
    "\n",
    "        # --- Target token stats ---\n",
    "        if targets is not None:\n",
    "            targets = targets.to(probs_A.device)\n",
    "            mask = ~torch.isin(targets, torch.tensor(mask_ids, device=targets.device))\n",
    "            target_probs_A = probs_A[torch.arange(len(targets)), targets]\n",
    "            target_probs_B = probs_B[torch.arange(len(targets)), targets]\n",
    "            target_logprobs_A = torch.log(target_probs_A + eps)\n",
    "            target_logprobs_B = torch.log(target_probs_B + eps)\n",
    "            nll_A, nll_B = -target_logprobs_A, -target_logprobs_B\n",
    "            target_prob_diff = target_probs_A - target_probs_B\n",
    "            target_prob_tvd = 0.5 * torch.abs(target_probs_A - target_probs_B)\n",
    "            target_logprob_diff = target_logprobs_A - target_logprobs_B\n",
    "            nll_diff = nll_A - nll_B\n",
    "        else:\n",
    "            mask = None\n",
    "            target_probs_A = target_probs_B = None\n",
    "            target_logprobs_A = target_logprobs_B = None\n",
    "            nll_A = nll_B = None\n",
    "            target_prob_diff = target_prob_tvd = None\n",
    "            target_logprob_diff = nll_diff = None\n",
    "\n",
    "        # --- Top-K agreement ---\n",
    "        top_vals_A, top_idx_A = torch.topk(probs_A, max_k, dim=-1)\n",
    "        top_vals_B, top_idx_B = torch.topk(probs_B, max_k, dim=-1)\n",
    "\n",
    "        acc_A_topk, acc_B_topk, agree_topk, jaccard_topk = {}, {}, {}, {}\n",
    "        prob_mass_A_topk, prob_mass_B_topk, shared_mass_topk = {}, {}, {}\n",
    "        prob_overlap_topk, expected_agree_topk = {}, {}\n",
    "\n",
    "        for k in topk:\n",
    "            tkA, tkB = top_idx_A[:, :k], top_idx_B[:, :k]\n",
    "            tvA, tvB = top_vals_A[:, :k], top_vals_B[:, :k]\n",
    "\n",
    "            # Probability mass in top-k region\n",
    "            prob_mass_A_topk[k] = tvA.sum(dim=-1)\n",
    "            prob_mass_B_topk[k] = tvB.sum(dim=-1)\n",
    "\n",
    "            # Shared token set\n",
    "            inter_mask = (tkA.unsqueeze(-1) == tkB.unsqueeze(-2))\n",
    "            inter_counts = inter_mask.any(dim=-1).sum(dim=1).float()\n",
    "\n",
    "            # Jaccard + full agreement\n",
    "            jaccard_topk[k] = inter_counts / (2 * k - inter_counts + eps)\n",
    "            agree_topk[k] = (inter_counts == k).float()\n",
    "\n",
    "            # Shared probability mass\n",
    "            shared_mass = torch.zeros_like(prob_mass_A_topk[k])\n",
    "            for i in range(tkA.size(0)):\n",
    "                shared_tokens = torch.tensor(list(set(tkA[i].tolist()) & set(tkB[i].tolist())),\n",
    "                                            device=probs_A.device, dtype=torch.long)\n",
    "                if len(shared_tokens) > 0:\n",
    "                    shared_mass[i] = 0.5 * (\n",
    "                        probs_A[i, shared_tokens].sum() + probs_B[i, shared_tokens].sum()\n",
    "                    )\n",
    "            shared_mass_topk[k] = shared_mass\n",
    "\n",
    "            # Expected agreement baseline (prob mass overlap)\n",
    "            expected_agree_topk[k] = prob_mass_A_topk[k] * prob_mass_B_topk[k]\n",
    "\n",
    "            # Optional: overlap ratio\n",
    "            prob_overlap_topk[k] = shared_mass / (\n",
    "                0.5 * (prob_mass_A_topk[k] + prob_mass_B_topk[k]) + eps\n",
    "            )\n",
    "\n",
    "            # Accuracy for each model\n",
    "            if targets is not None:\n",
    "                acc_A = (targets.unsqueeze(-1) == tkA).any(dim=-1).float()\n",
    "                acc_B = (targets.unsqueeze(-1) == tkB).any(dim=-1).float()\n",
    "                if mask is not None:\n",
    "                    acc_A, acc_B = acc_A * mask, acc_B * mask\n",
    "                acc_A_topk[k] = acc_A\n",
    "                acc_B_topk[k] = acc_B\n",
    "            else:\n",
    "                acc_A_topk[k] = acc_B_topk[k] = None\n",
    "\n",
    "        detailed.append({\n",
    "            \"prompt_id\": row_A[\"prompt_id\"],\n",
    "            \"prompt_text\": row_A[\"prompt_text\"],\n",
    "            \"dataset\": row_A[\"dataset\"],\n",
    "            \"layer_index\": row_A[\"layer_index\"],\n",
    "            \"layer_name\": row_A[\"layer_name\"],\n",
    "            \"vocab_size\": row_A[\"vocab_size\"],\n",
    "            \"input_ids\": row_A.get(\"input_ids\"),\n",
    "            \"position\": row_A.get(\"position\"),\n",
    "            \"targets\": targets,\n",
    "            \"mask\": mask,\n",
    "            # Divergences\n",
    "            \"kl_ab\": kl_ab.detach().cpu(),\n",
    "            \"kl_ba\": kl_ba.detach().cpu(),\n",
    "            \"jsd_div\": jsd_div.detach().cpu(),\n",
    "            \"jsd_dist\": jsd_dist.detach().cpu(),\n",
    "            \"vocab_tvd\": vocab_tvd.detach().cpu(),\n",
    "            # Target-level\n",
    "            \"target_probs_A\": target_probs_A,\n",
    "            \"target_probs_B\": target_probs_B,\n",
    "            \"target_logprobs_A\": target_logprobs_A,\n",
    "            \"target_logprobs_B\": target_logprobs_B,\n",
    "            \"target_prob_diff\": target_prob_diff,\n",
    "            \"target_prob_tvd\": target_prob_tvd,\n",
    "            \"target_logprob_diff\": target_logprob_diff,\n",
    "            \"nll_A\": nll_A,\n",
    "            \"nll_B\": nll_B,\n",
    "            \"nll_diff\": nll_diff,\n",
    "            # Accuracy\n",
    "            \"acc_A_topk\": acc_A_topk,\n",
    "            \"acc_B_topk\": acc_B_topk,\n",
    "            \"agree_topk\": agree_topk,\n",
    "            \"jaccard_topk\": jaccard_topk,\n",
    "        })\n",
    "\n",
    "    # --- Aggregate summary ---\n",
    "    def build_summary(detailed, topk=(1, 5, 10, 20)):\n",
    "        \"\"\"Aggregate per-layer summary metrics from detailed compare_metrics output.\"\"\"\n",
    "        summary_rows = []\n",
    "        for r in detailed:\n",
    "            row_summary = {\n",
    "                \"prompt_id\": r[\"prompt_id\"],\n",
    "                \"layer_index\": r[\"layer_index\"],\n",
    "                \"layer_name\": r.get(\"layer_name\", None),\n",
    "                # Divergences\n",
    "                \"kl_ab\": safe_mean(r[\"kl_ab\"]),\n",
    "                \"kl_ba\": safe_mean(r[\"kl_ba\"]),\n",
    "                \"jsd_div\": safe_mean(r[\"jsd_div\"]),\n",
    "                \"jsd_dist\": safe_mean(r[\"jsd_dist\"]),\n",
    "                \"vocab_tvd\": safe_mean(r[\"vocab_tvd\"]),\n",
    "                # Target-level metrics\n",
    "                \"target_prob_diff\": safe_mean(r[\"target_prob_diff\"]),\n",
    "                \"target_prob_tvd\": safe_mean(r[\"target_prob_tvd\"]),\n",
    "                \"target_logprob_diff\": safe_mean(r[\"target_logprob_diff\"]),\n",
    "                \"nll_diff\": safe_mean(r[\"nll_diff\"]),\n",
    "            }\n",
    "            for k in topk:\n",
    "                row_summary[f\"acc_A@{k}\"] = safe_mean(r[\"acc_A_topk\"].get(k))\n",
    "                row_summary[f\"acc_B@{k}\"] = safe_mean(r[\"acc_B_topk\"].get(k))\n",
    "                row_summary[f\"agree@{k}\"] = safe_mean(r[\"agree_topk\"].get(k))\n",
    "                row_summary[f\"jaccard@{k}\"] = safe_mean(r[\"jaccard_topk\"].get(k))\n",
    "            summary_rows.append(row_summary)\n",
    "\n",
    "        summary = pd.DataFrame(summary_rows)\n",
    "        layer_summary = (\n",
    "            summary.groupby(\"layer_name\")\n",
    "                .mean(numeric_only=True)\n",
    "                .reset_index()\n",
    "                .sort_values(\"layer_name\")\n",
    "        )\n",
    "        return summary, layer_summary\n",
    "\n",
    "    # Call the summary builder\n",
    "    summary, layer_summary = build_summary(detailed, topk=topk)\n",
    "    # Save to parquet\n",
    "    summary.to_parquet(f\"logs/results_summary/batch_{lens_type}/nq_200/nq_query_200_batch{batch_num}.parquet\", index=False)\n",
    "    layer_summary.to_parquet(f\"logs/results_summary/batch_{lens_type}/nq_200/layer_wise_nq_query_200_batch{batch_num}.parquet\", index=False)\n",
    "\n",
    "    return detailed, summary, layer_summary\n",
    "\n",
    "\n",
    "lens_type = \"norm\"\n",
    "batch_num = 19\n",
    "\n",
    "# Load logits:\n",
    "probs_A = torch.load(\n",
    "    f\"logs/batch_probs_{lens_type}/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch{batch_num}.pt\",\n",
    "    weights_only=False \n",
    ")\n",
    "\n",
    "probs_B = torch.load(\n",
    "    f\"logs/batch_probs_{lens_type}/llama8b_hf100b/nq_200/nq_query_200_llama8b_hf100b_batch{batch_num}.pt\",\n",
    "    weights_only=False \n",
    ")\n",
    "\n",
    "# Extract comparison metrics:\n",
    "detailed, summary, layer_summary = compare_metrics(metrics_A=probs_A, metrics_B=probs_B, batch_num=batch_num, lens_type=lens_type)\n",
    "\n",
    "# Saving detailed as a torch file:\n",
    "save_path = f\"logs/topk_compare/batch_{lens_type}/nq_200/nq_query_200_batch{batch_num}.pt\"\n",
    "torch.save(detailed, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e597a578",
   "metadata": {},
   "source": [
    "### [✓] Non-normalized Comparison DONE\n",
    "### [✓] Normalized Comparison DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1056b20",
   "metadata": {},
   "source": [
    "# Comparison Results Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ea7621",
   "metadata": {},
   "source": [
    "## Heatmap Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31edafe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def pretty_layer_name(raw_name: str) -> str:\n",
    "    if raw_name == \"embed_tokens\":\n",
    "        return \"Embedding\"\n",
    "    elif raw_name.startswith(\"layers_\"):\n",
    "        idx = int(raw_name.split(\".\")[1])\n",
    "        return f\"Layer {idx+1}\"\n",
    "    elif raw_name in [\"output\", \"lm_head\"]:\n",
    "        return \"Output\"\n",
    "    else:\n",
    "        return raw_name\n",
    "\n",
    "\n",
    "def plot_heatmap(data, tokenizer, prompt_id=0, mask_ids=[128000, 128009],\n",
    "                     token_maxlen=20, x_per_col=0.9, y_per_row=0.35,\n",
    "                     metric=\"jsd_div\", color_map=\"coolwarm\", title=\"Jensen-Shannon divergence\",\n",
    "                     save_path=None):\n",
    "\n",
    "    rows = [r for r in data if r[\"prompt_id\"] == prompt_id]\n",
    "    rows = sorted(rows, key=lambda r: r[\"layer_index\"])\n",
    "\n",
    "    input_ids = torch.tensor(rows[0][\"input_ids\"])\n",
    "    target_ids = torch.tensor(rows[0][\"targets\"])\n",
    "\n",
    "    min_len = min(len(input_ids), len(target_ids))\n",
    "    input_ids = input_ids[:min_len]\n",
    "    target_ids = target_ids[:min_len]\n",
    "\n",
    "    keep_mask = torch.ones_like(target_ids, dtype=torch.bool)\n",
    "    for mid in mask_ids:\n",
    "        keep_mask &= (target_ids != mid)\n",
    "\n",
    "    input_ids = input_ids[keep_mask].tolist()\n",
    "    target_ids = target_ids[keep_mask].tolist()\n",
    "\n",
    "    def dec(tid):\n",
    "        s = tokenizer.decode([tid]).replace(\"\\n\", \" \")\n",
    "        return (s[:token_maxlen] + \"…\") if len(s) > token_maxlen else s\n",
    "\n",
    "    input_tokens  = [dec(tid) for tid in input_ids]\n",
    "    target_tokens = [dec(tid) for tid in target_ids]\n",
    "\n",
    "    matrix = torch.stack([r[metric][keep_mask] for r in rows]).cpu().numpy()\n",
    "    n_rows, n_cols = matrix.shape\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(max(6, n_cols * x_per_col), max(3, n_rows * y_per_row)),\n",
    "                           constrained_layout=True)\n",
    "\n",
    "    im = sns.heatmap(\n",
    "        matrix,\n",
    "        cmap=color_map,\n",
    "        cbar=True,\n",
    "        annot=True,          \n",
    "        xticklabels=False,   \n",
    "        yticklabels=[pretty_layer_name(r[\"layer_name\"]) for r in rows]\n",
    "    )\n",
    "\n",
    "    centers = np.arange(n_cols) + 0.5\n",
    "    ax.set_xlim(0, n_cols)              \n",
    "    ax.set_xticks(centers)\n",
    "    ax.set_xticklabels(input_tokens, rotation=90, ha=\"center\", fontsize=9)\n",
    "\n",
    "    ax_top = ax.twiny()\n",
    "    ax_top.set_xlim(ax.get_xlim())\n",
    "    ax_top.set_xticks(centers)\n",
    "    ax_top.set_xticklabels(target_tokens, rotation=90, ha=\"center\", fontsize=8)\n",
    "    ax_top.set_xlabel(\"Target tokens\")\n",
    "\n",
    "    ax.invert_yaxis()               \n",
    "    ax.set_aspect(\"auto\")      \n",
    "    ax.set_xlabel(\"Input tokens\")\n",
    "    ax.set_ylabel(\"Layers\")\n",
    "    ax.set_title(f\"{title} prompt {prompt_id}\" if title is not None  else \"\")\n",
    "\n",
    "    plt.subplots_adjust(bottom=0.25, top=0.85)\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3c4b8c",
   "metadata": {},
   "source": [
    "## Non-normalized Lens Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8711ed6c",
   "metadata": {},
   "source": [
    "## Normalized Lens Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logit-lens-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
