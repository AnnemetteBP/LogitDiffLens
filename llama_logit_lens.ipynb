{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e63148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datasets import load_dataset, DownloadMode\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from llama_wrapper import LlamaPromptLens, run_logit_lens_batched, run_logit_lens_autoregressive_batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21e09c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class Models(Enum):\n",
    "    LAIN8B = \"Models/LLaMA3Instruct\"\n",
    "    HF100B = \"Models/HF1BitLLM100Btokens\"\n",
    "\n",
    "\n",
    "class Names(Enum):\n",
    "    LAIN8B = \"Meta-Llama-3-8B-Instruct-fp\"\n",
    "    HF100B = \"Llama3-8B-1.58-100B-tokens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfff273",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(Models.LAIN8B.value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93dfb13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r'D:\\LogitLensData\\nq'\n",
    "\n",
    "destination_path = str(Path(filepath))\n",
    "nq_dataset = load_dataset(\n",
    "    'sentence-transformers/natural-questions',\n",
    "    split={\n",
    "        'train': 'train[:200]'\n",
    "    },\n",
    "    cache_dir=destination_path,\n",
    "    download_mode=DownloadMode.REUSE_DATASET_IF_EXISTS,\n",
    "    keep_in_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2f9ffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nq_queries = nq_dataset['train']['query']\n",
    "nq_answers = nq_dataset['train']['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "253c2a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nq_queries_200 = nq_queries[:200]\n",
    "nq_queries_400 = nq_queries[200:400]\n",
    "nq_queries_600 = nq_queries[400:600]\n",
    "nq_queries_800 = nq_queries[600:800]\n",
    "nq_queries_1000 = nq_queries[800:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9fd47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nq_queries_1 = nq_queries[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9d68e7",
   "metadata": {},
   "source": [
    "### LLaMA FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5b7865",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama8b_fp = LlamaPromptLens(\n",
    "    model_id=Models.LAIN8B.value,\n",
    "    normalization_mode=\"model\",\n",
    "    include_subblocks=False,\n",
    "    device=\"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c340bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logit_lens_batched(\n",
    "    lens=llama8b_fp,\n",
    "    prompts=nq_queries_200,\n",
    "    dataset_name=\"nq_200\",\n",
    "    model_name=\"llama8b_fp\",\n",
    "    save_dir=\"logs/lens_batches_norm\",\n",
    "    proj_precision=None,\n",
    "    batch_size=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638cf34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.load(\n",
    "    \"logs/lens_batches_norm/llama8b_fp/nq_200/nq_200_llama8b_fp_batch0.pt\",\n",
    "    weights_only=False \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26707424",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9b1d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"layer_name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfabce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm = torch.load(\n",
    "    \"logs/lens_batches_norm/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch0.pt\",\n",
    "    weights_only=False \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a734a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12765b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = torch.load(\n",
    "    \"logs/lens_batches_raw/llama8b_fp/nq_200/nq_query_200_llama8b_fp_batch0.pt\",\n",
    "    weights_only=False \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0bb8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f5d34f",
   "metadata": {},
   "source": [
    "### HF1BitLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "012916bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture detected: bitnet\n",
      "BitNet model (BitLinear layers).\n",
      "[ok] model.layers.0.self_attn.rotary_emb is LlamaRotaryEmbedding (old API)\n",
      "[ok] model.layers.1.self_attn.rotary_emb is LlamaRotaryEmbedding (old API)\n",
      "[ok] model.layers.2.self_attn.rotary_emb is LlamaRotaryEmbedding (old API)\n",
      "[ok] model.layers.3.self_attn.rotary_emb is LlamaRotaryEmbedding (old API)\n",
      "[ok] model.layers.4.self_attn.rotary_emb is LlamaRotaryEmbedding (old API)\n",
      "[ok] model.layers.5.self_attn.rotary_emb is LlamaRotaryEmbedding (old API)\n",
      "[ok] model.layers.6.self_attn.rotary_emb is LlamaRotaryEmbedding (old API)\n",
      "[ok] model.layers.7.self_attn.rotary_emb is LlamaRotaryEmbedding (old API)\n",
      "[ok] model.layers.8.self_attn.rotary_emb is LlamaRotaryEmbedding (old API)\n",
      "[ok] model.layers.9.self_attn.rotary_emb is LlamaRotaryEmbedding (old API)\n",
      "[ok] model.layers.10.self_attn.rotary_emb is LlamaRotaryEmbedding (old API)\n",
      "[ok] model.layers.11.self_attn.rotary_emb is LlamaRotaryEmbedding (old API)\n",
      "[ok] model.layers.12.self_attn.rotary_emb is LlamaRotaryEmbedding (old API)\n",
      "[ok] model.layers.13.self_attn.rotary_emb is LlamaRotaryEmbedding (old API)\n",
      "[ok] model.layers.14.self_attn.rotary_emb is LlamaRotaryEmbedding (old API)\n",
      "[ok] model.layers.15.self_attn.rotary_emb is LlamaRotaryEmbedding (old API)\n",
      "[ok] model.layers.16.self_attn.rotary_emb is LlamaRotaryEmbedding (old API)\n",
      "[ok] model.layers.17.self_attn.rotary_emb is LlamaRotaryEmbedding (old API)\n",
      "[ok] model.layers.18.self_attn.rotary_emb is LlamaRotaryEmbedding (old API)\n",
      "[ok] model.layers.19.self_attn.rotary_emb is LlamaRotaryEmbedding (old API)\n",
      "[ok] model.layers.20.self_attn.rotary_emb is LlamaRotaryEmbedding (old API)\n",
      "[ok] model.layers.21.self_attn.rotary_emb is LlamaRotaryEmbedding (old API)\n",
      "[ok] model.layers.22.self_attn.rotary_emb is LlamaRotaryEmbedding (old API)\n",
      "[ok] model.layers.23.self_attn.rotary_emb is LlamaRotaryEmbedding (old API)\n",
      "[ok] model.layers.24.self_attn.rotary_emb is LlamaRotaryEmbedding (old API)\n",
      "[ok] model.layers.25.self_attn.rotary_emb is LlamaRotaryEmbedding (old API)\n",
      "[ok] model.layers.26.self_attn.rotary_emb is LlamaRotaryEmbedding (old API)\n",
      "[ok] model.layers.27.self_attn.rotary_emb is LlamaRotaryEmbedding (old API)\n",
      "[ok] model.layers.28.self_attn.rotary_emb is LlamaRotaryEmbedding (old API)\n",
      "[ok] model.layers.29.self_attn.rotary_emb is LlamaRotaryEmbedding (old API)\n",
      "[ok] model.layers.30.self_attn.rotary_emb is LlamaRotaryEmbedding (old API)\n",
      "[ok] model.layers.31.self_attn.rotary_emb is LlamaRotaryEmbedding (old API)\n"
     ]
    }
   ],
   "source": [
    "llama8b_hf100b = LlamaPromptLens(\n",
    "    model_id=Models.HF100B.value,\n",
    "    normalization_mode=\"model\",\n",
    "    include_subblocks=False,\n",
    "    device=\"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95050386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] RoPE is a callable module — using legacy API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Saved batch 0: logs/lens_batches_norm/nq_200_llama8b_hf100b_batch0.pt\n",
      "[info] RoPE is a callable module — using legacy API.\n",
      "[✓] Saved batch 1: logs/lens_batches_norm/nq_200_llama8b_hf100b_batch1.pt\n",
      "[info] RoPE is a callable module — using legacy API.\n",
      "[✓] Saved batch 2: logs/lens_batches_norm/nq_200_llama8b_hf100b_batch2.pt\n",
      "[info] RoPE is a callable module — using legacy API.\n",
      "[✓] Saved batch 3: logs/lens_batches_norm/nq_200_llama8b_hf100b_batch3.pt\n",
      "[info] RoPE is a callable module — using legacy API.\n",
      "[✓] Saved batch 4: logs/lens_batches_norm/nq_200_llama8b_hf100b_batch4.pt\n",
      "[info] RoPE is a callable module — using legacy API.\n",
      "[✓] Saved batch 5: logs/lens_batches_norm/nq_200_llama8b_hf100b_batch5.pt\n",
      "[info] RoPE is a callable module — using legacy API.\n",
      "[✓] Saved batch 6: logs/lens_batches_norm/nq_200_llama8b_hf100b_batch6.pt\n",
      "[info] RoPE is a callable module — using legacy API.\n",
      "[✓] Saved batch 7: logs/lens_batches_norm/nq_200_llama8b_hf100b_batch7.pt\n",
      "[info] RoPE is a callable module — using legacy API.\n",
      "[✓] Saved batch 8: logs/lens_batches_norm/nq_200_llama8b_hf100b_batch8.pt\n",
      "[info] RoPE is a callable module — using legacy API.\n",
      "[✓] Saved batch 9: logs/lens_batches_norm/nq_200_llama8b_hf100b_batch9.pt\n",
      "All 200 prompts processed.\n"
     ]
    }
   ],
   "source": [
    "run_logit_lens_batched(\n",
    "    lens=llama8b_hf100b,\n",
    "    prompts=nq_queries_200,\n",
    "    dataset_name=\"nq_200\",\n",
    "    model_name=\"llama8b_hf100b\",\n",
    "    save_dir=\"logs/lens_batches_norm\",\n",
    "    proj_precision=None,\n",
    "    batch_size=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfbe3455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.load(\n",
    "    \"logs/lens_batches_norm/nq_200_llama8b_hf100b_batch0.pt\",\n",
    "    weights_only=False \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d42db43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>dataset</th>\n",
       "      <th>layer_index</th>\n",
       "      <th>layer_name</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>target_ids</th>\n",
       "      <th>logits</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>when did richmond last play in a preliminary f...</td>\n",
       "      <td>nq_200</td>\n",
       "      <td>0</td>\n",
       "      <td>embed_tokens</td>\n",
       "      <td>[tensor(128000), tensor(9493), tensor(1550), t...</td>\n",
       "      <td>[tensor(9493), tensor(1550), tensor(9257), ten...</td>\n",
       "      <td>[[tensor(-0.0092), tensor(-0.0074), tensor(-0....</td>\n",
       "      <td>[tensor(0), tensor(1), tensor(2), tensor(3), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>when did richmond last play in a preliminary f...</td>\n",
       "      <td>nq_200</td>\n",
       "      <td>1</td>\n",
       "      <td>layer.0</td>\n",
       "      <td>[tensor(128000), tensor(9493), tensor(1550), t...</td>\n",
       "      <td>[tensor(9493), tensor(1550), tensor(9257), ten...</td>\n",
       "      <td>[[tensor(0.0964), tensor(-0.1299), tensor(-0.0...</td>\n",
       "      <td>[tensor(0), tensor(1), tensor(2), tensor(3), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>when did richmond last play in a preliminary f...</td>\n",
       "      <td>nq_200</td>\n",
       "      <td>2</td>\n",
       "      <td>layer.1</td>\n",
       "      <td>[tensor(128000), tensor(9493), tensor(1550), t...</td>\n",
       "      <td>[tensor(9493), tensor(1550), tensor(9257), ten...</td>\n",
       "      <td>[[tensor(0.1694), tensor(-0.1995), tensor(-0.0...</td>\n",
       "      <td>[tensor(0), tensor(1), tensor(2), tensor(3), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>when did richmond last play in a preliminary f...</td>\n",
       "      <td>nq_200</td>\n",
       "      <td>3</td>\n",
       "      <td>layer.2</td>\n",
       "      <td>[tensor(128000), tensor(9493), tensor(1550), t...</td>\n",
       "      <td>[tensor(9493), tensor(1550), tensor(9257), ten...</td>\n",
       "      <td>[[tensor(0.1379), tensor(-0.3599), tensor(-0.0...</td>\n",
       "      <td>[tensor(0), tensor(1), tensor(2), tensor(3), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>when did richmond last play in a preliminary f...</td>\n",
       "      <td>nq_200</td>\n",
       "      <td>4</td>\n",
       "      <td>layer.3</td>\n",
       "      <td>[tensor(128000), tensor(9493), tensor(1550), t...</td>\n",
       "      <td>[tensor(9493), tensor(1550), tensor(9257), ten...</td>\n",
       "      <td>[[tensor(0.1394), tensor(-0.3552), tensor(-0.0...</td>\n",
       "      <td>[tensor(0), tensor(1), tensor(2), tensor(3), t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prompt_id                                        prompt_text dataset  \\\n",
       "0          0  when did richmond last play in a preliminary f...  nq_200   \n",
       "1          0  when did richmond last play in a preliminary f...  nq_200   \n",
       "2          0  when did richmond last play in a preliminary f...  nq_200   \n",
       "3          0  when did richmond last play in a preliminary f...  nq_200   \n",
       "4          0  when did richmond last play in a preliminary f...  nq_200   \n",
       "\n",
       "   layer_index    layer_name  \\\n",
       "0            0  embed_tokens   \n",
       "1            1       layer.0   \n",
       "2            2       layer.1   \n",
       "3            3       layer.2   \n",
       "4            4       layer.3   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [tensor(128000), tensor(9493), tensor(1550), t...   \n",
       "1  [tensor(128000), tensor(9493), tensor(1550), t...   \n",
       "2  [tensor(128000), tensor(9493), tensor(1550), t...   \n",
       "3  [tensor(128000), tensor(9493), tensor(1550), t...   \n",
       "4  [tensor(128000), tensor(9493), tensor(1550), t...   \n",
       "\n",
       "                                          target_ids  \\\n",
       "0  [tensor(9493), tensor(1550), tensor(9257), ten...   \n",
       "1  [tensor(9493), tensor(1550), tensor(9257), ten...   \n",
       "2  [tensor(9493), tensor(1550), tensor(9257), ten...   \n",
       "3  [tensor(9493), tensor(1550), tensor(9257), ten...   \n",
       "4  [tensor(9493), tensor(1550), tensor(9257), ten...   \n",
       "\n",
       "                                              logits  \\\n",
       "0  [[tensor(-0.0092), tensor(-0.0074), tensor(-0....   \n",
       "1  [[tensor(0.0964), tensor(-0.1299), tensor(-0.0...   \n",
       "2  [[tensor(0.1694), tensor(-0.1995), tensor(-0.0...   \n",
       "3  [[tensor(0.1379), tensor(-0.3599), tensor(-0.0...   \n",
       "4  [[tensor(0.1394), tensor(-0.3552), tensor(-0.0...   \n",
       "\n",
       "                                            position  \n",
       "0  [tensor(0), tensor(1), tensor(2), tensor(3), t...  \n",
       "1  [tensor(0), tensor(1), tensor(2), tensor(3), t...  \n",
       "2  [tensor(0), tensor(1), tensor(2), tensor(3), t...  \n",
       "3  [tensor(0), tensor(1), tensor(2), tensor(3), t...  \n",
       "4  [tensor(0), tensor(1), tensor(2), tensor(3), t...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6544c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>dataset</th>\n",
       "      <th>layer_index</th>\n",
       "      <th>layer_name</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>target_ids</th>\n",
       "      <th>logits</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>19</td>\n",
       "      <td>where was the movie paint your wagon filmed</td>\n",
       "      <td>nq_200</td>\n",
       "      <td>29</td>\n",
       "      <td>layer.28</td>\n",
       "      <td>[tensor(128000), tensor(2940), tensor(574), te...</td>\n",
       "      <td>[tensor(2940), tensor(574), tensor(279), tenso...</td>\n",
       "      <td>[[tensor(0.4070), tensor(0.5046), tensor(0.424...</td>\n",
       "      <td>[tensor(0), tensor(1), tensor(2), tensor(3), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>19</td>\n",
       "      <td>where was the movie paint your wagon filmed</td>\n",
       "      <td>nq_200</td>\n",
       "      <td>30</td>\n",
       "      <td>layer.29</td>\n",
       "      <td>[tensor(128000), tensor(2940), tensor(574), te...</td>\n",
       "      <td>[tensor(2940), tensor(574), tensor(279), tenso...</td>\n",
       "      <td>[[tensor(0.3380), tensor(1.0720), tensor(0.846...</td>\n",
       "      <td>[tensor(0), tensor(1), tensor(2), tensor(3), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>19</td>\n",
       "      <td>where was the movie paint your wagon filmed</td>\n",
       "      <td>nq_200</td>\n",
       "      <td>31</td>\n",
       "      <td>layer.30</td>\n",
       "      <td>[tensor(128000), tensor(2940), tensor(574), te...</td>\n",
       "      <td>[tensor(2940), tensor(574), tensor(279), tenso...</td>\n",
       "      <td>[[tensor(1.3205), tensor(2.6418), tensor(1.766...</td>\n",
       "      <td>[tensor(0), tensor(1), tensor(2), tensor(3), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>19</td>\n",
       "      <td>where was the movie paint your wagon filmed</td>\n",
       "      <td>nq_200</td>\n",
       "      <td>32</td>\n",
       "      <td>layer.31</td>\n",
       "      <td>[tensor(128000), tensor(2940), tensor(574), te...</td>\n",
       "      <td>[tensor(2940), tensor(574), tensor(279), tenso...</td>\n",
       "      <td>[[tensor(0.6804), tensor(1.5972), tensor(0.924...</td>\n",
       "      <td>[tensor(0), tensor(1), tensor(2), tensor(3), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>19</td>\n",
       "      <td>where was the movie paint your wagon filmed</td>\n",
       "      <td>nq_200</td>\n",
       "      <td>33</td>\n",
       "      <td>output</td>\n",
       "      <td>[tensor(128000), tensor(2940), tensor(574), te...</td>\n",
       "      <td>[tensor(2940), tensor(574), tensor(279), tenso...</td>\n",
       "      <td>[[tensor(3.4929), tensor(8.4756), tensor(5.696...</td>\n",
       "      <td>[tensor(0), tensor(1), tensor(2), tensor(3), t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     prompt_id                                  prompt_text dataset  \\\n",
       "675         19  where was the movie paint your wagon filmed  nq_200   \n",
       "676         19  where was the movie paint your wagon filmed  nq_200   \n",
       "677         19  where was the movie paint your wagon filmed  nq_200   \n",
       "678         19  where was the movie paint your wagon filmed  nq_200   \n",
       "679         19  where was the movie paint your wagon filmed  nq_200   \n",
       "\n",
       "     layer_index layer_name  \\\n",
       "675           29   layer.28   \n",
       "676           30   layer.29   \n",
       "677           31   layer.30   \n",
       "678           32   layer.31   \n",
       "679           33     output   \n",
       "\n",
       "                                             input_ids  \\\n",
       "675  [tensor(128000), tensor(2940), tensor(574), te...   \n",
       "676  [tensor(128000), tensor(2940), tensor(574), te...   \n",
       "677  [tensor(128000), tensor(2940), tensor(574), te...   \n",
       "678  [tensor(128000), tensor(2940), tensor(574), te...   \n",
       "679  [tensor(128000), tensor(2940), tensor(574), te...   \n",
       "\n",
       "                                            target_ids  \\\n",
       "675  [tensor(2940), tensor(574), tensor(279), tenso...   \n",
       "676  [tensor(2940), tensor(574), tensor(279), tenso...   \n",
       "677  [tensor(2940), tensor(574), tensor(279), tenso...   \n",
       "678  [tensor(2940), tensor(574), tensor(279), tenso...   \n",
       "679  [tensor(2940), tensor(574), tensor(279), tenso...   \n",
       "\n",
       "                                                logits  \\\n",
       "675  [[tensor(0.4070), tensor(0.5046), tensor(0.424...   \n",
       "676  [[tensor(0.3380), tensor(1.0720), tensor(0.846...   \n",
       "677  [[tensor(1.3205), tensor(2.6418), tensor(1.766...   \n",
       "678  [[tensor(0.6804), tensor(1.5972), tensor(0.924...   \n",
       "679  [[tensor(3.4929), tensor(8.4756), tensor(5.696...   \n",
       "\n",
       "                                              position  \n",
       "675  [tensor(0), tensor(1), tensor(2), tensor(3), t...  \n",
       "676  [tensor(0), tensor(1), tensor(2), tensor(3), t...  \n",
       "677  [tensor(0), tensor(1), tensor(2), tensor(3), t...  \n",
       "678  [tensor(0), tensor(1), tensor(2), tensor(3), t...  \n",
       "679  [tensor(0), tensor(1), tensor(2), tensor(3), t...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58c359cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['embed_tokens', 'layer.0', 'layer.1', 'layer.2', 'layer.3',\n",
       "       'layer.4', 'layer.5', 'layer.6', 'layer.7', 'layer.8', 'layer.9',\n",
       "       'layer.10', 'layer.11', 'layer.12', 'layer.13', 'layer.14',\n",
       "       'layer.15', 'layer.16', 'layer.17', 'layer.18', 'layer.19',\n",
       "       'layer.20', 'layer.21', 'layer.22', 'layer.23', 'layer.24',\n",
       "       'layer.25', 'layer.26', 'layer.27', 'layer.28', 'layer.29',\n",
       "       'layer.30', 'layer.31', 'output'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"layer_name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29d5ab53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model uses internal RoPE via position_ids → old API confirmed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'old'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def verify_rope_api(lens):\n",
    "    model = lens.model\n",
    "    device = next(model.parameters()).device\n",
    "    block = model.base_model.layers[0]\n",
    "\n",
    "    # --- Handle both standard and BitNet projections ---\n",
    "    attn = block.self_attn\n",
    "    q_proj = getattr(attn, \"q_proj\", None)\n",
    "\n",
    "    if q_proj is not None:\n",
    "        # For normal Linear layers\n",
    "        hidden_size = getattr(q_proj, \"in_features\", None)\n",
    "        if hidden_size is None and hasattr(q_proj, \"weight\"):\n",
    "            hidden_size = q_proj.weight.shape[-1]\n",
    "    else:\n",
    "        # fallback if q_proj missing or BitLinear-like\n",
    "        hidden_size = getattr(block, \"hidden_size\", 4096)\n",
    "\n",
    "    x = torch.randn(1, 4, hidden_size, device=device)\n",
    "\n",
    "    try:\n",
    "        # --- Try new API (position_embeddings) ---\n",
    "        rotary_emb = block.self_attn.rotary_emb\n",
    "        cos, sin = rotary_emb(torch.arange(4, device=device).unsqueeze(0))\n",
    "        _ = block.self_attn(x, position_embeddings=(cos, sin))\n",
    "        print(\"Model accepts external position_embeddings → new RoPE API confirmed.\")\n",
    "        return \"new\"\n",
    "\n",
    "    except TypeError:\n",
    "        try:\n",
    "            # --- Fallback: old API ---\n",
    "            position_ids = torch.arange(4, device=device).unsqueeze(0)\n",
    "            _ = block.self_attn(x, position_ids=position_ids)\n",
    "            print(\"Model uses internal RoPE via position_ids → old API confirmed.\")\n",
    "            return \"old\"\n",
    "        except Exception as e:\n",
    "            print(\"RoPE test failed:\", e)\n",
    "            return \"error\"\n",
    "\n",
    "# Run the test\n",
    "verify_rope_api(llama8b_hf100b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a4349c",
   "metadata": {},
   "source": [
    "# Softmax and Single Model Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ff482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def extract_metrics(\n",
    "    data,\n",
    "    topk=[1, 5, 10, 20],\n",
    "    mask_ids=[128000, 128009],\n",
    "    device=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Extract top-k accuracy, log-probs, and NLL metrics from logit lens outputs.\n",
    "    Works with both a list of dicts and a pandas DataFrame (as produced by _run_logit_lens_batch).\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        data = data.to_dict(orient=\"records\")\n",
    "\n",
    "    results = []\n",
    "    all_k = sorted(set([1] + list(topk)))  # always include top-1\n",
    "    max_k = max(all_k)\n",
    "\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    mask_ids = torch.tensor(mask_ids, device=device)\n",
    "\n",
    "    for row in data:\n",
    "        logits = row[\"logits\"].to(device)  # [seq_len, vocab]\n",
    "        targets = row.get(\"target_ids\", None)\n",
    "        if targets is not None:\n",
    "            targets = targets.to(device)\n",
    "\n",
    "        # --- normalize shapes ---\n",
    "        if logits.dim() == 3 and logits.size(0) == 1:\n",
    "            logits = logits.squeeze(0)\n",
    "        if targets is not None and targets.dim() == 2 and targets.size(0) == 1:\n",
    "            targets = targets.squeeze(0)\n",
    "\n",
    "        seq_len, vocab_size = logits.shape\n",
    "\n",
    "        # --- stable softmax ---\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "        probs = log_probs.exp()\n",
    "\n",
    "        # --- top-k predictions ---\n",
    "        top_vals, top_idx = torch.topk(probs, max_k, dim=-1)\n",
    "        topk_preds = {k: top_idx[:, :k] for k in all_k}\n",
    "        topk_vals = {k: top_vals[:, :k] for k in all_k}\n",
    "\n",
    "        # --- metrics if targets exist ---\n",
    "        if targets is not None:\n",
    "            # mask out special tokens\n",
    "            mask = ~torch.isin(targets, mask_ids)\n",
    "\n",
    "            # target log probs and nll\n",
    "            target_logprobs = log_probs[torch.arange(seq_len, device=device), targets]\n",
    "            target_probs = target_logprobs.exp()\n",
    "            nll = -target_logprobs\n",
    "\n",
    "            # accuracy metrics\n",
    "            correct_topk, acc_topk = {}, {}\n",
    "            for k in all_k:\n",
    "                correct = (targets.unsqueeze(-1) == topk_preds[k]).any(dim=-1).int()\n",
    "                correct_topk[k] = correct\n",
    "                valid_correct = correct[mask]\n",
    "                acc_mean = valid_correct.float().mean().item() if valid_correct.numel() > 0 else float(\"nan\")\n",
    "                acc_topk[k] = {\"mean\": acc_mean, \"per_token\": correct.tolist()}\n",
    "\n",
    "            # monotonicity sanity check\n",
    "            for k1, k2 in zip(all_k[:-1], all_k[1:]):\n",
    "                assert (correct_topk[k1] <= correct_topk[k2]).all(), f\"Top-{k1} not subset of top-{k2}\"\n",
    "\n",
    "        else:\n",
    "            mask = target_probs = target_logprobs = nll = correct_topk = acc_topk = None\n",
    "\n",
    "        results.append({\n",
    "            \"prompt_id\": row.get(\"prompt_id\"),\n",
    "            \"prompt_text\": row.get(\"prompt_text\"),\n",
    "            \"layer_index\": row.get(\"layer_index\"),\n",
    "            \"layer_name\": row.get(\"layer_name\"),\n",
    "            \"dataset\": row.get(\"dataset\"),\n",
    "            \"vocab_size\": vocab_size,\n",
    "            \"input_ids\": row.get(\"input_ids\"),\n",
    "            \"position\": row.get(\"position\"),\n",
    "            \"targets\": targets,\n",
    "            \"mask\": mask,\n",
    "            \"logits\": logits.cpu(),\n",
    "            \"log_probs\": log_probs.cpu(),\n",
    "            \"probs\": probs.cpu(),\n",
    "            \"nll\": nll.cpu() if nll is not None else None,\n",
    "            \"target_probs\": target_probs.cpu() if target_probs is not None else None,\n",
    "            \"target_logprobs\": target_logprobs.cpu() if target_logprobs is not None else None,\n",
    "            \"topk_preds\": {k: v.cpu() for k, v in topk_preds.items()},\n",
    "            \"topk_vals\": {k: v.cpu() for k, v in topk_vals.items()},\n",
    "            \"correct_topk\": {k: v.cpu() for k, v in correct_topk.items()} if correct_topk else None,\n",
    "            \"acc_topk\": acc_topk,\n",
    "        })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a50e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_num = 11\n",
    "lens_type = \"norm\" # raw, \"unitrms\", \"norm\", for sublock-level: \"subraw\", \"subnorm\", \"subunitrms\"\n",
    "model_name = \"hf100b\" # \"fp\", \"hf100b\"\n",
    "\n",
    "# Load logits:\n",
    "model_logits = torch.load(\n",
    "    f\"logs/lens_batches_{lens_type}/llama8b_{model_name}/nq_200/nq_query_200_llama8b_{model_name}_batch{batch_num}.pt\",\n",
    "    weights_only=False \n",
    ")\n",
    "\n",
    "# Extract topk metrics:\n",
    "extracted_metrics = extract_metrics(model_logits)\n",
    "\n",
    "# Saving as a torch file:\n",
    "save_path = f\"logs/batch_probs_{lens_type}/llama8b_{model_name}/nq_200/nq_query_200_llama8b_{model_name}_batch{batch_num}.pt\"\n",
    "torch.save(extracted_metrics, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32cead8",
   "metadata": {},
   "source": [
    "#### Subblocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a7bbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "batch_num = 0\n",
    "lens_type = \"norm\" # raw, \"unitrms\", \"norm\"\n",
    "model_name = \"hf100b\" # \"fp\", \"hf100b\"\n",
    "\n",
    "# Load logits:\n",
    "model_logits = torch.load(\n",
    "    f\"logs/lens_batches_subblocks/sub_{lens_type}/nq_queries_1_llama8b_{model_name}_batch{batch_num}.pt\",\n",
    "    weights_only=False \n",
    ")\n",
    "\n",
    "# Extract topk metrics:\n",
    "extracted_metrics = extract_metrics(model_logits)\n",
    "\n",
    "# Saving as a torch file:\n",
    "save_path = f\"logs/lens_batches_subblocks/sub_probs/{lens_type}_nq_queries_1_llama8b_{model_name}_batch{batch_num}.pt\"\n",
    "torch.save(extracted_metrics, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0074ac96",
   "metadata": {},
   "source": [
    "### [✓] Non-normalized Lens DONE\n",
    "### [✓] Normalized Lens DONE\n",
    "### [✓] Final RMS Normalized Lens DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046a7c07",
   "metadata": {},
   "source": [
    "# Comparing Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc987bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tok_a = AutoTokenizer.from_pretrained(Models.LAIN8B.value)\n",
    "tok_b = AutoTokenizer.from_pretrained(Models.HF100B.value)\n",
    "\n",
    "print(\"Tokenizer A vocab size:\", len(tok_a))\n",
    "print(\"Tokenizer B vocab size:\", len(tok_b))\n",
    "\n",
    "shared = set(tok_a.get_vocab().keys()) & set(tok_b.get_vocab().keys())\n",
    "unique_a = set(tok_a.get_vocab().keys()) - set(tok_b.get_vocab().keys())\n",
    "unique_b = set(tok_b.get_vocab().keys()) - set(tok_a.get_vocab().keys())\n",
    "\n",
    "print(f\"Shared tokens: {len(shared)}\")\n",
    "print(f\"Unique to A: {len(unique_a)} | Unique to B: {len(unique_b)}\")\n",
    "\n",
    "mismatches = []\n",
    "for token, id_a in tok_a.get_vocab().items():\n",
    "    id_b = tok_b.get_vocab().get(token, None)\n",
    "    if id_b is not None and id_a != id_b:\n",
    "        mismatches.append((token, id_a, id_b))\n",
    "    if len(mismatches) > 10:\n",
    "        break\n",
    "\n",
    "if not mismatches:\n",
    "    print(\"Token IDs aligned between tokenizers!\")\n",
    "else:\n",
    "    print(\"Some token ID mismatches found:\")\n",
    "    for token, id_a, id_b in mismatches[:5]:\n",
    "        print(f\"  '{token}': A={id_a}, B={id_b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc2defd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def js_divergence_from_logprobs_nats(lp, lq, dim=-1, eps=1e-12, base=\"e\"):\n",
    "    \"\"\"\n",
    "    Jensen–Shannon divergence from log-probabilities.\n",
    "    More stable than using raw probabilities.\n",
    "    Returns divergence in nats (base-e) or bits (base-2).\n",
    "    \"\"\"\n",
    "    lp, lq = lp.float(), lq.float()\n",
    "    p, q = lp.exp(), lq.exp()\n",
    "    m = 0.5 * (p + q)\n",
    "\n",
    "    kl_pm = torch.sum(p * (lp - torch.log(m + eps)), dim=dim)\n",
    "    kl_qm = torch.sum(q * (lq - torch.log(m + eps)), dim=dim)\n",
    "    jsd = 0.5 * (kl_pm + kl_qm)\n",
    "\n",
    "    if base == \"2\":  # convert nats → bits JSD_bits ∈ [0, 1]\n",
    "        jsd = jsd / torch.log(torch.tensor(2.0))\n",
    "    return jsd\n",
    "\n",
    "def js_distance_from_logprobs(lp, lq, dim=-1, eps=1e-12, base=\"e\"):\n",
    "    return torch.sqrt(js_divergence_from_logprobs(lp, lq, dim=dim, eps=eps, base=base))\n",
    "\n",
    "def js_divergence_from_logprobs(lp, lq, dim=-1, eps=1e-12):\n",
    "    \"\"\"Numerically stable Jensen–Shannon divergence from log-probabilities.\"\"\"\n",
    "    lp, lq = lp.float(), lq.float()\n",
    "    p, q = lp.exp(), lq.exp()\n",
    "    m = 0.5 * (p + q)\n",
    "\n",
    "    # KL(P‖M) and KL(Q‖M) in log-space (using lp, lq)\n",
    "    kl_pm = torch.sum(p * (lp - torch.log(m + eps)), dim=dim)\n",
    "    kl_qm = torch.sum(q * (lq - torch.log(m + eps)), dim=dim)\n",
    "    return 0.5 * (kl_pm + kl_qm)\n",
    "\n",
    "def safe_mean(x):\n",
    "    \"\"\"Robust mean helper for torch tensors, lists, or None.\"\"\"\n",
    "    if x is None:\n",
    "        return None\n",
    "    if torch.is_tensor(x):\n",
    "        if x.numel() == 0:\n",
    "            return None\n",
    "        return x.float().mean().item()\n",
    "    if isinstance(x, (list, tuple, np.ndarray)):\n",
    "        if len(x) == 0:\n",
    "            return None\n",
    "        return float(np.nanmean(x))\n",
    "    return float(x)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def compare_metrics(\n",
    "    metrics_A,\n",
    "    metrics_B,\n",
    "    topk=(1, 5, 10, 20),\n",
    "    eps=1e-9,\n",
    "    mode=\"aligned\",  # \"aligned\" | \"position_final\"\n",
    "    mask_ids=[128000, 128009],\n",
    "    batch_num=0,\n",
    "    lens_type=\"raw\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare per-token probability distributions between two logit-lens runs.\n",
    "    Uses log_probs and probs already provided by extract_metrics().\n",
    "    \"\"\"\n",
    "\n",
    "    topk = sorted(set([1] + list(topk)))\n",
    "    max_k = max(topk)\n",
    "\n",
    "    # --- Pair rows ---\n",
    "    if mode == \"aligned\":\n",
    "        pairs = list(zip(metrics_A, metrics_B))\n",
    "    elif mode == \"position_final\":\n",
    "        def last_by_prompt(rows):\n",
    "            best = {}\n",
    "            for r in rows:\n",
    "                pid = r[\"prompt_id\"]\n",
    "                if pid not in best or r[\"layer_index\"] > best[pid][\"layer_index\"]:\n",
    "                    best[pid] = r\n",
    "            return best\n",
    "        last_A = last_by_prompt(metrics_A)\n",
    "        last_B = last_by_prompt(metrics_B)\n",
    "        common_pids = sorted(set(last_A) & set(last_B))\n",
    "        pairs = [(last_A[pid], last_B[pid]) for pid in common_pids]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown mode: {mode}\")\n",
    "\n",
    "    detailed = []\n",
    "\n",
    "    for row_A, row_B in pairs:\n",
    "        assert row_A[\"prompt_id\"] == row_B[\"prompt_id\"]\n",
    "        if mode == \"aligned\":\n",
    "            assert row_A[\"layer_index\"] == row_B[\"layer_index\"]\n",
    "\n",
    "        probs_A, probs_B = row_A[\"probs\"].float(), row_B[\"probs\"].float()\n",
    "        log_probs_A, log_probs_B = row_A[\"log_probs\"].float(), row_B[\"log_probs\"].float()\n",
    "        targets = row_A.get(\"targets\", None)\n",
    "\n",
    "        # --- Divergences (JSD, KL, TVD) ---\n",
    "        kl_ab = torch.sum(probs_A * (log_probs_A - log_probs_B), dim=-1)\n",
    "        kl_ba = torch.sum(probs_B * (log_probs_B - log_probs_A), dim=-1)\n",
    "        m = 0.5 * (probs_A + probs_B)\n",
    "        jsd_div = 0.5 * (\n",
    "            torch.sum(probs_A * (log_probs_A - torch.log(m + eps)), dim=-1)\n",
    "            + torch.sum(probs_B * (log_probs_B - torch.log(m + eps)), dim=-1)\n",
    "        )\n",
    "        jsd_dist = torch.sqrt(jsd_div)\n",
    "        vocab_tvd = 0.5 * torch.sum(torch.abs(probs_A - probs_B), dim=-1)\n",
    "\n",
    "        # Entropy (“heat”)\n",
    "        heat_A = -torch.sum(probs_A * log_probs_A, dim=-1)\n",
    "        heat_B = -torch.sum(probs_B * log_probs_B, dim=-1)\n",
    "\n",
    "        # IQR (distribution spread)\n",
    "        sorted_A, _ = torch.sort(probs_A, dim=-1)\n",
    "        sorted_B, _ = torch.sort(probs_B, dim=-1)\n",
    "        q25_A = torch.quantile(sorted_A, 0.25, dim=-1)\n",
    "        q75_A = torch.quantile(sorted_A, 0.75, dim=-1)\n",
    "        q25_B = torch.quantile(sorted_B, 0.25, dim=-1)\n",
    "        q75_B = torch.quantile(sorted_B, 0.75, dim=-1)\n",
    "        iqr_A = q75_A - q25_A\n",
    "        iqr_B = q75_B - q25_B\n",
    "\n",
    "        # Marginals\n",
    "        marginal_stats = {\n",
    "            \"mean_A\": probs_A.mean(dim=-1),\n",
    "            \"mean_B\": probs_B.mean(dim=-1),\n",
    "            \"max_A\": probs_A.max(dim=-1).values,\n",
    "            \"max_B\": probs_B.max(dim=-1).values,\n",
    "            \"min_A\": probs_A.min(dim=-1).values,\n",
    "            \"min_B\": probs_B.min(dim=-1).values,\n",
    "        }\n",
    "\n",
    "        # --- Target token stats ---\n",
    "        if targets is not None:\n",
    "            targets = targets.to(probs_A.device)\n",
    "            mask = ~torch.isin(targets, torch.tensor(mask_ids, device=targets.device))\n",
    "            target_probs_A = probs_A[torch.arange(len(targets)), targets]\n",
    "            target_probs_B = probs_B[torch.arange(len(targets)), targets]\n",
    "            target_logprobs_A = log_probs_A[torch.arange(len(targets)), targets]\n",
    "            target_logprobs_B = log_probs_B[torch.arange(len(targets)), targets]\n",
    "            nll_A, nll_B = -target_logprobs_A, -target_logprobs_B\n",
    "            target_prob_diff = target_probs_A - target_probs_B\n",
    "            target_prob_tvd = 0.5 * torch.abs(target_probs_A - target_probs_B)\n",
    "            target_logprob_diff = target_logprobs_A - target_logprobs_B\n",
    "            nll_diff = nll_A - nll_B\n",
    "        else:\n",
    "            mask = None\n",
    "            target_probs_A = target_probs_B = None\n",
    "            target_logprobs_A = target_logprobs_B = None\n",
    "            nll_A = nll_B = None\n",
    "            target_prob_diff = target_prob_tvd = None\n",
    "            target_logprob_diff = nll_diff = None\n",
    "\n",
    "        # --- Top-K metrics ---\n",
    "        top_vals_A, top_idx_A = torch.topk(probs_A, max_k, dim=-1)\n",
    "        top_vals_B, top_idx_B = torch.topk(probs_B, max_k, dim=-1)\n",
    "\n",
    "        acc_A_topk, acc_B_topk, agree_topk, jaccard_topk = {}, {}, {}, {}\n",
    "        prob_mass_A_topk, prob_mass_B_topk, shared_mass_topk = {}, {}, {}\n",
    "        prob_overlap_topk, prob_mass_overlap_topk = {}, {}\n",
    "        tail_mass_A_topk, tail_mass_B_topk = {}, {}\n",
    "\n",
    "        for k in topk:\n",
    "            tkA, tkB = top_idx_A[:, :k], top_idx_B[:, :k]\n",
    "            tvA, tvB = top_vals_A[:, :k], top_vals_B[:, :k]\n",
    "\n",
    "            # Probability mass and tails\n",
    "            prob_mass_A_topk[k] = tvA.sum(dim=-1)\n",
    "            prob_mass_B_topk[k] = tvB.sum(dim=-1)\n",
    "            tail_mass_A_topk[k] = 1.0 - prob_mass_A_topk[k]\n",
    "            tail_mass_B_topk[k] = 1.0 - prob_mass_B_topk[k]\n",
    "\n",
    "            # Shared token set\n",
    "            inter_mask = (tkA.unsqueeze(-1) == tkB.unsqueeze(-2))\n",
    "            inter_counts = inter_mask.any(dim=-1).sum(dim=1).float()\n",
    "            jaccard_topk[k] = inter_counts / (2 * k - inter_counts + eps)\n",
    "            agree_topk[k] = (inter_counts == k).float()\n",
    "\n",
    "            shared_mass = torch.zeros_like(prob_mass_A_topk[k])\n",
    "            for i in range(tkA.size(0)):\n",
    "                shared_tokens = torch.tensor(\n",
    "                    list(set(tkA[i].tolist()) & set(tkB[i].tolist())),\n",
    "                    device=probs_A.device,\n",
    "                    dtype=torch.long,\n",
    "                )\n",
    "                if len(shared_tokens) > 0:\n",
    "                    shared_mass[i] = 0.5 * (\n",
    "                        probs_A[i, shared_tokens].sum()\n",
    "                        + probs_B[i, shared_tokens].sum()\n",
    "                    )\n",
    "            shared_mass_topk[k] = shared_mass\n",
    "\n",
    "            # Probability overlaps\n",
    "            prob_mass_overlap_topk[k] = prob_mass_A_topk[k] * prob_mass_B_topk[k]\n",
    "            prob_overlap_topk[k] = shared_mass / (\n",
    "                0.5 * (prob_mass_A_topk[k] + prob_mass_B_topk[k]) + eps\n",
    "            )\n",
    "\n",
    "            # Accuracy\n",
    "            if targets is not None:\n",
    "                acc_A = (targets.unsqueeze(-1) == tkA).any(dim=-1).float()\n",
    "                acc_B = (targets.unsqueeze(-1) == tkB).any(dim=-1).float()\n",
    "                if mask is not None:\n",
    "                    acc_A, acc_B = acc_A * mask, acc_B * mask\n",
    "                acc_A_topk[k] = acc_A\n",
    "                acc_B_topk[k] = acc_B\n",
    "            else:\n",
    "                acc_A_topk[k] = acc_B_topk[k] = None\n",
    "\n",
    "        # --- Collect detailed record ---\n",
    "        detailed.append({\n",
    "            \"prompt_id\": row_A[\"prompt_id\"],\n",
    "            \"prompt_text\": row_A[\"prompt_text\"],\n",
    "            \"dataset\": row_A[\"dataset\"],\n",
    "            \"layer_index\": row_A[\"layer_index\"],\n",
    "            \"layer_name\": row_A[\"layer_name\"],\n",
    "            \"vocab_size\": row_A[\"vocab_size\"],\n",
    "            \"input_ids\": row_A.get(\"input_ids\"),\n",
    "            \"position\": row_A.get(\"position\"),\n",
    "            \"targets\": targets,\n",
    "            \"mask\": mask,\n",
    "            # Divergences\n",
    "            \"kl_ab\": kl_ab.detach().cpu(),\n",
    "            \"kl_ba\": kl_ba.detach().cpu(),\n",
    "            \"jsd_div\": jsd_div.detach().cpu(),\n",
    "            \"jsd_dist\": jsd_dist.detach().cpu(),\n",
    "            \"vocab_tvd\": vocab_tvd.detach().cpu(),\n",
    "            # Heat, IQR, Marginals\n",
    "            \"heat_A\": heat_A.detach().cpu(),\n",
    "            \"heat_B\": heat_B.detach().cpu(),\n",
    "            \"iqr_A\": iqr_A.detach().cpu(),\n",
    "            \"iqr_B\": iqr_B.detach().cpu(),\n",
    "            \"mean_prob_A\": marginal_stats[\"mean_A\"].detach().cpu(),\n",
    "            \"mean_prob_B\": marginal_stats[\"mean_B\"].detach().cpu(),\n",
    "            \"max_prob_A\": marginal_stats[\"max_A\"].detach().cpu(),\n",
    "            \"max_prob_B\": marginal_stats[\"max_B\"].detach().cpu(),\n",
    "            \"min_prob_A\": marginal_stats[\"min_A\"].detach().cpu(),\n",
    "            \"min_prob_B\": marginal_stats[\"min_B\"].detach().cpu(),\n",
    "            # Target-level\n",
    "            \"target_probs_A\": target_probs_A,\n",
    "            \"target_probs_B\": target_probs_B,\n",
    "            \"target_logprobs_A\": target_logprobs_A,\n",
    "            \"target_logprobs_B\": target_logprobs_B,\n",
    "            \"target_prob_diff\": target_prob_diff,\n",
    "            \"target_prob_tvd\": target_prob_tvd,\n",
    "            \"target_logprob_diff\": target_logprob_diff,\n",
    "            \"nll_A\": nll_A,\n",
    "            \"nll_B\": nll_B,\n",
    "            \"nll_diff\": nll_diff,\n",
    "            # Top-k and overlap metrics\n",
    "            \"acc_A_topk\": acc_A_topk,\n",
    "            \"acc_B_topk\": acc_B_topk,\n",
    "            \"agree_topk\": agree_topk,\n",
    "            \"jaccard_topk\": jaccard_topk,\n",
    "            \"prob_mass_A_topk\": prob_mass_A_topk,\n",
    "            \"prob_mass_B_topk\": prob_mass_B_topk,\n",
    "            \"tail_mass_A_topk\": tail_mass_A_topk,\n",
    "            \"tail_mass_B_topk\": tail_mass_B_topk,\n",
    "            \"shared_mass_topk\": shared_mass_topk,\n",
    "            \"prob_overlap_topk\": prob_overlap_topk,\n",
    "            \"prob_mass_overlap_topk\": prob_mass_overlap_topk,\n",
    "        })\n",
    "\n",
    "    # --- Aggregate summary ---\n",
    "    def build_summary(detailed, topk=(1, 5, 10, 20)):\n",
    "        summary_rows = []\n",
    "        for r in detailed:\n",
    "            row_summary = {\n",
    "                \"prompt_id\": r[\"prompt_id\"],\n",
    "                \"layer_index\": r[\"layer_index\"],\n",
    "                \"layer_name\": r.get(\"layer_name\", None),\n",
    "                # Divergences\n",
    "                \"kl_ab\": safe_mean(r[\"kl_ab\"]),\n",
    "                \"kl_ba\": safe_mean(r[\"kl_ba\"]),\n",
    "                \"jsd_div\": safe_mean(r[\"jsd_div\"]),\n",
    "                \"jsd_dist\": safe_mean(r[\"jsd_dist\"]),\n",
    "                \"vocab_tvd\": safe_mean(r[\"vocab_tvd\"]),\n",
    "                # Heat/IQR/Marginals\n",
    "                \"heat_A\": safe_mean(r[\"heat_A\"]),\n",
    "                \"heat_B\": safe_mean(r[\"heat_B\"]),\n",
    "                \"iqr_A\": safe_mean(r[\"iqr_A\"]),\n",
    "                \"iqr_B\": safe_mean(r[\"iqr_B\"]),\n",
    "                \"mean_prob_A\": safe_mean(r[\"mean_prob_A\"]),\n",
    "                \"mean_prob_B\": safe_mean(r[\"mean_prob_B\"]),\n",
    "                \"max_prob_A\": safe_mean(r[\"max_prob_A\"]),\n",
    "                \"max_prob_B\": safe_mean(r[\"max_prob_B\"]),\n",
    "                \"min_prob_A\": safe_mean(r[\"min_prob_A\"]),\n",
    "                \"min_prob_B\": safe_mean(r[\"min_prob_B\"]),\n",
    "                # Target-level\n",
    "                \"target_prob_diff\": safe_mean(r[\"target_prob_diff\"]),\n",
    "                \"target_prob_tvd\": safe_mean(r[\"target_prob_tvd\"]),\n",
    "                \"target_logprob_diff\": safe_mean(r[\"target_logprob_diff\"]),\n",
    "                \"nll_diff\": safe_mean(r[\"nll_diff\"]),\n",
    "            }\n",
    "            for k in topk:\n",
    "                row_summary[f\"acc_A@{k}\"] = safe_mean(r[\"acc_A_topk\"].get(k))\n",
    "                row_summary[f\"acc_B@{k}\"] = safe_mean(r[\"acc_B_topk\"].get(k))\n",
    "                row_summary[f\"agree@{k}\"] = safe_mean(r[\"agree_topk\"].get(k))\n",
    "                row_summary[f\"jaccard@{k}\"] = safe_mean(r[\"jaccard_topk\"].get(k))\n",
    "                row_summary[f\"prob_overlap@{k}\"] = safe_mean(r[\"prob_overlap_topk\"].get(k))\n",
    "                row_summary[f\"prob_mass_overlap@{k}\"] = safe_mean(r[\"prob_mass_overlap_topk\"].get(k))\n",
    "                row_summary[f\"tail_A@{k}\"] = safe_mean(r[\"tail_mass_A_topk\"].get(k))\n",
    "                row_summary[f\"tail_B@{k}\"] = safe_mean(r[\"tail_mass_B_topk\"].get(k))\n",
    "            summary_rows.append(row_summary)\n",
    "\n",
    "        summary = pd.DataFrame(summary_rows)\n",
    "        layer_summary = (\n",
    "            summary.groupby(\"layer_name\")\n",
    "            .mean(numeric_only=True)\n",
    "            .reset_index()\n",
    "            .sort_values(\"layer_name\")\n",
    "        )\n",
    "        return summary, layer_summary\n",
    "\n",
    "\n",
    "    # Call the summary builder\n",
    "    summary, layer_summary = build_summary(detailed, topk=topk)\n",
    "    # Save to parquet\n",
    "    summary.to_parquet(f\"logs/results_summary/batch_{lens_type}/nq_200/nq_query_200_batch{batch_num}.parquet\", index=False)\n",
    "    layer_summary.to_parquet(f\"logs/results_summary/batch_{lens_type}/nq_200/layer_wise_nq_query_200_batch{batch_num}.parquet\", index=False)\n",
    "\n",
    "    return detailed, summary, layer_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0515e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def js_divergence_from_logprobs_nats(lp, lq, dim=-1, eps=1e-12, base=\"e\"):\n",
    "    \"\"\"\n",
    "    Jensen–Shannon divergence from log-probabilities.\n",
    "    More stable than using raw probabilities.\n",
    "    Returns divergence in nats (base-e) or bits (base-2).\n",
    "    \"\"\"\n",
    "    lp, lq = lp.float(), lq.float()\n",
    "    p, q = lp.exp(), lq.exp()\n",
    "    m = 0.5 * (p + q)\n",
    "\n",
    "    kl_pm = torch.sum(p * (lp - torch.log(m + eps)), dim=dim)\n",
    "    kl_qm = torch.sum(q * (lq - torch.log(m + eps)), dim=dim)\n",
    "    jsd = 0.5 * (kl_pm + kl_qm)\n",
    "\n",
    "    if base == \"2\":  # convert nats → bits JSD_bits ∈ [0, 1]\n",
    "        jsd = jsd / torch.log(torch.tensor(2.0))\n",
    "    return jsd\n",
    "\n",
    "def js_distance_from_logprobs(lp, lq, dim=-1, eps=1e-12, base=\"e\"):\n",
    "    return torch.sqrt(js_divergence_from_logprobs(lp, lq, dim=dim, eps=eps, base=base))\n",
    "\n",
    "def js_divergence_from_logprobs(lp, lq, dim=-1, eps=1e-12):\n",
    "    \"\"\"Numerically stable Jensen–Shannon divergence from log-probabilities.\"\"\"\n",
    "    lp, lq = lp.float(), lq.float()\n",
    "    p, q = lp.exp(), lq.exp()\n",
    "    m = 0.5 * (p + q)\n",
    "\n",
    "    # KL(P‖M) and KL(Q‖M) in log-space (using lp, lq)\n",
    "    kl_pm = torch.sum(p * (lp - torch.log(m + eps)), dim=dim)\n",
    "    kl_qm = torch.sum(q * (lq - torch.log(m + eps)), dim=dim)\n",
    "    return 0.5 * (kl_pm + kl_qm)\n",
    "\n",
    "def safe_mean(x):\n",
    "    \"\"\"Robust mean helper for torch tensors, lists, or None.\"\"\"\n",
    "    if x is None:\n",
    "        return None\n",
    "    if torch.is_tensor(x):\n",
    "        if x.numel() == 0:\n",
    "            return None\n",
    "        return x.float().mean().item()\n",
    "    if isinstance(x, (list, tuple, np.ndarray)):\n",
    "        if len(x) == 0:\n",
    "            return None\n",
    "        return float(np.nanmean(x))\n",
    "    return float(x)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def compare_metrics_with_softmax(\n",
    "    metrics_A,\n",
    "    metrics_B,\n",
    "    topk=(1, 5, 10, 20),\n",
    "    eps=1e-9,\n",
    "    mode=\"aligned\",  # \"aligned\" | \"position_final\"\n",
    "    mask_ids=[128000, 128009],\n",
    "    batch_num=0,\n",
    "    lens_type=\"raw\",\n",
    "    device=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Unified metric comparison for logit-lens runs.\n",
    "\n",
    "    Takes raw logits (and optional targets) and computes:\n",
    "    - Log-probs, probs, entropy (heat)\n",
    "    - KL, JSD, TVD divergences\n",
    "    - Top-k accuracy, tail mass, probability overlaps\n",
    "    - Marginals (mean, max, min probs)\n",
    "    - IQR of probability distribution\n",
    "    \"\"\"\n",
    "\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    topk = sorted(set([1] + list(topk)))\n",
    "    max_k = max(topk)\n",
    "\n",
    "    # --- Pair rows ---\n",
    "    if mode == \"aligned\":\n",
    "        pairs = list(zip(metrics_A, metrics_B))\n",
    "    elif mode == \"position_final\":\n",
    "        def last_by_prompt(rows):\n",
    "            best = {}\n",
    "            for r in rows:\n",
    "                pid = r[\"prompt_id\"]\n",
    "                if pid not in best or r[\"layer_index\"] > best[pid][\"layer_index\"]:\n",
    "                    best[pid] = r\n",
    "            return best\n",
    "\n",
    "        last_A = last_by_prompt(metrics_A)\n",
    "        last_B = last_by_prompt(metrics_B)\n",
    "        common_pids = sorted(set(last_A) & set(last_B))\n",
    "        pairs = [(last_A[pid], last_B[pid]) for pid in common_pids]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown mode: {mode}\")\n",
    "\n",
    "    detailed = []\n",
    "\n",
    "    for row_A, row_B in pairs:\n",
    "        assert row_A[\"prompt_id\"] == row_B[\"prompt_id\"]\n",
    "        if mode == \"aligned\":\n",
    "            assert row_A[\"layer_index\"] == row_B[\"layer_index\"]\n",
    "\n",
    "        # --- Move logits to device and compute softmax/log-softmax ---\n",
    "        logits_A = row_A[\"logits\"].to(device).float()\n",
    "        logits_B = row_B[\"logits\"].to(device).float()\n",
    "        log_probs_A = F.log_softmax(logits_A, dim=-1)\n",
    "        log_probs_B = F.log_softmax(logits_B, dim=-1)\n",
    "        probs_A = log_probs_A.exp()\n",
    "        probs_B = log_probs_B.exp()\n",
    "\n",
    "        targets = row_A.get(\"target_ids\", None)\n",
    "        if targets is not None:\n",
    "            targets = targets.to(device)\n",
    "\n",
    "        # --- Divergences ---\n",
    "        kl_ab = torch.sum(probs_A * (log_probs_A - log_probs_B), dim=-1)\n",
    "        kl_ba = torch.sum(probs_B * (log_probs_B - log_probs_A), dim=-1)\n",
    "        m = 0.5 * (probs_A + probs_B)\n",
    "        jsd_div = 0.5 * (\n",
    "            torch.sum(probs_A * (log_probs_A - torch.log(m + eps)), dim=-1)\n",
    "            + torch.sum(probs_B * (log_probs_B - torch.log(m + eps)), dim=-1)\n",
    "        )\n",
    "        jsd_dist = torch.sqrt(jsd_div)\n",
    "        vocab_tvd = 0.5 * torch.sum(torch.abs(probs_A - probs_B), dim=-1)\n",
    "\n",
    "        # --- Entropy (\"heat\") ---\n",
    "        heat_A = -torch.sum(probs_A * log_probs_A, dim=-1)\n",
    "        heat_B = -torch.sum(probs_B * log_probs_B, dim=-1)\n",
    "\n",
    "        # --- IQR and Marginals ---\n",
    "        sorted_A, _ = torch.sort(probs_A, dim=-1)\n",
    "        sorted_B, _ = torch.sort(probs_B, dim=-1)\n",
    "        q25_A = torch.quantile(sorted_A, 0.25, dim=-1)\n",
    "        q75_A = torch.quantile(sorted_A, 0.75, dim=-1)\n",
    "        q25_B = torch.quantile(sorted_B, 0.25, dim=-1)\n",
    "        q75_B = torch.quantile(sorted_B, 0.75, dim=-1)\n",
    "        iqr_A = q75_A - q25_A\n",
    "        iqr_B = q75_B - q25_B\n",
    "        mean_prob_A = probs_A.mean(dim=-1)\n",
    "        mean_prob_B = probs_B.mean(dim=-1)\n",
    "        max_prob_A = probs_A.max(dim=-1).values\n",
    "        max_prob_B = probs_B.max(dim=-1).values\n",
    "        min_prob_A = probs_A.min(dim=-1).values\n",
    "        min_prob_B = probs_B.min(dim=-1).values\n",
    "\n",
    "        # --- Target token stats ---\n",
    "        if targets is not None:\n",
    "            mask = ~torch.isin(targets, torch.tensor(mask_ids, device=targets.device))\n",
    "            target_probs_A = probs_A[torch.arange(len(targets)), targets]\n",
    "            target_probs_B = probs_B[torch.arange(len(targets)), targets]\n",
    "            target_logprobs_A = log_probs_A[torch.arange(len(targets)), targets]\n",
    "            target_logprobs_B = log_probs_B[torch.arange(len(targets)), targets]\n",
    "            nll_A, nll_B = -target_logprobs_A, -target_logprobs_B\n",
    "            target_prob_diff = target_probs_A - target_probs_B\n",
    "            target_prob_tvd = 0.5 * torch.abs(target_probs_A - target_probs_B)\n",
    "            target_logprob_diff = target_logprobs_A - target_logprobs_B\n",
    "            nll_diff = nll_A - nll_B\n",
    "        else:\n",
    "            mask = None\n",
    "            target_probs_A = target_probs_B = None\n",
    "            target_logprobs_A = target_logprobs_B = None\n",
    "            nll_A = nll_B = None\n",
    "            target_prob_diff = target_prob_tvd = None\n",
    "            target_logprob_diff = nll_diff = None\n",
    "\n",
    "        # --- Top-K metrics ---\n",
    "        top_vals_A, top_idx_A = torch.topk(probs_A, max_k, dim=-1)\n",
    "        top_vals_B, top_idx_B = torch.topk(probs_B, max_k, dim=-1)\n",
    "\n",
    "        acc_A_topk, acc_B_topk, agree_topk, jaccard_topk = {}, {}, {}, {}\n",
    "        prob_mass_A_topk, prob_mass_B_topk, shared_mass_topk = {}, {}, {}\n",
    "        prob_overlap_topk, prob_mass_overlap_topk = {}, {}\n",
    "        tail_mass_A_topk, tail_mass_B_topk = {}, {}\n",
    "\n",
    "        for k in topk:\n",
    "            tkA, tkB = top_idx_A[:, :k], top_idx_B[:, :k]\n",
    "            tvA, tvB = top_vals_A[:, :k], top_vals_B[:, :k]\n",
    "\n",
    "            # Probability mass + tail\n",
    "            prob_mass_A_topk[k] = tvA.sum(dim=-1)\n",
    "            prob_mass_B_topk[k] = tvB.sum(dim=-1)\n",
    "            tail_mass_A_topk[k] = 1.0 - prob_mass_A_topk[k]\n",
    "            tail_mass_B_topk[k] = 1.0 - prob_mass_B_topk[k]\n",
    "\n",
    "            # Shared set + overlaps\n",
    "            inter_mask = (tkA.unsqueeze(-1) == tkB.unsqueeze(-2))\n",
    "            inter_counts = inter_mask.any(dim=-1).sum(dim=1).float()\n",
    "            jaccard_topk[k] = inter_counts / (2 * k - inter_counts + eps)\n",
    "            agree_topk[k] = (inter_counts == k).float()\n",
    "\n",
    "            shared_mass = torch.zeros_like(prob_mass_A_topk[k])\n",
    "            for i in range(tkA.size(0)):\n",
    "                shared_tokens = list(set(tkA[i].tolist()) & set(tkB[i].tolist()))\n",
    "                if len(shared_tokens) > 0:\n",
    "                    shared_tokens = torch.tensor(shared_tokens, device=device)\n",
    "                    shared_mass[i] = 0.5 * (\n",
    "                        probs_A[i, shared_tokens].sum() + probs_B[i, shared_tokens].sum()\n",
    "                    )\n",
    "            shared_mass_topk[k] = shared_mass\n",
    "\n",
    "            prob_mass_overlap_topk[k] = prob_mass_A_topk[k] * prob_mass_B_topk[k]\n",
    "            prob_overlap_topk[k] = shared_mass / (\n",
    "                0.5 * (prob_mass_A_topk[k] + prob_mass_B_topk[k]) + eps\n",
    "            )\n",
    "\n",
    "            # Accuracy\n",
    "            if targets is not None:\n",
    "                acc_A = (targets.unsqueeze(-1) == tkA).any(dim=-1).float()\n",
    "                acc_B = (targets.unsqueeze(-1) == tkB).any(dim=-1).float()\n",
    "                if mask is not None:\n",
    "                    acc_A, acc_B = acc_A * mask, acc_B * mask\n",
    "                acc_A_topk[k] = acc_A\n",
    "                acc_B_topk[k] = acc_B\n",
    "            else:\n",
    "                acc_A_topk[k] = acc_B_topk[k] = None\n",
    "\n",
    "        detailed.append({\n",
    "            \"prompt_id\": row_A[\"prompt_id\"],\n",
    "            \"prompt_text\": row_A.get(\"prompt_text\"),\n",
    "            \"dataset\": row_A.get(\"dataset\"),\n",
    "            \"layer_index\": row_A[\"layer_index\"],\n",
    "            \"layer_name\": row_A[\"layer_name\"],\n",
    "            \"vocab_size\": row_A[\"logits\"].size(-1),\n",
    "            \"input_ids\": row_A.get(\"input_ids\"),\n",
    "            \"position\": row_A.get(\"position\"),\n",
    "            \"targets\": targets,\n",
    "            \"mask\": mask,\n",
    "            # Divergences\n",
    "            \"kl_ab\": kl_ab.cpu(),\n",
    "            \"kl_ba\": kl_ba.cpu(),\n",
    "            \"jsd_div\": jsd_div.cpu(),\n",
    "            \"jsd_dist\": jsd_dist.cpu(),\n",
    "            \"vocab_tvd\": vocab_tvd.cpu(),\n",
    "            # Heat / IQR / Marginals\n",
    "            \"heat_A\": heat_A.cpu(),\n",
    "            \"heat_B\": heat_B.cpu(),\n",
    "            \"iqr_A\": iqr_A.cpu(),\n",
    "            \"iqr_B\": iqr_B.cpu(),\n",
    "            \"mean_prob_A\": mean_prob_A.cpu(),\n",
    "            \"mean_prob_B\": mean_prob_B.cpu(),\n",
    "            \"max_prob_A\": max_prob_A.cpu(),\n",
    "            \"max_prob_B\": max_prob_B.cpu(),\n",
    "            \"min_prob_A\": min_prob_A.cpu(),\n",
    "            \"min_prob_B\": min_prob_B.cpu(),\n",
    "            # Target\n",
    "            \"target_probs_A\": target_probs_A,\n",
    "            \"target_probs_B\": target_probs_B,\n",
    "            \"target_logprobs_A\": target_logprobs_A,\n",
    "            \"target_logprobs_B\": target_logprobs_B,\n",
    "            \"target_prob_diff\": target_prob_diff,\n",
    "            \"target_prob_tvd\": target_prob_tvd,\n",
    "            \"target_logprob_diff\": target_logprob_diff,\n",
    "            \"nll_A\": nll_A,\n",
    "            \"nll_B\": nll_B,\n",
    "            \"nll_diff\": nll_diff,\n",
    "            # Top-k / overlap\n",
    "            \"acc_A_topk\": acc_A_topk,\n",
    "            \"acc_B_topk\": acc_B_topk,\n",
    "            \"agree_topk\": agree_topk,\n",
    "            \"jaccard_topk\": jaccard_topk,\n",
    "            \"prob_mass_A_topk\": prob_mass_A_topk,\n",
    "            \"prob_mass_B_topk\": prob_mass_B_topk,\n",
    "            \"tail_mass_A_topk\": tail_mass_A_topk,\n",
    "            \"tail_mass_B_topk\": tail_mass_B_topk,\n",
    "            \"shared_mass_topk\": shared_mass_topk,\n",
    "            \"prob_overlap_topk\": prob_overlap_topk,\n",
    "            \"prob_mass_overlap_topk\": prob_mass_overlap_topk,\n",
    "        })\n",
    "\n",
    "    # --- Summary aggregation ---\n",
    "    def build_summary(detailed, topk):\n",
    "        rows = []\n",
    "        for r in detailed:\n",
    "            s = {\n",
    "                \"prompt_id\": r[\"prompt_id\"],\n",
    "                \"layer_index\": r[\"layer_index\"],\n",
    "                \"layer_name\": r.get(\"layer_name\"),\n",
    "                \"kl_ab\": safe_mean(r[\"kl_ab\"]),\n",
    "                \"kl_ba\": safe_mean(r[\"kl_ba\"]),\n",
    "                \"jsd_div\": safe_mean(r[\"jsd_div\"]),\n",
    "                \"jsd_dist\": safe_mean(r[\"jsd_dist\"]),\n",
    "                \"vocab_tvd\": safe_mean(r[\"vocab_tvd\"]),\n",
    "                \"heat_A\": safe_mean(r[\"heat_A\"]),\n",
    "                \"heat_B\": safe_mean(r[\"heat_B\"]),\n",
    "                \"iqr_A\": safe_mean(r[\"iqr_A\"]),\n",
    "                \"iqr_B\": safe_mean(r[\"iqr_B\"]),\n",
    "                \"mean_prob_A\": safe_mean(r[\"mean_prob_A\"]),\n",
    "                \"mean_prob_B\": safe_mean(r[\"mean_prob_B\"]),\n",
    "                \"max_prob_A\": safe_mean(r[\"max_prob_A\"]),\n",
    "                \"max_prob_B\": safe_mean(r[\"max_prob_B\"]),\n",
    "                \"min_prob_A\": safe_mean(r[\"min_prob_A\"]),\n",
    "                \"min_prob_B\": safe_mean(r[\"min_prob_B\"]),\n",
    "                \"target_prob_diff\": safe_mean(r[\"target_prob_diff\"]),\n",
    "                \"target_prob_tvd\": safe_mean(r[\"target_prob_tvd\"]),\n",
    "                \"target_logprob_diff\": safe_mean(r[\"target_logprob_diff\"]),\n",
    "                \"nll_diff\": safe_mean(r[\"nll_diff\"]),\n",
    "            }\n",
    "            for k in topk:\n",
    "                s[f\"acc_A@{k}\"] = safe_mean(r[\"acc_A_topk\"].get(k))\n",
    "                s[f\"acc_B@{k}\"] = safe_mean(r[\"acc_B_topk\"].get(k))\n",
    "                s[f\"agree@{k}\"] = safe_mean(r[\"agree_topk\"].get(k))\n",
    "                s[f\"jaccard@{k}\"] = safe_mean(r[\"jaccard_topk\"].get(k))\n",
    "                s[f\"prob_overlap@{k}\"] = safe_mean(r[\"prob_overlap_topk\"].get(k))\n",
    "                s[f\"prob_mass_overlap@{k}\"] = safe_mean(r[\"prob_mass_overlap_topk\"].get(k))\n",
    "                s[f\"tail_A@{k}\"] = safe_mean(r[\"tail_mass_A_topk\"].get(k))\n",
    "                s[f\"tail_B@{k}\"] = safe_mean(r[\"tail_mass_B_topk\"].get(k))\n",
    "            rows.append(s)\n",
    "\n",
    "        summary = pd.DataFrame(rows)\n",
    "        layer_summary = (\n",
    "            summary.groupby(\"layer_name\")\n",
    "            .mean(numeric_only=True)\n",
    "            .reset_index()\n",
    "            .sort_values(\"layer_name\")\n",
    "        )\n",
    "        return summary, layer_summary\n",
    "\n",
    "    summary, layer_summary = build_summary(detailed, topk)\n",
    "    # Save to parquet\n",
    "    summary.to_parquet(f\"logs/results_summary/batch_{lens_type}/nq_200/nq_query_200_batch{batch_num}.parquet\", index=False)\n",
    "    layer_summary.to_parquet(f\"logs/results_summary/batch_{lens_type}/nq_200/layer_wise_nq_query_200_batch{batch_num}.parquet\", index=False)\n",
    "    \n",
    "    return detailed, summary, layer_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad80498",
   "metadata": {},
   "outputs": [],
   "source": [
    "lens_type = \"sub\" # \"raw\", \"norm\"\n",
    "batch_num = 0\n",
    "sub_name = \"unitrms\"\n",
    "# Load logits:\n",
    "probs_A = torch.load(\n",
    "    f\"logs/lens_batches_subblocks/sub_probs/{sub_name}_nq_queries_1_llama8b_fp_batch{batch_num}.pt\",\n",
    "    weights_only=False \n",
    ")\n",
    "\n",
    "probs_B = torch.load(\n",
    "    f\"logs/lens_batches_subblocks/sub_probs/{sub_name}_nq_queries_1_llama8b_hf100b_batch{batch_num}.pt\",\n",
    "    weights_only=False \n",
    ")\n",
    "\n",
    "# Extract comparison metrics:\n",
    "detailed, summary, layer_summary = compare_metrics(metrics_A=probs_A, metrics_B=probs_B, batch_num=batch_num, lens_type=lens_type)\n",
    "\n",
    "# Saving detailed as a torch file:\n",
    "save_path = f\"logs/topk_compare/batch_{lens_type}/nq_200/{sub_name}_nq_query_200_batch{batch_num}.pt\"\n",
    "torch.save(detailed, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19961ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "batch_num = 0\n",
    "lens_type = \"norm\" # raw, \"unitrms\", \"norm\"\n",
    "\n",
    "# Load logits:\n",
    "probs_A = torch.load(\n",
    "    f\"logs/lens_batches_subblocks/sub_probs/{lens_type}_nq_queries_1_llama8b_{model_name}_batch{batch_num}.pt\",\n",
    "    weights_only=False \n",
    ")\n",
    "\n",
    "probs_B = torch.load(\n",
    "    f\"logs/lens_batches_subblocks/sub_probs/{lens_type}_nq_queries_1_llama8b_{model_name}_batch{batch_num}.pt\",\n",
    "    weights_only=False \n",
    ")\n",
    "\n",
    "# Extract comparison metrics:\n",
    "detailed, summary, layer_summary = compare_metrics(metrics_A=probs_A, metrics_B=probs_B, batch_num=batch_num, lens_type=lens_type)\n",
    "\n",
    "# Saving detailed as a torch file:\n",
    "save_path = f\"logs/topk_compare/batch_{lens_type}/nq_200/nq_query_200_batch{batch_num}.pt\"\n",
    "torch.save(detailed, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e597a578",
   "metadata": {},
   "source": [
    "### [✓] Non-normalized Comparison DONE\n",
    "### [✓] Normalized Comparison DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1056b20",
   "metadata": {},
   "source": [
    "# Comparison Results Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ea7621",
   "metadata": {},
   "source": [
    "## Heatmap Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bd51cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "raw = \"raw\"\n",
    "norm = \"norm\"\n",
    "unitrms = \"unitrms\"\n",
    "batch_num = 0\n",
    "\n",
    "# Load non-normalized lens comparison data:\n",
    "raw_data = torch.load(\n",
    "    f\"logs/topk_compare/batch_{raw}/nq_200/nq_query_200_batch{batch_num}.pt\",\n",
    "    weights_only=False \n",
    ")\n",
    "\n",
    "# Load normalized lens comparison data:\n",
    "norm_data = torch.load(\n",
    "    f\"logs/topk_compare/batch_{norm}/nq_200/nq_query_200_batch{batch_num}.pt\",\n",
    "    weights_only=False \n",
    ")\n",
    "\n",
    "unitrms_data = torch.load(\n",
    "    f\"logs/topk_compare/batch_{unitrms}/nq_200/nq_query_200_batch{batch_num}.pt\",\n",
    "    weights_only=False \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d202546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "lens_type = \"unitrms\"\n",
    "type = \"sub\"\n",
    "batch_num = 0\n",
    "\n",
    "# Load non-normalized lens comparison data:\n",
    "sub_data = torch.load(\n",
    "    f\"logs/topk_compare/batch_sub/nq_200/{lens_type}_nq_query_200_batch{batch_num}.pt\",\n",
    "    weights_only=False \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec377ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "lens_type = \"raw\"\n",
    "type = \"sub\"\n",
    "batch_num = 0\n",
    "\n",
    "# Load non-normalized lens comparison data:\n",
    "sub_raw = torch.load(\n",
    "    f\"logs/topk_compare/batch_sub/nq_200/{lens_type}_nq_query_200_batch{batch_num}.pt\",\n",
    "    weights_only=False \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1690a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "lens_type = \"norm\"\n",
    "type = \"sub\"\n",
    "batch_num = 0\n",
    "\n",
    "# Load non-normalized lens comparison data:\n",
    "sub_norm= torch.load(\n",
    "    f\"logs/topk_compare/batch_sub/nq_200/{lens_type}_nq_query_200_batch{batch_num}.pt\",\n",
    "    weights_only=False \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1746702",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Models/LLaMA3Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a22f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"BOS ID:\", tokenizer.bos_token_id)\n",
    "print(\"EOS ID:\", tokenizer.eos_token_id)\n",
    "print(\"PAD ID:\", tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fd6f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': tokenizer.eos_token})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321c1822",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"BOS ID:\", tokenizer.bos_token_id)\n",
    "print(\"EOS ID:\", tokenizer.eos_token_id)\n",
    "print(\"PAD ID:\", tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cfba4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Compare norm magnitudes for BOS token\n",
    "for layer in range(num_layers):\n",
    "    bos_norm_A = rA[\"hidden_states\"][layer][0, 0].norm().item()\n",
    "    bos_norm_B = rB[\"hidden_states\"][layer][0, 0].norm().item()\n",
    "    print(layer, bos_norm_A / bos_norm_B)\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "if tokenizer:\n",
    "    mask_ids = [tokenizer.bos_token_id, tokenizer.eos_token_id, tokenizer.pad_token_id]\n",
    "else:\n",
    "    mask_ids = [128000, 128009]\n",
    "\n",
    "mask = ~torch.isin(torch.tensor(rows[0][\"input_ids\"]), torch.tensor(mask_ids))\n",
    "metric_values = metric_values[:, mask]  # skip BOS/EOS in visualization\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e49a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: BOS (beginning-of-sequence) token handling\n",
    "#\n",
    "# We retain the BOS token in the logit lens analysis because it encodes the model's\n",
    "# initial internal state before any contextual input is processed.\n",
    "# Divergence patterns at this position often reveal how quantization or fine-tuning\n",
    "# affects early-layer activations and scaling, even before text content appears.\n",
    "#\n",
    "# However, the BOS token is excluded (masked) from all predictive metrics such as\n",
    "# accuracy, NLL, or top-k agreement, since no token is predicted *before* BOS.\n",
    "#\n",
    "# In short:\n",
    "# - BOS is kept for representational and divergence analysis.\n",
    "# - BOS is masked out for predictive or target-based comparisons.\n",
    "#\n",
    "# This distinction allows us to observe early activation drift without contaminating\n",
    "# metrics that depend on next-token predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31edafe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def pretty_layer_name(raw_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert raw layer names like:\n",
    "        \"layer_12\", \"layer.12.mlp\", \"layer_7.self_attn\"\n",
    "    into pretty printable labels like:\n",
    "        \"Layer 13\", \"Layer 13 · MLP\", \"Layer 8 · Attention\"\n",
    "    \"\"\"\n",
    "    # Embedding and output special cases\n",
    "    if raw_name in {\"embed_tokens\", \"embedding\"}:\n",
    "        return \"Embedding\"\n",
    "    if raw_name in {\"output\", \"lm_head\"}:\n",
    "        return \"Output\"\n",
    "\n",
    "    # Normalize separators for consistent parsing\n",
    "    name = raw_name.replace(\"_\", \".\")  \n",
    "\n",
    "    # Split and detect indices + subcomponents\n",
    "    parts = name.split(\".\")\n",
    "    if len(parts) == 1:\n",
    "        return raw_name  # fallback for unknown patterns\n",
    "\n",
    "    layer_idx = None\n",
    "    sub_name = None\n",
    "\n",
    "    # Find the numeric layer index and optional subcomponent\n",
    "    for p in parts:\n",
    "        if p.isdigit():\n",
    "            layer_idx = int(p)\n",
    "        elif any(s in p for s in [\"attn\", \"mlp\", \"block\"]):\n",
    "            sub_name = p\n",
    "\n",
    "    if layer_idx is None:\n",
    "        return raw_name\n",
    "\n",
    "    # Construct readable name\n",
    "    base = f\"Layer {layer_idx + 1}\"  # +1 for human-friendly indexing\n",
    "    if sub_name is None:\n",
    "        return base\n",
    "    elif \"attn\" in sub_name:\n",
    "        return f\"{base} · Attention\"\n",
    "    elif \"mlp\" in sub_name:\n",
    "        return f\"{base} · MLP\"\n",
    "    elif \"block\" in sub_name:\n",
    "        return f\"{base} · Block\"\n",
    "    else:\n",
    "        return f\"{base} · {sub_name}\"\n",
    "\n",
    "\n",
    "\n",
    "def plot_heatmap(data, tokenizer, prompt_id=0, mask_ids=[128000, 128009],\n",
    "                     token_maxlen=20, x_per_col=0.9, y_per_row=0.35,\n",
    "                     metric=\"jsd_div\", color_map=\"coolwarm\", title=\"Jensen-Shannon divergence\",\n",
    "                     save_path=None):\n",
    "\n",
    "    rows = [r for r in data if r[\"prompt_id\"] == prompt_id]\n",
    "    rows = sorted(rows, key=lambda r: r[\"layer_index\"])\n",
    "\n",
    "    input_ids = torch.tensor(rows[0][\"input_ids\"])\n",
    "    target_ids = torch.tensor(rows[0][\"targets\"])\n",
    "\n",
    "    min_len = min(len(input_ids), len(target_ids))\n",
    "    input_ids = input_ids[:min_len]\n",
    "    target_ids = target_ids[:min_len]\n",
    "\n",
    "    mask_ids = [tokenizer.bos_token_id, tokenizer.eos_token_id, tokenizer.pad_token_id]\n",
    "    mask_ids = [mid for mid in mask_ids if mid is not None]\n",
    "\n",
    "    for r in data:\n",
    "        if \"targets\" in r and r[\"targets\"] is not None:\n",
    "            mask = ~torch.isin(r[\"targets\"], torch.tensor(mask_ids))\n",
    "            for m in [\"kl_ab\", \"kl_ba\", \"jsd_div\", \"jsd_dist\", \"vocab_tvd\"]:\n",
    "                if m in r and isinstance(r[m], torch.Tensor):\n",
    "                    r[m][~mask] = float(\"nan\")\n",
    "\n",
    "    keep_mask = torch.ones_like(target_ids, dtype=torch.bool)\n",
    "    for mid in mask_ids:\n",
    "        keep_mask &= (target_ids != mid)\n",
    "\n",
    "    input_ids = input_ids[keep_mask].tolist()\n",
    "    target_ids = target_ids[keep_mask].tolist()\n",
    "\n",
    "    def dec(tid):\n",
    "        s = tokenizer.decode([tid]).replace(\"\\n\", \" \")\n",
    "        return (s[:token_maxlen] + \"…\") if len(s) > token_maxlen else s\n",
    "\n",
    "    input_tokens  = [dec(tid) for tid in input_ids]\n",
    "    target_tokens = [dec(tid) for tid in target_ids]\n",
    "\n",
    "    matrix = torch.stack([r[metric][keep_mask] for r in rows]).cpu().numpy()\n",
    "    n_rows, n_cols = matrix.shape\n",
    "\n",
    "    # Opt for resacling for including subblocks: y_per_row = 0.25 if any(\"·\" in pretty_layer_name(r[\"layer_name\"]) for r in rows) else 0.35\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(max(6, n_cols * x_per_col), max(3, n_rows * y_per_row)),\n",
    "                           constrained_layout=True)\n",
    "\n",
    "    im = sns.heatmap(\n",
    "        matrix,\n",
    "        cmap=color_map,\n",
    "        cbar=True,\n",
    "        annot=True,          \n",
    "        xticklabels=False,   \n",
    "        yticklabels=[pretty_layer_name(r[\"layer_name\"]) for r in rows]\n",
    "    )\n",
    "\n",
    "    centers = np.arange(n_cols) + 0.5\n",
    "    ax.set_xlim(0, n_cols)              \n",
    "    ax.set_xticks(centers)\n",
    "    ax.set_xticklabels(input_tokens, rotation=90, ha=\"center\", fontsize=9)\n",
    "\n",
    "    ax_top = ax.twiny()\n",
    "    ax_top.set_xlim(ax.get_xlim())\n",
    "    ax_top.set_xticks(centers)\n",
    "    ax_top.set_xticklabels(target_tokens, rotation=90, ha=\"center\", fontsize=8)\n",
    "    ax_top.set_xlabel(\"Target tokens\")\n",
    "\n",
    "    ax.invert_yaxis()               \n",
    "    ax.set_aspect(\"auto\")      \n",
    "    ax.set_xlabel(\"Input tokens\")\n",
    "    ax.set_ylabel(\"Layers\")\n",
    "    #ax.set_title(f\"{title} prompt {prompt_id}\" if title is not None  else \"\")\n",
    "    ax.set_title(f\"{title}\" if title is not None  else \"\")\n",
    "\n",
    "    plt.subplots_adjust(bottom=0.25, top=0.85)\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7134f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = unitrms_data\n",
    "fig_path = \"figs/unitrms_lens/jsd_div_unitrms.png\"\n",
    "plot_heatmap(\n",
    "    data, tokenizer, prompt_id=0,\n",
    "    metric=\"jsd_div\", color_map=\"Blues\",\n",
    "    title=\"Final RMS Lens Jensen-Shannon divergence\",\n",
    "    save_path=fig_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7c8233",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = norm_data\n",
    "fig_path = \"figs/norm_lens/jsd_div_norm.png\"\n",
    "plot_heatmap(\n",
    "    data, tokenizer, prompt_id=0,\n",
    "    metric=\"jsd_div\", color_map=\"Blues\",\n",
    "    title=\"Normalized Lens Jensen-Shannon divergence\",\n",
    "    save_path=fig_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5114e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw_data\n",
    "fig_path = \"figs/raw_lens/jsd_div_raw.png\"\n",
    "plot_heatmap(\n",
    "    data, tokenizer, prompt_id=0,\n",
    "    metric=\"jsd_div\", color_map=\"Blues\",\n",
    "    title=\"Final Layer RMS Lens Jensen-Shannon divergence\",\n",
    "    save_path=fig_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8bc4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = norm_data\n",
    "fig_raw = \"figs/norm_lens/jsd_div_prompt0.png\"\n",
    "plot_heatmap(\n",
    "    data, tokenizer, prompt_id=0,\n",
    "    metric=\"jsd_div\", color_map=\"Blues\",\n",
    "    title=\"Normalized Lens Jensen-Shannon divergence\",\n",
    "    save_path=fig_raw\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c048e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw_data\n",
    "fig_raw = \"figs/raw_lens/jsd_div_prompt0.png\"\n",
    "plot_heatmap(\n",
    "    data, tokenizer, prompt_id=0,\n",
    "    metric=\"jsd_div\", color_map=\"Blues\",\n",
    "    title=\"Non-normalized Lens Jensen-Shannon divergence\",\n",
    "    save_path=fig_raw\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3c4b8c",
   "metadata": {},
   "source": [
    "## Non-normalized Lens Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8711ed6c",
   "metadata": {},
   "source": [
    "## Normalized Lens Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logit-lens-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
