{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f6294ae",
   "metadata": {},
   "source": [
    "# ==============================================\n",
    "# Notebook for Logit Lens and Hidden Acts ======\n",
    "# =============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad138a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datasets import load_dataset, DownloadMode\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from old_lens.mi_utils.quant_configs.bnb_configs import load_bnb_in_4bit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f24fe2",
   "metadata": {},
   "source": [
    "# ==============================================\n",
    "# Models & Dataset =============================\n",
    "# =============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340878a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r'D:\\LogitLensData\\nq'\n",
    "\n",
    "destination_path = str(Path(filepath))\n",
    "nq_dataset = load_dataset(\n",
    "    'sentence-transformers/natural-questions',\n",
    "    split={\n",
    "        'train': 'train[:1000]'\n",
    "    },\n",
    "    cache_dir=destination_path,\n",
    "    download_mode=DownloadMode.REUSE_DATASET_IF_EXISTS,\n",
    "    keep_in_memory=True\n",
    ")\n",
    "\n",
    "nq_queries = nq_dataset['train']['query']\n",
    "nq_answers = nq_dataset['train']['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68ca72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nq_1000 = nq_queries[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacd528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nq_500 = nq_queries[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6d258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class Models(Enum):\n",
    "    LAIN8B = \"Models/LLaMA3Instruct\"\n",
    "    HF100B = \"Models/HF1BitLLM100Btokens\"\n",
    "\n",
    "\n",
    "class Names(Enum):\n",
    "    LAIN8B = \"Meta-Llama-3-8B-Instruct-fp\"\n",
    "    HF100B = \"Llama3-8B-1.58-100B-tokens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f135f946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_tok(\n",
    "    model_name: str,\n",
    "    low_cpu_mem_usage: bool = True,\n",
    "    local_files_only: bool = True,\n",
    "    device_map: str = \"cpu\",\n",
    "    dtype: torch.dtype = torch.float32,\n",
    "    load_in_8bit: bool = False\n",
    "):\n",
    "    tok = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        output_hidden_states=True,\n",
    "        return_dict_in_generate=True,\n",
    "        return_dict=True,\n",
    "        output_attentions=True,\n",
    "        low_cpu_mem_usage=low_cpu_mem_usage,\n",
    "        local_files_only=local_files_only,\n",
    "        device_map=device_map,\n",
    "        load_in_8bit=load_in_8bit,\n",
    "        torch_dtype=dtype,\n",
    "        attn_implementation=\"eager\",\n",
    "    )\n",
    "    return model, tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6741ccfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_orig, orig_tokenizer = load_model_and_tok(Models.LAIN8B.value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57b52df",
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_token_id = orig_tokenizer.eos_token_id\n",
    "bos_token_id = orig_tokenizer.bos_token_id\n",
    "print(f\"eos: {eos_token_id}\\nbos: {bos_token_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50589c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_8bit, orig_tokenizer = load_model_and_tok(Models.LAIN8B.value, dtype=torch.float16, load_in_8bit=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4cbb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4bit, orig_tokenizer = load_bnb_in_4bit(Models.LAIN8B.value, double_quant=False, dtype=torch.float16, device_map=\"cpu\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93562c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_quant, quant_tokenizer = load_model_and_tok(Models.HF100B.value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdeb4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for q in nq_500:\n",
    "    ids = orig_tokenizer.encode(q, add_special_tokens=True)\n",
    "    lengths.append(len(ids))\n",
    "\n",
    "print(\"=== Token Length Statistics (LLaMA-3-8B-Instruct tokenizer) ===\")\n",
    "print(f\"Samples analyzed: {len(lengths)}\")\n",
    "print(f\"Mean length:       {np.mean(lengths):.2f}\")\n",
    "print(f\"Median length:     {np.median(lengths):.0f}\")\n",
    "print(f\"90th percentile:   {np.percentile(lengths, 90):.0f}\")\n",
    "print(f\"95th percentile:   {np.percentile(lengths, 95):.0f}\")\n",
    "print(f\"Max observed len:  {np.max(lengths)}\")\n",
    "print(f\"Min observed len:  {np.min(lengths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61cc4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "sig = inspect.signature(model_orig.model.layers[0].forward)\n",
    "print(sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4a964b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "\n",
    "MODELS = {\n",
    "    \"base_fp32\": {\n",
    "        \"path\": \"meta-llama/Llama-2-7b-hf\",\n",
    "        \"quant\": None\n",
    "    },\n",
    "    \"bnb_8bit\": {\n",
    "        \"path\": \"meta-llama/Llama-2-7b-hf\",\n",
    "        \"quant\": BitsAndBytesConfig(load_in_8bit=True, torch_dtype=torch.float16)\n",
    "    },\n",
    "    \"bnb_4bit\": {\n",
    "        \"path\": \"meta-llama/Llama-2-7b-hf\",\n",
    "        \"quant\": BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            torch_dtype=torch.float16\n",
    "        )\n",
    "    },\n",
    "}\n",
    "\n",
    "SAVE_DIR = \"weights_extracted\" \n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "def extract_and_save_weights(model_name: str, model_cfg: dict):\n",
    "    print(f\"\\n🔹 Extracting weights from {model_name} ...\")\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_cfg[\"path\"],\n",
    "        quantization_config=model_cfg[\"quant\"],\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "\n",
    "    out_dir = os.path.join(SAVE_DIR, model_name)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        # Detach, dequantize (if needed), and upcast to float32\n",
    "        w = param.detach().clone().to(torch.float32).cpu()\n",
    "\n",
    "        fname = name.replace(\".\", \"_\") + \".pt\"\n",
    "        torch.save(w, os.path.join(out_dir, fname))\n",
    "\n",
    "    print(f\"Saved float32 weights for {model_name} to {out_dir}\")\n",
    "\n",
    "    # small sanity check\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"   Total parameters: {total_params:,}\")\n",
    "    print(f\"   Example tensor dtype: {w.dtype}, shape: {tuple(w.shape)}\")\n",
    "\n",
    "\n",
    "\n",
    "for model_name, model_cfg in MODELS.items():\n",
    "    extract_and_save_weights(model_name, model_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2094d259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, glob\n",
    "\n",
    "base_w = torch.load(\"weights_extracted/base_fp32/model_layers_0_self_attn_q_proj_weight.pt\")\n",
    "bnb_w = torch.load(\"weights_extracted/bnb_8bit/model_layers_0_self_attn_q_proj_weight.pt\")\n",
    "\n",
    "print(base_w.dtype, bnb_w.dtype)\n",
    "print(\"Mean abs diff:\", (base_w - bnb_w).abs().mean().item())\n",
    "print(\"Cosine similarity:\", torch.nn.functional.cosine_similarity(\n",
    "    base_w.flatten(), bnb_w.flatten(), dim=0\n",
    ").item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b729d26",
   "metadata": {},
   "source": [
    "# ==============================================\n",
    "# Logit Lens with Normaliztion =================\n",
    "# =============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37206e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"MatMul8bitLt: inputs will be cast\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Normalization modes\n",
    "# ============================================================\n",
    "def apply_normalization(x, model, normalize_mode=\"raw\", block=None, layer_index=None):\n",
    "    x = x.to(torch.float32) \n",
    "    \n",
    "    if normalize_mode == \"raw\":\n",
    "        return x\n",
    "\n",
    "    elif normalize_mode == \"unit_rms\":\n",
    "        if layer_index == -1:\n",
    "            return x\n",
    "        elif block is not None:\n",
    "            eps = 1e-5\n",
    "            return x / (x.pow(2).mean(dim=-1, keepdim=True).add(eps).sqrt())\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    elif normalize_mode == \"rms_layer\":\n",
    "        if layer_index == -1:\n",
    "            return x\n",
    "        elif block is not None:\n",
    "            return block.post_attention_layernorm(x.to(torch.float32))\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    elif normalize_mode == \"norm_rms\":\n",
    "        if layer_index == -1:\n",
    "            return x\n",
    "        elif block is not None:\n",
    "            return model.model.norm(x).to(torch.float32)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown normalization_mode: {normalize_mode}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Helper: causal + padding mask for LLaMA blocks\n",
    "# ============================================================\n",
    "def build_full_attention_mask(input_ids, attention_mask, device, model=None):\n",
    "    bsz, seq_len = input_ids.shape\n",
    "\n",
    "    causal = torch.triu(\n",
    "        torch.ones((seq_len, seq_len), device=device, dtype=torch.bool), diagonal=1\n",
    "    ).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    if attention_mask is None:\n",
    "        padding_mask = torch.zeros((bsz, 1, 1, seq_len), device=device, dtype=torch.bool)\n",
    "    else:\n",
    "        padding_mask = (attention_mask[:, None, None, :] == 0)\n",
    "\n",
    "    full = causal | padding_mask\n",
    "\n",
    "    attn_impl = getattr(getattr(model, \"config\", None), \"attn_implementation\", None)\n",
    "    attn_impl = attn_impl or \"eager\" \n",
    "\n",
    "    if attn_impl in [\"flash_attention_2\", \"sdpa\"]:\n",
    "        return full.to(torch.bool)\n",
    "    else:\n",
    "        return full.to(torch.float32) * -1e9\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Collector with multiple normalization variants + attention weights (optional storage)\n",
    "# ============================================================\n",
    "@torch.no_grad()\n",
    "def collect_logit_lens_full(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    prompts,\n",
    "    batch_index=0,\n",
    "    max_len=17,\n",
    "    device=None,\n",
    "    clamp_logits=False,         \n",
    "    clamp_value=100.0,         \n",
    "    save_path=None,\n",
    "    collect_attn=True,\n",
    "    save_attn=True,\n",
    "    norm_modes=(\"raw\", \"unit_rms\", \"norm_rms\"),\n",
    "):\n",
    "\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    bnb_layer_types = (\"Linear4bit\", \"Linear8bitLt\")\n",
    "    is_quantized = any(any(name in type(m).__name__ for name in bnb_layer_types)\n",
    "                       for m in model.modules())\n",
    "\n",
    "    if is_quantized:\n",
    "        try:\n",
    "            first_param_device = next(model.parameters()).device\n",
    "        except StopIteration:\n",
    "            first_param_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"[info] Detected quantized model → device {first_param_device}\")\n",
    "        model.eval()\n",
    "    else:\n",
    "        model = model.to(device).eval()\n",
    "\n",
    "    Path(save_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # ============================================================\n",
    "    # Tokenization\n",
    "    # ============================================================\n",
    "    encoded = []\n",
    "    pad_id = tokenizer.pad_token_id or tokenizer.eos_token_id\n",
    "    bos_id = tokenizer.bos_token_id\n",
    "    eos_id = tokenizer.eos_token_id\n",
    "\n",
    "    for p in prompts:\n",
    "        ids = tokenizer.encode(p, add_special_tokens=False)\n",
    "        content = ids[: max_len - 2]\n",
    "        ids = torch.tensor([bos_id] + content + [eos_id], dtype=torch.long)\n",
    "        if len(ids) < max_len:\n",
    "            ids = F.pad(ids, (0, max_len - len(ids)), value=pad_id)\n",
    "        encoded.append(ids)\n",
    "\n",
    "    input_ids = torch.stack(encoded, dim=0).to(device)\n",
    "\n",
    "    # ============================================================\n",
    "    # Build attention mask (stop after first EOS)\n",
    "    # ============================================================\n",
    "    attention_mask = torch.ones_like(input_ids, dtype=torch.long)\n",
    "    for i, ids in enumerate(input_ids):\n",
    "        eos_positions = (ids == eos_id).nonzero(as_tuple=True)[0]\n",
    "        if len(eos_positions) > 0:\n",
    "            eos_pos = eos_positions[0].item()\n",
    "            attention_mask[i, eos_pos + 1:] = 0\n",
    "\n",
    "    batch_size, seq_len = input_ids.shape\n",
    "    full_mask = build_full_attention_mask(input_ids, attention_mask, device)\n",
    "    #print(f\"[mask] dtype={full_mask.dtype}, shape={tuple(full_mask.shape)}, example={full_mask.flatten()[0].item()}\")\n",
    "    print(\n",
    "        f\"[mask] dtype={full_mask.dtype}, shape={tuple(full_mask.shape)}, \"\n",
    "        f\"min={full_mask.min().item()}, max={full_mask.max().item()}, \"\n",
    "        f\"unique={torch.unique(full_mask)}\"\n",
    "    )\n",
    "    assert (full_mask == 0).sum() < full_mask.numel(), \"Mask seems to contain only zeros — check logic!\"\n",
    "\n",
    "    position_ids = torch.arange(seq_len, device=device).unsqueeze(0).expand(batch_size, -1)\n",
    "    vocab_size = model.lm_head.out_features\n",
    "\n",
    "    print(f\"[info] Tokenized {batch_size} prompts | seq_len={seq_len}\")\n",
    "    print(f\"[info] Collecting from {len(model.model.layers)} layers | quantized={is_quantized}\")\n",
    "\n",
    "    # ============================================================\n",
    "    # Projection helper (with consistent upcasting and sanitization)\n",
    "    # ============================================================\n",
    "    def project(x):\n",
    "        x_fp32 = x.to(torch.float32)\n",
    "\n",
    "        head_dtype = next(model.lm_head.parameters()).dtype\n",
    "        x_cast = x_fp32.to(head_dtype)\n",
    "\n",
    "        logits = model.lm_head(x_cast)\n",
    "\n",
    "        logits = torch.nan_to_num(logits, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        if clamp_logits and is_quantized:\n",
    "            logits = logits.clamp(-clamp_value, clamp_value)\n",
    "\n",
    "        return logits.to(torch.float32)\n",
    "\n",
    "    # ============================================================\n",
    "    # Collection containers\n",
    "    # ============================================================\n",
    "    rows = []\n",
    "    all_hidden, all_logits, all_attn = {}, {}, {}\n",
    "\n",
    "    # ============================================================\n",
    "    # Embedding layer\n",
    "    # ============================================================\n",
    "    x = model.model.embed_tokens(input_ids).to(torch.float32)\n",
    "    hidden_variants = {mode: apply_normalization(x.clone(), model, mode, layer_index=-1)\n",
    "                       for mode in norm_modes}\n",
    "    logits_variants = {mode: project(hidden_variants[mode]) for mode in norm_modes}\n",
    "\n",
    "    for mode in norm_modes:\n",
    "        all_hidden[f\"embed_tokens_{mode}\"] = hidden_variants[mode].cpu()\n",
    "        all_logits[f\"embed_tokens_{mode}\"] = logits_variants[mode].cpu()\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        rows.append({\n",
    "            \"prompt_id\": i,\n",
    "            \"prompt_text\": prompts[i],\n",
    "            \"batch_index\": batch_index,\n",
    "            \"vocab_size\": vocab_size,\n",
    "            \"layer_index\": -1,\n",
    "            \"layer_name\": \"embed_tokens\",\n",
    "            \"input_ids\": input_ids[i].cpu(),\n",
    "            \"target_ids\": input_ids[i, 1:].cpu(),\n",
    "            \"attention_mask\": attention_mask[i].cpu(),\n",
    "            **{f\"hidden_{m}\": hidden_variants[m][i, :-1].cpu() for m in norm_modes},\n",
    "            **{f\"logits_{m}\": logits_variants[m][i, :-1].cpu() for m in norm_modes},\n",
    "        })\n",
    "\n",
    "    # ============================================================\n",
    "    # Transformer layers\n",
    "    # ============================================================\n",
    "    for li, block in enumerate(model.model.layers):\n",
    "        out = block(\n",
    "            x, position_ids=position_ids,\n",
    "            attention_mask=full_mask,\n",
    "            output_attentions=collect_attn,\n",
    "        )\n",
    "        x = out[0]\n",
    "        attn = out[1] if collect_attn else None\n",
    "\n",
    "        layer_output = x.detach().clone().to(torch.float32)\n",
    "        hidden_variants = {\n",
    "            mode: apply_normalization(layer_output.clone(), model, mode, block=block, layer_index=li)\n",
    "            for mode in norm_modes\n",
    "        }\n",
    "        logits_variants = {mode: project(hidden_variants[mode]) for mode in norm_modes}\n",
    "\n",
    "        for mode in norm_modes:\n",
    "            hidden_variants[mode] = hidden_variants[mode][:, :-1, :]\n",
    "            logits_variants[mode] = logits_variants[mode][:, :-1, :]\n",
    "\n",
    "        for mode in norm_modes:\n",
    "            all_hidden[f\"layer.{li}_{mode}\"] = hidden_variants[mode].cpu()\n",
    "            all_logits[f\"layer.{li}_{mode}\"] = logits_variants[mode].cpu()\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            record = {\n",
    "                \"prompt_id\": i,\n",
    "                \"prompt_text\": prompts[i],\n",
    "                \"batch_index\": batch_index,\n",
    "                \"vocab_size\": vocab_size,\n",
    "                \"layer_index\": li,\n",
    "                \"layer_name\": f\"layer.{li}\",\n",
    "                \"input_ids\": input_ids[i].cpu(),\n",
    "                \"target_ids\": input_ids[i, 1:].cpu(),\n",
    "                \"attention_mask\": attention_mask[i].cpu(),\n",
    "                **{f\"hidden_{m}\": hidden_variants[m][i].cpu() for m in norm_modes},\n",
    "                **{f\"logits_{m}\": logits_variants[m][i].cpu() for m in norm_modes},\n",
    "            }\n",
    "            if save_attn and attn is not None:\n",
    "                record[\"attn\"] = attn[i].cpu()\n",
    "            rows.append(record)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    # ============================================================\n",
    "    # Final RMSNorm output\n",
    "    # ============================================================\n",
    "    x = model.model.norm(x.to(torch.float32))\n",
    "    h = x\n",
    "    l = project(h)\n",
    "    h, l = h[:, :-1, :], l[:, :-1, :]\n",
    "\n",
    "    all_hidden[\"output_true\"] = h.cpu()\n",
    "    all_logits[\"output_true\"] = l.cpu()\n",
    "\n",
    "    for mode in norm_modes:\n",
    "        all_hidden[f\"output_{mode}\"] = h.cpu()\n",
    "        all_logits[f\"output_{mode}\"] = l.cpu()\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        rows.append({\n",
    "            \"prompt_id\": i,\n",
    "            \"prompt_text\": prompts[i],\n",
    "            \"batch_index\": batch_index,\n",
    "            \"vocab_size\": vocab_size,\n",
    "            \"layer_index\": len(model.model.layers),\n",
    "            \"layer_name\": \"output\",\n",
    "            \"input_ids\": input_ids[i].cpu(),\n",
    "            \"target_ids\": input_ids[i, 1:].cpu(),\n",
    "            \"attention_mask\": attention_mask[i].cpu(),\n",
    "            **{f\"hidden_{m}\": h[i].cpu() for m in norm_modes},\n",
    "            **{f\"logits_{m}\": l[i].cpu() for m in norm_modes},\n",
    "        })\n",
    "\n",
    "\n",
    "    # ============================================================\n",
    "    # Save and finish \n",
    "    # ============================================================\n",
    "    if save_path:\n",
    "        torch.save(rows, save_path)\n",
    "        print(f\"[saved] Logit-lens data → {save_path}\")\n",
    "\n",
    "\n",
    "    print(f\"[info] Model has {len(model.model.layers)} transformer blocks (plus embedding + output).\")\n",
    "\n",
    "    return rows, all_hidden, all_logits, all_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8653a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "def run_logit_lens_in_batches(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    all_prompts,\n",
    "    batch_size=20,\n",
    "    save_prefix=\"logitlens_batch\",\n",
    "    max_len=17,\n",
    "    normalize_mode=(\"raw\", \"unit_rms\", \"norm_rms\"),\n",
    "    device=None,\n",
    "    clamp_logits=False,\n",
    "    collect_attn=False,\n",
    "    save_attn=False \n",
    "):\n",
    "\n",
    "    num_batches = (len(all_prompts) + batch_size - 1) // batch_size\n",
    "    print(f\"[run] Processing {len(all_prompts)} prompts in {num_batches} batches of {batch_size}\")\n",
    "\n",
    "    for batch_idx in tqdm(range(num_batches), desc=\"Running logit lens batches\"):\n",
    "        start = batch_idx * batch_size\n",
    "        end = min((batch_idx + 1) * batch_size, len(all_prompts))\n",
    "        batch_prompts = all_prompts[start:end]\n",
    "\n",
    "        save_path = f\"{save_prefix}_batch{batch_idx:03d}.pt\"\n",
    "\n",
    "        print(f\"\\n[batch {batch_idx+1}/{num_batches}] {len(batch_prompts)} prompts → {save_path}\")\n",
    "\n",
    "        try:\n",
    "            rows, hidden_dict, logits_dict, all_attn = collect_logit_lens_full(\n",
    "                model=model,\n",
    "                tokenizer=tokenizer,\n",
    "                prompts=batch_prompts,\n",
    "                max_len=max_len,\n",
    "                device=device,\n",
    "                norm_modes=normalize_mode,\n",
    "                save_path=save_path,\n",
    "                clamp_logits=clamp_logits,\n",
    "                collect_attn=collect_attn,\n",
    "                save_attn=save_attn,\n",
    "            )\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            print(f\"[error] Batch {batch_idx} failed: {e}\")\n",
    "            continue\n",
    "\n",
    "        del rows, hidden_dict, logits_dict, all_attn, batch_prompts\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    print(\"\\n[done] All batches processed and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c78c746",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logit_lens_in_batches(\n",
    "    model=model_8bit,\n",
    "    tokenizer=orig_tokenizer,\n",
    "    all_prompts=nq_500,\n",
    "    batch_size=10,\n",
    "    max_len=17,\n",
    "    normalize_mode=(\"raw\", \"unit_rms\", \"norm_rms\"), \n",
    "    save_prefix=\"saved_data/lens_data/m_8bit/m_8bit_modes\",\n",
    "    device=\"cpu\",\n",
    "    clamp_logits=False,\n",
    "    collect_attn=False,\n",
    "    save_attn=False  \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae5e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_data = torch.load(\"saved_data/lens_data/m_orig/m_orig_modes_batch000.pt\", weights_only=False, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf0f30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39183c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_data_df = pd.DataFrame(ll_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051c0999",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28426c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_data_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591013aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_data_df[\"layer_name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6ef638",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667f2444",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_data_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169fe977",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(orig_tokenizer.decode([128000]))\n",
    "print(orig_tokenizer.decode([128009]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bee5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(orig_tokenizer.decode([128000, 9906, 1917, 128009]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37103286",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(orig_tokenizer.bos_token_id, orig_tokenizer.eos_token_id)\n",
    "print(model_8bit.config.bos_token_id, model_8bit.config.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b55c33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = orig_tokenizer.encode(\"Hello world\", add_special_tokens=True)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0f33a9",
   "metadata": {},
   "source": [
    "# ==============================================\n",
    "# TopK Comparison ==============================\n",
    "# =============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8db2ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, beta = 0.5, 0.5\n",
    "df[\"S_l\"] = alpha * df[\"TVD_FP32_vs_Quant\"] + beta * (1 - df[\"Align_to_Output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93bdff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc, torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cache BOS–EOS valid indices per prompt\n",
    "# ============================================================\n",
    "_mask_cache = {}\n",
    "\n",
    "\n",
    "def preprocess_metrics(metrics, lens_type=\"raw\"):\n",
    "    \"\"\"Trim logits/hidden/targets to BOS–EOS span, cached per prompt_id.\"\"\"\n",
    "    processed = []\n",
    "    for row in metrics:\n",
    "        pid = row.get(\"prompt_id\")\n",
    "        logits = row.get(f\"logits_{lens_type}\")\n",
    "        hidden = row.get(f\"hidden_{lens_type}\")\n",
    "        attn_mask = row.get(\"attention_mask\")\n",
    "        targets = row.get(\"target_ids\")\n",
    "\n",
    "        if logits is None or targets is None or attn_mask is None:\n",
    "            continue\n",
    "\n",
    "        # reuse cached BOS–EOS mask\n",
    "        if pid in _mask_cache:\n",
    "            valid_pos = _mask_cache[pid]\n",
    "        else:\n",
    "            if not isinstance(attn_mask, torch.Tensor):\n",
    "                attn_mask = torch.tensor(attn_mask)\n",
    "            if attn_mask.ndim == 4:\n",
    "                attn_mask = attn_mask[:, 0, 0, :]\n",
    "            elif attn_mask.ndim == 1:\n",
    "                attn_mask = attn_mask.unsqueeze(0)\n",
    "            attn_mask = attn_mask.to(torch.bool)\n",
    "\n",
    "            mask_1d = attn_mask[0]\n",
    "            true_pos = mask_1d.nonzero(as_tuple=True)[0]\n",
    "            if true_pos.numel() < 2:\n",
    "                continue\n",
    "\n",
    "            bos_idx, eos_idx = int(true_pos[0]), int(true_pos[-1])\n",
    "            eval_mask = torch.zeros_like(mask_1d, dtype=torch.bool)\n",
    "            if eos_idx > bos_idx + 1:\n",
    "                eval_mask[bos_idx + 1:eos_idx] = True\n",
    "            valid_pos = eval_mask.nonzero(as_tuple=True)[0]\n",
    "            if valid_pos.numel() == 0:\n",
    "                continue\n",
    "\n",
    "            _mask_cache[pid] = valid_pos\n",
    "\n",
    "        if logits.ndim == 2:\n",
    "            logits = logits.unsqueeze(0)\n",
    "        if targets.ndim == 1:\n",
    "            targets = targets.unsqueeze(0)\n",
    "        if hidden is not None and hidden.ndim == 2:\n",
    "            hidden = hidden.unsqueeze(0)\n",
    "\n",
    "        logits_trim = logits[:, valid_pos, :].contiguous()\n",
    "        targets_trim = targets[:, valid_pos].contiguous()\n",
    "        hidden_trim = hidden[:, valid_pos, :].contiguous() if hidden is not None else None\n",
    "\n",
    "        row_out = dict(row)\n",
    "        row_out[f\"logits_{lens_type}\"] = logits_trim\n",
    "        row_out[f\"hidden_{lens_type}\"] = hidden_trim\n",
    "        row_out[\"target_ids\"] = targets_trim\n",
    "        processed.append(row_out)\n",
    "\n",
    "    return processed\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Compute metrics and top-k similarities for A vs B\n",
    "# ============================================================\n",
    "@torch.no_grad()\n",
    "def compute_topk(\n",
    "    metrics_A,\n",
    "    metrics_B,\n",
    "    norm_modes=(\"raw\", \"unit_rms\", \"norm_rms\"),\n",
    "    topk=(1, 5, 10, 20),\n",
    "    device=\"cpu\",\n",
    "    eps = 1e-12,\n",
    "    output_dir=\"logs/new_summary\",\n",
    "    run_name=None,\n",
    "    batch_idx=None,\n",
    "    debug=False,\n",
    "):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # --- safe clean helper ---\n",
    "    \"\"\"def clean(x):\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            x = x.detach().to(\"cpu\", copy=False).float()\n",
    "            x = torch.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "            return x.tolist()\n",
    "        return x\"\"\"\n",
    "    def clean(x):\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            x = x.detach().to(\"cpu\", copy=False).float()\n",
    "            x = torch.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "            return x.view(-1).tolist()\n",
    "        elif isinstance(x, (list, np.ndarray)):\n",
    "            return [float(v) if np.isfinite(v) else 0.0 for v in x]\n",
    "        else:\n",
    "            return float(x) if np.isfinite(x) else 0.0\n",
    "\n",
    "    # --- preprocess all normalization modes ---\n",
    "    proc_modes = {\n",
    "        m: (preprocess_metrics(metrics_A, m), preprocess_metrics(metrics_B, m))\n",
    "        for m in norm_modes\n",
    "    }\n",
    "\n",
    "    if debug:\n",
    "        print(f\"[mask cache] built for {len(_mask_cache)} prompt_ids\")\n",
    "        for pid, mask in list(_mask_cache.items())[:10]: \n",
    "            print(f\"  prompt_id={pid:<5} → len={len(mask)}  positions={mask.tolist()}\")\n",
    "        lengths = [len(v) for v in _mask_cache.values()]\n",
    "        print(f\"  unique mask lengths: {sorted(set(lengths))}\")\n",
    "\n",
    "    rec_map = {}\n",
    "\n",
    "    # --- main computation ---\n",
    "    for mode in norm_modes:\n",
    "        A_trim, B_trim = proc_modes[mode]\n",
    "        if not A_trim or not B_trim:\n",
    "            if debug:\n",
    "                print(f\"[skip] no valid rows for mode={mode}\")\n",
    "            continue\n",
    "\n",
    "        for rA in A_trim:\n",
    "            pid, lid = rA[\"prompt_id\"], rA[\"layer_index\"]\n",
    "            rB = next((r for r in B_trim if r.get(\"prompt_id\") == pid and r.get(\"layer_index\") == lid), None)\n",
    "            if rB is None:\n",
    "                continue\n",
    "\n",
    "            key = (pid, lid)\n",
    "            record = rec_map.setdefault(\n",
    "                key,\n",
    "                dict(\n",
    "                    prompt_id=pid,\n",
    "                    batch_index=rA.get(\"batch_index\", batch_idx),\n",
    "                    layer_index=lid,\n",
    "                    layer_name=rA.get(\"layer_name\"),\n",
    "                    prompt_text=rA.get(\"prompt_text\"),\n",
    "                ),\n",
    "            )\n",
    "\n",
    "            # --- tensor setup ---\n",
    "            logits_A, logits_B = rA[f\"logits_{mode}\"], rB[f\"logits_{mode}\"]\n",
    "            targets = rA[\"target_ids\"]\n",
    "            hidden_A, hidden_B = rA.get(f\"hidden_{mode}\"), rB.get(f\"hidden_{mode}\")\n",
    "\n",
    "            if logits_A.ndim == 2: logits_A = logits_A.unsqueeze(0)\n",
    "            if logits_B.ndim == 2: logits_B = logits_B.unsqueeze(0)\n",
    "            if targets.ndim == 1: targets = targets.unsqueeze(0)\n",
    "\n",
    "            logits_A, logits_B = logits_A.to(device).float(), logits_B.to(device).float()\n",
    "            targets = targets.to(device)\n",
    "            if hidden_A is not None: hidden_A = hidden_A.to(device).float()\n",
    "            if hidden_B is not None: hidden_B = hidden_B.to(device).float()\n",
    "\n",
    "            L = targets.size(1)\n",
    "            logits_A, logits_B = logits_A[:, :L, :], logits_B[:, :L, :]\n",
    "            if hidden_A is not None: hidden_A = hidden_A[:, :L, :]\n",
    "            if hidden_B is not None: hidden_B = hidden_B[:, :L, :]\n",
    "\n",
    "            vocab = max(logits_A.size(-1), logits_B.size(-1))\n",
    "            if logits_A.size(-1) < vocab:\n",
    "                logits_A = F.pad(logits_A, (0, vocab - logits_A.size(-1)))\n",
    "            if logits_B.size(-1) < vocab:\n",
    "                logits_B = F.pad(logits_B, (0, vocab - logits_B.size(-1)))\n",
    "\n",
    "            # --- probability space ---\n",
    "            logp_A = F.log_softmax(logits_A, dim=-1)\n",
    "            logp_B = F.log_softmax(logits_B, dim=-1)\n",
    "\n",
    "            # Compute probabilities cleanly and normalize to avoid drift\n",
    "            pA = torch.exp(logp_A)\n",
    "            pB = torch.exp(logp_B)\n",
    "\n",
    "            # Explicit renormalization (prevents underflow/rounding issues)\n",
    "            pA = pA / (pA.sum(-1, keepdim=True) + eps)\n",
    "            pB = pB / (pB.sum(-1, keepdim=True) + eps)\n",
    "\n",
    "            # unpack first dimension (batch=1)\n",
    "            logp_A, logp_B = logp_A[0], logp_B[0]\n",
    "            pA, pB, tgt = pA[0], pB[0], targets[0]\n",
    "\n",
    "            # --- basic metrics ---\n",
    "            kl_ab = torch.sum(pA * (logp_A - logp_B), dim=-1).clamp_min(0.0)\n",
    "            kl_ba = torch.sum(pB * (logp_B - logp_A), dim=-1).clamp_min(0.0)\n",
    "            js_div = 0.5 * (kl_ab + kl_ba)\n",
    "            js_dist = torch.sqrt(torch.clamp(js_div, min=0.0) + eps)\n",
    "\n",
    "            # move to cpu and clean\n",
    "            kl_ab = clean(kl_ab)\n",
    "            kl_ba = clean(kl_ba)\n",
    "            js_div = clean(js_div)\n",
    "            js_dist = clean(js_dist)\n",
    "\n",
    "            # TVD and entropy\n",
    "            tvd = clean(0.5 * torch.sum(torch.abs(pA - pB), dim=-1))\n",
    "            entropy_A = clean(-torch.sum(pA * logp_A, dim=-1))\n",
    "            entropy_B = clean(-torch.sum(pB * logp_B, dim=-1))\n",
    "\n",
    "\n",
    "            # === per-position L2 ===\n",
    "            if hidden_A is not None and hidden_B is not None:\n",
    "                cosine = clean(F.cosine_similarity(hidden_A[0], hidden_B[0], dim=-1))\n",
    "                l2_tensor = torch.sqrt(torch.sum((hidden_A[0] - hidden_B[0]) ** 2, dim=-1))\n",
    "                l2 = clean(l2_tensor)\n",
    "                #if debug:\n",
    "                    #print(f\"[debug] pid={pid} lid={lid} L2 shape={l2_tensor.shape} mean={l2_tensor.mean().item():.3g}\")\n",
    "            else:\n",
    "                cosine, l2 = [0.0] * L, [0.0] * L\n",
    "\n",
    "            # --- other metrics ---\n",
    "            logp_diff = clean(\n",
    "                torch.gather(logp_A, -1, tgt.unsqueeze(-1)).squeeze(-1)\n",
    "                - torch.gather(logp_B, -1, tgt.unsqueeze(-1)).squeeze(-1)\n",
    "            )\n",
    "\n",
    "            # probability rations\n",
    "\n",
    "            \"\"\"ce_A = F.cross_entropy(logits_A.view(-1, vocab), targets.view(-1))\n",
    "            ce_B = F.cross_entropy(logits_B.view(-1, vocab), targets.view(-1))\n",
    "            ppl_A, ppl_B = float(torch.exp(ce_A)), float(torch.exp(ce_B))\"\"\"\n",
    "            # === per-position cross-entropy and perplexity ===\n",
    "            ce_A_pos = F.cross_entropy(\n",
    "                logits_A.view(-1, vocab), targets.view(-1), reduction=\"none\"\n",
    "            ).view(targets.shape)\n",
    "            ce_B_pos = F.cross_entropy(\n",
    "                logits_B.view(-1, vocab), targets.view(-1), reduction=\"none\"\n",
    "            ).view(targets.shape)\n",
    "\n",
    "            # Compute per-position perplexity\n",
    "            ppl_A_pos = torch.exp(ce_A_pos)\n",
    "            ppl_B_pos = torch.exp(ce_B_pos)\n",
    "\n",
    "            # Convert everything safely to Python lists\n",
    "            ppl_A_pos = clean(ppl_A_pos)\n",
    "            ppl_B_pos = clean(ppl_B_pos)\n",
    "\n",
    "            # Compute per-position difference as list comprehension to avoid tensor ops\n",
    "            ppl_diff = [a - b for a, b in zip(ppl_A_pos, ppl_B_pos)]\n",
    "\n",
    "            record.update(\n",
    "                {\n",
    "                    f\"kl_ab_{mode}\": kl_ab,\n",
    "                    f\"kl_ba_{mode}\": kl_ba,\n",
    "                    f\"js_div_{mode}\": js_div,\n",
    "                    f\"js_dist_{mode}\": js_dist,\n",
    "                    f\"tvd_{mode}\": tvd,\n",
    "                    f\"entropy_A_{mode}\": entropy_A,\n",
    "                    f\"entropy_B_{mode}\": entropy_B,\n",
    "                    f\"cosine_sim_{mode}\": cosine,\n",
    "                    f\"l2_dist_{mode}\": l2,   \n",
    "                    f\"logp_diff_{mode}\": logp_diff,\n",
    "                    #f\"ppl_A_{mode}\": [ppl_A],\n",
    "                    #f\"ppl_B_{mode}\": [ppl_B],\n",
    "                    #f\"ppl_diff_{mode}\": [ppl_A - ppl_B],\n",
    "                    f\"ppl_A_{mode}\": ppl_A_pos,\n",
    "                    f\"ppl_B_{mode}\": ppl_B_pos,\n",
    "                    f\"ppl_diff_{mode}\": ppl_diff,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # === top-k metrics ===\n",
    "            fams = {key: {} for key in [\n",
    "                f\"acc_A_{mode}\", f\"acc_B_{mode}\",\n",
    "                f\"jaccard_{mode}\", f\"disagree_set_{mode}\", f\"agree_set_{mode}\",\n",
    "                f\"agree_correct_{mode}\", f\"disagree_correct_{mode}\",\n",
    "                f\"agree_wrong_{mode}\", f\"prob_overlap_{mode}\",\n",
    "                f\"top_pred_ids_A_{mode}\", f\"top_pred_vals_A_{mode}\",\n",
    "                f\"top_pred_ids_B_{mode}\", f\"top_pred_vals_B_{mode}\"\n",
    "            ]}\n",
    "\n",
    "            max_k = max(topk)\n",
    "            top_vals_A, top_idx_A = torch.topk(pA, max_k, -1)\n",
    "            top_vals_B, top_idx_B = torch.topk(pB, max_k, -1)\n",
    "\n",
    "            top_vals_A, top_vals_B = top_vals_A.cpu(), top_vals_B.cpu()\n",
    "            top_idx_A, top_idx_B = top_idx_A.cpu(), top_idx_B.cpu()\n",
    "            tgt_cpu = tgt.cpu()\n",
    "\n",
    "            for k in topk:\n",
    "                tkA, tkB = top_idx_A[:, :k], top_idx_B[:, :k]\n",
    "                tvA, tvB = top_vals_A[:, :k], top_vals_B[:, :k]\n",
    "\n",
    "                acc_A = (tkA == tgt_cpu.unsqueeze(1)).any(1).float()\n",
    "                acc_B = (tkB == tgt_cpu.unsqueeze(1)).any(1).float()\n",
    "\n",
    "                # --- set overlap ---\n",
    "                inter = torch.tensor(\n",
    "                    [len(set(tkA[i].tolist()) & set(tkB[i].tolist())) for i in range(L)],\n",
    "                    dtype=torch.float32,\n",
    "                )\n",
    "                jaccard = inter / (2 * k - inter + eps)\n",
    "                disagree_set = 1.0 - jaccard\n",
    "                agree_set = (inter > 0).float()\n",
    "\n",
    "                # --- correctness relations ---\n",
    "                agree_correct = acc_A * acc_B\n",
    "                disagree_correct = ((acc_A + acc_B).round() == 1).float()  # XOR\n",
    "                agree_wrong = ((1 - acc_A) * (1 - acc_B)).float()\n",
    "\n",
    "                # --- probability mass overlap ---\n",
    "                pmA, pmB = tvA.sum(1), tvB.sum(1)\n",
    "                shared_mass = torch.zeros_like(pmA)\n",
    "                for i in range(L):\n",
    "                    shared = set(tkA[i].tolist()) & set(tkB[i].tolist())\n",
    "                    if shared:\n",
    "                        shared_mass[i] = 0.5 * (\n",
    "                            pA[i, list(shared)].sum().cpu() + pB[i, list(shared)].sum().cpu()\n",
    "                        )\n",
    "                prob_overlap = shared_mass / (0.5 * (pmA + pmB) + eps)\n",
    "\n",
    "                # --- save results ---\n",
    "                fams[f\"acc_A_{mode}\"][f\"@{k}\"] = acc_A.tolist()\n",
    "                fams[f\"acc_B_{mode}\"][f\"@{k}\"] = acc_B.tolist()\n",
    "                fams[f\"jaccard_{mode}\"][f\"@{k}\"] = jaccard.tolist()\n",
    "                fams[f\"disagree_set_{mode}\"][f\"@{k}\"] = disagree_set.tolist()\n",
    "                fams[f\"agree_set_{mode}\"][f\"@{k}\"] = agree_set.tolist()\n",
    "                fams[f\"agree_correct_{mode}\"][f\"@{k}\"] = agree_correct.tolist()\n",
    "                fams[f\"disagree_correct_{mode}\"][f\"@{k}\"] = disagree_correct.tolist()\n",
    "                fams[f\"agree_wrong_{mode}\"][f\"@{k}\"] = agree_wrong.tolist()\n",
    "                fams[f\"prob_overlap_{mode}\"][f\"@{k}\"] = prob_overlap.tolist()\n",
    "\n",
    "                # top predictions\n",
    "                if k == 1:\n",
    "                    fams[f\"top_pred_ids_A_{mode}\"][f\"@{k}\"] = [int(x) for x in tkA[:, 0].tolist()]\n",
    "                    fams[f\"top_pred_vals_A_{mode}\"][f\"@{k}\"] = [float(x) for x in tvA[:, 0].tolist()]\n",
    "                    fams[f\"top_pred_ids_B_{mode}\"][f\"@{k}\"] = [int(x) for x in tkB[:, 0].tolist()]\n",
    "                    fams[f\"top_pred_vals_B_{mode}\"][f\"@{k}\"] = [float(x) for x in tvB[:, 0].tolist()]\n",
    "                else:\n",
    "                    fams[f\"top_pred_ids_A_{mode}\"][f\"@{k}\"] = [[int(x) for x in arr] for arr in tkA.tolist()]\n",
    "                    fams[f\"top_pred_vals_A_{mode}\"][f\"@{k}\"] = [[float(x) for x in arr] for arr in tvA.tolist()]\n",
    "                    fams[f\"top_pred_ids_B_{mode}\"][f\"@{k}\"] = [[int(x) for x in arr] for arr in tkB.tolist()]\n",
    "                    fams[f\"top_pred_vals_B_{mode}\"][f\"@{k}\"] = [[float(x) for x in arr] for arr in tvB.tolist()]\n",
    "\n",
    "\n",
    "            record.update(fams)\n",
    "\n",
    "            # --- cleanup per iteration ---\n",
    "            del logits_A, logits_B, logp_A, logp_B, pA, pB, hidden_A, hidden_B, targets\n",
    "            gc.collect()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    # --- finalize and save ---\n",
    "    df = pd.DataFrame(list(rec_map.values()), dtype=object)\n",
    "    out_path = os.path.join(output_dir, f\"{run_name or 'run'}_batch{int(batch_idx or 0):03d}.parquet\")\n",
    "    df.to_parquet(out_path, index=False)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"[saved] {len(df)} rows → {out_path}\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27f667ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc, torch, psutil\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def mem_report(note=\"\"):\n",
    "    mem = psutil.virtual_memory()\n",
    "    print(f\"[mem] {note} used {mem.used/1e9:.1f} / {mem.total/1e9:.1f} GB\")\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def run_topk_streaming(\n",
    "    dir_A,\n",
    "    dir_B,\n",
    "    output_dir=\"saved_data/topk\",\n",
    "    norm_modes=(\"raw\",\"unit_rms\",\"norm_rms\"),\n",
    "    topk=(1,5,10,20),\n",
    "    device=None,\n",
    "    run_name=\"run\",\n",
    "    debug=True\n",
    "):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    files_A = sorted([f for f in os.listdir(dir_A) if f.endswith(\".pt\")])\n",
    "    files_B = sorted([f for f in os.listdir(dir_B) if f.endswith(\".pt\")])\n",
    "    assert len(files_A) == len(files_B), \"Mismatch in number of files\"\n",
    "\n",
    "    print(f\"[info] Found {len(files_A)} file pairs to process\")\n",
    "\n",
    "    for batch_idx, (fa, fb) in enumerate(tqdm(zip(files_A, files_B), total=len(files_A))):\n",
    "        path_A = os.path.join(dir_A, fa)\n",
    "        path_B = os.path.join(dir_B, fb)\n",
    "        print(f\"\\n[batch {batch_idx}] {fa} vs {fb}\")\n",
    "        mem_report(\"before loading\")\n",
    "\n",
    "        metrics_A = torch.load(path_A, map_location=\"cpu\")\n",
    "        metrics_B = torch.load(path_B, map_location=\"cpu\")\n",
    "\n",
    "        print(\"  [compute] running compute_topk ...\")\n",
    "        df = compute_topk(\n",
    "            metrics_A,\n",
    "            metrics_B,\n",
    "            norm_modes=norm_modes,\n",
    "            topk=topk,\n",
    "            device=device,\n",
    "            output_dir=output_dir,\n",
    "            run_name=run_name,\n",
    "            batch_idx=batch_idx,\n",
    "            debug=debug\n",
    "        )\n",
    "\n",
    "        print(f\"  [saved] {run_name}_batch{batch_idx}.parquet\")\n",
    "\n",
    "        del df, metrics_A, metrics_B\n",
    "        _mask_cache.clear()\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        mem_report(\"after cleanup\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00a7a6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Found 50 file pairs to process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[batch 0] m_orig_modes_batch000.pt vs m_4bit_modes_batch000.pt\n",
      "[mem] before loading used 5.2 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=1     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=2     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=3     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=4     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=5     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=6     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=7     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=8     → len=15  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "  prompt_id=9     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  unique mask lengths: [8, 9, 10, 11, 15]\n",
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch000.parquet\n",
      "  [saved] m_orig_m_4bit_batch0.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [02:31<2:04:04, 151.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mem] after cleanup used 6.7 / 66.6 GB\n",
      "\n",
      "[batch 1] m_orig_modes_batch001.pt vs m_4bit_modes_batch001.pt\n",
      "[mem] before loading used 6.7 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=1     → len=15  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "  prompt_id=2     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=3     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=4     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=5     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=6     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=7     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=8     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=9     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  unique mask lengths: [8, 9, 10, 11, 15]\n",
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch001.parquet\n",
      "  [saved] m_orig_m_4bit_batch1.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [05:09<2:04:01, 155.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mem] after cleanup used 17.5 / 66.6 GB\n",
      "\n",
      "[batch 2] m_orig_modes_batch002.pt vs m_4bit_modes_batch002.pt\n",
      "[mem] before loading used 17.5 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=1     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=2     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=3     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=4     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=5     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=6     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=7     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=8     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=9     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  unique mask lengths: [8, 9, 10, 11]\n",
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch002.parquet\n",
      "  [saved] m_orig_m_4bit_batch2.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [07:59<2:07:01, 162.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mem] after cleanup used 27.4 / 66.6 GB\n",
      "\n",
      "[batch 3] m_orig_modes_batch003.pt vs m_4bit_modes_batch003.pt\n",
      "[mem] before loading used 27.4 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=1     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=2     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=3     → len=13  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "  prompt_id=4     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=5     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=6     → len=12  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  prompt_id=7     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=8     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=9     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  unique mask lengths: [8, 9, 10, 11, 12, 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [10:51<2:07:10, 165.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch003.parquet\n",
      "  [saved] m_orig_m_4bit_batch3.parquet\n",
      "[mem] after cleanup used 34.9 / 66.6 GB\n",
      "\n",
      "[batch 4] m_orig_modes_batch004.pt vs m_4bit_modes_batch004.pt\n",
      "[mem] before loading used 34.9 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=15  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "  prompt_id=1     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=2     → len=12  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  prompt_id=3     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=4     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=5     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=6     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=7     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=8     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=9     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  unique mask lengths: [8, 9, 10, 11, 12, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [13:41<2:05:29, 167.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch004.parquet\n",
      "  [saved] m_orig_m_4bit_batch4.parquet\n",
      "[mem] after cleanup used 35.2 / 66.6 GB\n",
      "\n",
      "[batch 5] m_orig_modes_batch005.pt vs m_4bit_modes_batch005.pt\n",
      "[mem] before loading used 35.2 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=1     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=2     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=3     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=4     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=5     → len=15  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "  prompt_id=6     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=7     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=8     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=9     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  unique mask lengths: [8, 9, 10, 11, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [16:26<2:02:11, 166.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch005.parquet\n",
      "  [saved] m_orig_m_4bit_batch5.parquet\n",
      "[mem] after cleanup used 34.9 / 66.6 GB\n",
      "\n",
      "[batch 6] m_orig_modes_batch006.pt vs m_4bit_modes_batch006.pt\n",
      "[mem] before loading used 34.9 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=1     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=2     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=3     → len=13  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "  prompt_id=4     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=5     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=6     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=7     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=8     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=9     → len=15  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "  unique mask lengths: [8, 9, 10, 11, 13, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [19:17<2:00:24, 168.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch006.parquet\n",
      "  [saved] m_orig_m_4bit_batch6.parquet\n",
      "[mem] after cleanup used 35.1 / 66.6 GB\n",
      "\n",
      "[batch 7] m_orig_modes_batch007.pt vs m_4bit_modes_batch007.pt\n",
      "[mem] before loading used 35.1 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=1     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=2     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=3     → len=13  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "  prompt_id=4     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=5     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=6     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=7     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=8     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=9     → len=12  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  unique mask lengths: [8, 9, 10, 12, 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [21:58<1:56:00, 165.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch007.parquet\n",
      "  [saved] m_orig_m_4bit_batch7.parquet\n",
      "[mem] after cleanup used 35.5 / 66.6 GB\n",
      "\n",
      "[batch 8] m_orig_modes_batch008.pt vs m_4bit_modes_batch008.pt\n",
      "[mem] before loading used 35.5 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=1     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=2     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=3     → len=14  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "  prompt_id=4     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=5     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=6     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=7     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=8     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=9     → len=13  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "  unique mask lengths: [8, 9, 11, 13, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [24:51<1:54:55, 168.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch008.parquet\n",
      "  [saved] m_orig_m_4bit_batch8.parquet\n",
      "[mem] after cleanup used 35.7 / 66.6 GB\n",
      "\n",
      "[batch 9] m_orig_modes_batch009.pt vs m_4bit_modes_batch009.pt\n",
      "[mem] before loading used 35.7 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=13  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "  prompt_id=1     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=2     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=3     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=4     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=5     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=6     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=7     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=8     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=9     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  unique mask lengths: [8, 9, 10, 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [27:43<1:52:49, 169.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch009.parquet\n",
      "  [saved] m_orig_m_4bit_batch9.parquet\n",
      "[mem] after cleanup used 35.3 / 66.6 GB\n",
      "\n",
      "[batch 10] m_orig_modes_batch010.pt vs m_4bit_modes_batch010.pt\n",
      "[mem] before loading used 35.3 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=1     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=2     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=3     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=4     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=5     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=6     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=7     → len=12  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  prompt_id=8     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=9     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  unique mask lengths: [8, 9, 10, 11, 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [30:36<1:50:46, 170.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch010.parquet\n",
      "  [saved] m_orig_m_4bit_batch10.parquet\n",
      "[mem] after cleanup used 35.3 / 66.6 GB\n",
      "\n",
      "[batch 11] m_orig_modes_batch011.pt vs m_4bit_modes_batch011.pt\n",
      "[mem] before loading used 35.3 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=1     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=2     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=3     → len=15  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "  prompt_id=4     → len=15  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "  prompt_id=5     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=6     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=7     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=8     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=9     → len=13  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "  unique mask lengths: [8, 9, 10, 11, 13, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [33:31<1:48:52, 171.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch011.parquet\n",
      "  [saved] m_orig_m_4bit_batch11.parquet\n",
      "[mem] after cleanup used 34.9 / 66.6 GB\n",
      "\n",
      "[batch 12] m_orig_modes_batch012.pt vs m_4bit_modes_batch012.pt\n",
      "[mem] before loading used 34.9 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=14  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "  prompt_id=1     → len=14  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "  prompt_id=2     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=3     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=4     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=5     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=6     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=7     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=8     → len=12  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  prompt_id=9     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  unique mask lengths: [8, 9, 10, 11, 12, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [36:25<1:46:19, 172.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch012.parquet\n",
      "  [saved] m_orig_m_4bit_batch12.parquet\n",
      "[mem] after cleanup used 34.9 / 66.6 GB\n",
      "\n",
      "[batch 13] m_orig_modes_batch013.pt vs m_4bit_modes_batch013.pt\n",
      "[mem] before loading used 34.9 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=1     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=2     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=3     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=4     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=5     → len=15  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "  prompt_id=6     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=7     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=8     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=9     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  unique mask lengths: [8, 9, 10, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [39:19<1:43:41, 172.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch013.parquet\n",
      "  [saved] m_orig_m_4bit_batch13.parquet\n",
      "[mem] after cleanup used 34.8 / 66.6 GB\n",
      "\n",
      "[batch 14] m_orig_modes_batch014.pt vs m_4bit_modes_batch014.pt\n",
      "[mem] before loading used 34.8 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=1     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=2     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=3     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=4     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=5     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=6     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=7     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=8     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=9     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  unique mask lengths: [8, 9, 10, 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [42:11<1:40:45, 172.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch014.parquet\n",
      "  [saved] m_orig_m_4bit_batch14.parquet\n",
      "[mem] after cleanup used 34.6 / 66.6 GB\n",
      "\n",
      "[batch 15] m_orig_modes_batch015.pt vs m_4bit_modes_batch015.pt\n",
      "[mem] before loading used 34.6 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=1     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=2     → len=13  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "  prompt_id=3     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=4     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=5     → len=15  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "  prompt_id=6     → len=12  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  prompt_id=7     → len=14  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "  prompt_id=8     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=9     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  unique mask lengths: [9, 10, 11, 12, 13, 14, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [45:08<1:38:37, 174.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch015.parquet\n",
      "  [saved] m_orig_m_4bit_batch15.parquet\n",
      "[mem] after cleanup used 35.6 / 66.6 GB\n",
      "\n",
      "[batch 16] m_orig_modes_batch016.pt vs m_4bit_modes_batch016.pt\n",
      "[mem] before loading used 35.6 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=1     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=2     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=3     → len=15  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "  prompt_id=4     → len=13  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "  prompt_id=5     → len=14  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "  prompt_id=6     → len=15  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "  prompt_id=7     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=8     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=9     → len=12  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  unique mask lengths: [9, 10, 11, 12, 13, 14, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [48:06<1:36:17, 175.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch016.parquet\n",
      "  [saved] m_orig_m_4bit_batch16.parquet\n",
      "[mem] after cleanup used 36.4 / 66.6 GB\n",
      "\n",
      "[batch 17] m_orig_modes_batch017.pt vs m_4bit_modes_batch017.pt\n",
      "[mem] before loading used 36.4 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=1     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=2     → len=14  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "  prompt_id=3     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=4     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=5     → len=12  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  prompt_id=6     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=7     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=8     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=9     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  unique mask lengths: [9, 10, 11, 12, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [50:55<1:32:28, 173.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch017.parquet\n",
      "  [saved] m_orig_m_4bit_batch17.parquet\n",
      "[mem] after cleanup used 36.4 / 66.6 GB\n",
      "\n",
      "[batch 18] m_orig_modes_batch018.pt vs m_4bit_modes_batch018.pt\n",
      "[mem] before loading used 36.4 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=1     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=2     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=3     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=4     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=5     → len=12  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  prompt_id=6     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=7     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=8     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=9     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  unique mask lengths: [8, 9, 10, 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [53:32<1:27:04, 168.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch018.parquet\n",
      "  [saved] m_orig_m_4bit_batch18.parquet\n",
      "[mem] after cleanup used 36.2 / 66.6 GB\n",
      "\n",
      "[batch 19] m_orig_modes_batch019.pt vs m_4bit_modes_batch019.pt\n",
      "[mem] before loading used 36.2 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=1     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=2     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=3     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=4     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=5     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=6     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=7     → len=12  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  prompt_id=8     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=9     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  unique mask lengths: [8, 9, 10, 11, 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [56:08<1:22:16, 164.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch019.parquet\n",
      "  [saved] m_orig_m_4bit_batch19.parquet\n",
      "[mem] after cleanup used 36.3 / 66.6 GB\n",
      "\n",
      "[batch 20] m_orig_modes_batch020.pt vs m_4bit_modes_batch020.pt\n",
      "[mem] before loading used 36.3 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=13  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "  prompt_id=1     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=2     → len=12  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  prompt_id=3     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=4     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=5     → len=13  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "  prompt_id=6     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=7     → len=12  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  prompt_id=8     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=9     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  unique mask lengths: [8, 9, 10, 11, 12, 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [58:42<1:18:04, 161.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch020.parquet\n",
      "  [saved] m_orig_m_4bit_batch20.parquet\n",
      "[mem] after cleanup used 35.1 / 66.6 GB\n",
      "\n",
      "[batch 21] m_orig_modes_batch021.pt vs m_4bit_modes_batch021.pt\n",
      "[mem] before loading used 35.1 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=1     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=2     → len=12  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  prompt_id=3     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=4     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=5     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=6     → len=12  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  prompt_id=7     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=8     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=9     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  unique mask lengths: [8, 9, 10, 11, 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [1:01:16<1:14:16, 159.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch021.parquet\n",
      "  [saved] m_orig_m_4bit_batch21.parquet\n",
      "[mem] after cleanup used 35.0 / 66.6 GB\n",
      "\n",
      "[batch 22] m_orig_modes_batch022.pt vs m_4bit_modes_batch022.pt\n",
      "[mem] before loading used 35.0 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=1     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=2     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=3     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=4     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=5     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=6     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=7     → len=13  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "  prompt_id=8     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=9     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  unique mask lengths: [8, 10, 11, 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [1:03:51<1:11:08, 158.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch022.parquet\n",
      "  [saved] m_orig_m_4bit_batch22.parquet\n",
      "[mem] after cleanup used 35.1 / 66.6 GB\n",
      "\n",
      "[batch 23] m_orig_modes_batch023.pt vs m_4bit_modes_batch023.pt\n",
      "[mem] before loading used 35.1 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=12  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  prompt_id=1     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=2     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=3     → len=15  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "  prompt_id=4     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=5     → len=12  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  prompt_id=6     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=7     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=8     → len=12  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  prompt_id=9     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  unique mask lengths: [8, 9, 10, 11, 12, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [1:06:29<1:08:23, 157.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch023.parquet\n",
      "  [saved] m_orig_m_4bit_batch23.parquet\n",
      "[mem] after cleanup used 35.4 / 66.6 GB\n",
      "\n",
      "[batch 24] m_orig_modes_batch024.pt vs m_4bit_modes_batch024.pt\n",
      "[mem] before loading used 35.4 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=1     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=2     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=3     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=4     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=5     → len=12  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  prompt_id=6     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=7     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=8     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=9     → len=14  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "  unique mask lengths: [8, 9, 10, 12, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [1:09:03<1:05:22, 156.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch024.parquet\n",
      "  [saved] m_orig_m_4bit_batch24.parquet\n",
      "[mem] after cleanup used 35.1 / 66.6 GB\n",
      "\n",
      "[batch 25] m_orig_modes_batch025.pt vs m_4bit_modes_batch025.pt\n",
      "[mem] before loading used 35.1 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=1     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=2     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=3     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=4     → len=14  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "  prompt_id=5     → len=14  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "  prompt_id=6     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=7     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=8     → len=15  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "  prompt_id=9     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  unique mask lengths: [8, 9, 10, 11, 14, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [1:11:40<1:02:41, 156.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch025.parquet\n",
      "  [saved] m_orig_m_4bit_batch25.parquet\n",
      "[mem] after cleanup used 35.6 / 66.6 GB\n",
      "\n",
      "[batch 26] m_orig_modes_batch026.pt vs m_4bit_modes_batch026.pt\n",
      "[mem] before loading used 35.6 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=1     → len=12  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  prompt_id=2     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=3     → len=12  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  prompt_id=4     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=5     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=6     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=7     → len=14  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "  prompt_id=8     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=9     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  unique mask lengths: [8, 9, 10, 12, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [1:14:17<1:00:05, 156.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch026.parquet\n",
      "  [saved] m_orig_m_4bit_batch26.parquet\n",
      "[mem] after cleanup used 36.0 / 66.6 GB\n",
      "\n",
      "[batch 27] m_orig_modes_batch027.pt vs m_4bit_modes_batch027.pt\n",
      "[mem] before loading used 36.0 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=1     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=2     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=3     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=4     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=5     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=6     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=7     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=8     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=9     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  unique mask lengths: [8, 9, 10, 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [1:16:50<57:09, 155.89s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch027.parquet\n",
      "  [saved] m_orig_m_4bit_batch27.parquet\n",
      "[mem] after cleanup used 35.1 / 66.6 GB\n",
      "\n",
      "[batch 28] m_orig_modes_batch028.pt vs m_4bit_modes_batch028.pt\n",
      "[mem] before loading used 35.1 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=1     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=2     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=3     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=4     → len=15  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "  prompt_id=5     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=6     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=7     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=8     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=9     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  unique mask lengths: [8, 9, 10, 11, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [1:19:24<54:22, 155.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch028.parquet\n",
      "  [saved] m_orig_m_4bit_batch28.parquet\n",
      "[mem] after cleanup used 35.5 / 66.6 GB\n",
      "\n",
      "[batch 29] m_orig_modes_batch029.pt vs m_4bit_modes_batch029.pt\n",
      "[mem] before loading used 35.5 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=1     → len=15  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "  prompt_id=2     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=3     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=4     → len=12  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  prompt_id=5     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=6     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=7     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=8     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=9     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  unique mask lengths: [8, 9, 10, 11, 12, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [1:22:00<51:48, 155.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch029.parquet\n",
      "  [saved] m_orig_m_4bit_batch29.parquet\n",
      "[mem] after cleanup used 35.9 / 66.6 GB\n",
      "\n",
      "[batch 30] m_orig_modes_batch030.pt vs m_4bit_modes_batch030.pt\n",
      "[mem] before loading used 35.9 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=12  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  prompt_id=1     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=2     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=3     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=4     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=5     → len=13  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "  prompt_id=6     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=7     → len=15  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "  prompt_id=8     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=9     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  unique mask lengths: [9, 10, 11, 12, 13, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [1:24:37<49:22, 155.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch030.parquet\n",
      "  [saved] m_orig_m_4bit_batch30.parquet\n",
      "[mem] after cleanup used 35.9 / 66.6 GB\n",
      "\n",
      "[batch 31] m_orig_modes_batch031.pt vs m_4bit_modes_batch031.pt\n",
      "[mem] before loading used 35.9 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=1     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=2     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=3     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=4     → len=15  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "  prompt_id=5     → len=14  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "  prompt_id=6     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=7     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=8     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=9     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  unique mask lengths: [8, 9, 10, 11, 14, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [1:27:16<47:00, 156.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch031.parquet\n",
      "  [saved] m_orig_m_4bit_batch31.parquet\n",
      "[mem] after cleanup used 35.9 / 66.6 GB\n",
      "\n",
      "[batch 32] m_orig_modes_batch032.pt vs m_4bit_modes_batch032.pt\n",
      "[mem] before loading used 35.9 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=15  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "  prompt_id=1     → len=12  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  prompt_id=2     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=3     → len=15  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "  prompt_id=4     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=5     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=6     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=7     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=8     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=9     → len=12  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  unique mask lengths: [9, 10, 11, 12, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [1:29:55<44:37, 157.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch032.parquet\n",
      "  [saved] m_orig_m_4bit_batch32.parquet\n",
      "[mem] after cleanup used 36.6 / 66.6 GB\n",
      "\n",
      "[batch 33] m_orig_modes_batch033.pt vs m_4bit_modes_batch033.pt\n",
      "[mem] before loading used 36.6 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=1     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=2     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=3     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=4     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=5     → len=12  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  prompt_id=6     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=7     → len=12  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  prompt_id=8     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=9     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  unique mask lengths: [8, 9, 10, 11, 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [1:32:31<41:54, 157.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch033.parquet\n",
      "  [saved] m_orig_m_4bit_batch33.parquet\n",
      "[mem] after cleanup used 36.6 / 66.6 GB\n",
      "\n",
      "[batch 34] m_orig_modes_batch034.pt vs m_4bit_modes_batch034.pt\n",
      "[mem] before loading used 36.6 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=14  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "  prompt_id=1     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=2     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=3     → len=13  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "  prompt_id=4     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=5     → len=13  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "  prompt_id=6     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=7     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=8     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=9     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  unique mask lengths: [8, 9, 10, 11, 13, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [1:35:09<39:18, 157.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch034.parquet\n",
      "  [saved] m_orig_m_4bit_batch34.parquet\n",
      "[mem] after cleanup used 36.1 / 66.6 GB\n",
      "\n",
      "[batch 35] m_orig_modes_batch035.pt vs m_4bit_modes_batch035.pt\n",
      "[mem] before loading used 36.1 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=1     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=2     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=3     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=4     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=5     → len=12  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  prompt_id=6     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=7     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=8     → len=15  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "  prompt_id=9     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  unique mask lengths: [8, 9, 10, 11, 12, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [1:37:45<36:35, 156.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch035.parquet\n",
      "  [saved] m_orig_m_4bit_batch35.parquet\n",
      "[mem] after cleanup used 35.4 / 66.6 GB\n",
      "\n",
      "[batch 36] m_orig_modes_batch036.pt vs m_4bit_modes_batch036.pt\n",
      "[mem] before loading used 35.4 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=14  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "  prompt_id=1     → len=14  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "  prompt_id=2     → len=12  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  prompt_id=3     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=4     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=5     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=6     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=7     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=8     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=9     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  unique mask lengths: [8, 9, 10, 12, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [1:40:23<34:03, 157.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch036.parquet\n",
      "  [saved] m_orig_m_4bit_batch36.parquet\n",
      "[mem] after cleanup used 35.5 / 66.6 GB\n",
      "\n",
      "[batch 37] m_orig_modes_batch037.pt vs m_4bit_modes_batch037.pt\n",
      "[mem] before loading used 35.5 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=1     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=2     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=3     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=4     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=5     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=6     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=7     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=8     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=9     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  unique mask lengths: [8, 9, 10, 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [1:42:58<31:18, 156.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch037.parquet\n",
      "  [saved] m_orig_m_4bit_batch37.parquet\n",
      "[mem] after cleanup used 35.4 / 66.6 GB\n",
      "\n",
      "[batch 38] m_orig_modes_batch038.pt vs m_4bit_modes_batch038.pt\n",
      "[mem] before loading used 35.4 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=1     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=2     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=3     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=4     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=5     → len=14  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "  prompt_id=6     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=7     → len=14  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "  prompt_id=8     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=9     → len=12  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  unique mask lengths: [9, 10, 11, 12, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [1:45:36<28:47, 157.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch038.parquet\n",
      "  [saved] m_orig_m_4bit_batch38.parquet\n",
      "[mem] after cleanup used 36.4 / 66.6 GB\n",
      "\n",
      "[batch 39] m_orig_modes_batch039.pt vs m_4bit_modes_batch039.pt\n",
      "[mem] before loading used 36.4 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=1     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=2     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=3     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=4     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=5     → len=12  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  prompt_id=6     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=7     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=8     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=9     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  unique mask lengths: [8, 9, 10, 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [1:48:11<26:05, 156.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch039.parquet\n",
      "  [saved] m_orig_m_4bit_batch39.parquet\n",
      "[mem] after cleanup used 36.2 / 66.6 GB\n",
      "\n",
      "[batch 40] m_orig_modes_batch040.pt vs m_4bit_modes_batch040.pt\n",
      "[mem] before loading used 36.2 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=1     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=2     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=3     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=4     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=5     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=6     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=7     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=8     → len=13  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "  prompt_id=9     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  unique mask lengths: [8, 9, 10, 11, 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [1:50:47<23:25, 156.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch040.parquet\n",
      "  [saved] m_orig_m_4bit_batch40.parquet\n",
      "[mem] after cleanup used 36.2 / 66.6 GB\n",
      "\n",
      "[batch 41] m_orig_modes_batch041.pt vs m_4bit_modes_batch041.pt\n",
      "[mem] before loading used 36.2 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=12  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  prompt_id=1     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=2     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=3     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=4     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=5     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=6     → len=14  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "  prompt_id=7     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=8     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=9     → len=13  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "  unique mask lengths: [8, 9, 10, 12, 13, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [1:53:23<20:50, 156.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch041.parquet\n",
      "  [saved] m_orig_m_4bit_batch41.parquet\n",
      "[mem] after cleanup used 36.1 / 66.6 GB\n",
      "\n",
      "[batch 42] m_orig_modes_batch042.pt vs m_4bit_modes_batch042.pt\n",
      "[mem] before loading used 36.1 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=1     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=2     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=3     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=4     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=5     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=6     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=7     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=8     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=9     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  unique mask lengths: [8, 9, 10, 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [1:55:58<18:10, 155.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch042.parquet\n",
      "  [saved] m_orig_m_4bit_batch42.parquet\n",
      "[mem] after cleanup used 36.2 / 66.6 GB\n",
      "\n",
      "[batch 43] m_orig_modes_batch043.pt vs m_4bit_modes_batch043.pt\n",
      "[mem] before loading used 36.2 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=1     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=2     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=3     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=4     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=5     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=6     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=7     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=8     → len=12  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  prompt_id=9     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  unique mask lengths: [8, 9, 10, 11, 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [1:58:33<15:33, 155.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch043.parquet\n",
      "  [saved] m_orig_m_4bit_batch43.parquet\n",
      "[mem] after cleanup used 36.2 / 66.6 GB\n",
      "\n",
      "[batch 44] m_orig_modes_batch044.pt vs m_4bit_modes_batch044.pt\n",
      "[mem] before loading used 36.2 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=1     → len=14  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "  prompt_id=2     → len=12  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  prompt_id=3     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=4     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=5     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=6     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=7     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=8     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=9     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  unique mask lengths: [8, 9, 10, 12, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [2:01:07<12:56, 155.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch044.parquet\n",
      "  [saved] m_orig_m_4bit_batch44.parquet\n",
      "[mem] after cleanup used 36.2 / 66.6 GB\n",
      "\n",
      "[batch 45] m_orig_modes_batch045.pt vs m_4bit_modes_batch045.pt\n",
      "[mem] before loading used 36.2 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=1     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=2     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=3     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=4     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=5     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=6     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=7     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=8     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=9     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  unique mask lengths: [8, 9, 10, 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [2:03:40<10:18, 154.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch045.parquet\n",
      "  [saved] m_orig_m_4bit_batch45.parquet\n",
      "[mem] after cleanup used 36.2 / 66.6 GB\n",
      "\n",
      "[batch 46] m_orig_modes_batch046.pt vs m_4bit_modes_batch046.pt\n",
      "[mem] before loading used 36.2 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=1     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=2     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=3     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=4     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=5     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=6     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=7     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=8     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=9     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  unique mask lengths: [8, 9, 10, 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [2:06:17<07:45, 155.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch046.parquet\n",
      "  [saved] m_orig_m_4bit_batch46.parquet\n",
      "[mem] after cleanup used 36.5 / 66.6 GB\n",
      "\n",
      "[batch 47] m_orig_modes_batch047.pt vs m_4bit_modes_batch047.pt\n",
      "[mem] before loading used 36.5 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=13  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "  prompt_id=1     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=2     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=3     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=4     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=5     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=6     → len=13  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "  prompt_id=7     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=8     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=9     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  unique mask lengths: [8, 9, 10, 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [2:08:51<05:09, 154.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch047.parquet\n",
      "  [saved] m_orig_m_4bit_batch47.parquet\n",
      "[mem] after cleanup used 36.5 / 66.6 GB\n",
      "\n",
      "[batch 48] m_orig_modes_batch048.pt vs m_4bit_modes_batch048.pt\n",
      "[mem] before loading used 36.5 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=1     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=2     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=3     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=4     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=5     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=6     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  prompt_id=7     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=8     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=9     → len=10  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  unique mask lengths: [8, 9, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [2:11:25<02:34, 154.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch048.parquet\n",
      "  [saved] m_orig_m_4bit_batch48.parquet\n",
      "[mem] after cleanup used 36.5 / 66.6 GB\n",
      "\n",
      "[batch 49] m_orig_modes_batch049.pt vs m_4bit_modes_batch049.pt\n",
      "[mem] before loading used 36.5 / 66.6 GB\n",
      "  [compute] running compute_topk ...\n",
      "[mask cache] built for 10 prompt_ids\n",
      "  prompt_id=0     → len=12  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  prompt_id=1     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=2     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=3     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=4     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=5     → len=8  positions=[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  prompt_id=6     → len=13  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "  prompt_id=7     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  prompt_id=8     → len=9  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "  prompt_id=9     → len=11  positions=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  unique mask lengths: [8, 9, 11, 12, 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [2:14:00<00:00, 160.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] 340 rows → saved_data/topk/4bit_test/m_orig_m_4bit_batch049.parquet\n",
      "  [saved] m_orig_m_4bit_batch49.parquet\n",
      "[mem] after cleanup used 36.5 / 66.6 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run_name = \"m_orig_m_4bit\"\n",
    "\n",
    "run_topk_streaming(\n",
    "    dir_A=\"saved_data/lens_data/m_orig\",\n",
    "    dir_B=\"saved_data/lens_data/m_4bit\",\n",
    "    output_dir=\"saved_data/topk/4bit_test\",\n",
    "    norm_modes=(\"raw\", \"unit_rms\", \"norm_rms\"),\n",
    "    topk=(1, 5, 10),\n",
    "    #eos_token_id=128009,\n",
    "    #bos_token_id=128000,\n",
    "    run_name=run_name,\n",
    "    device=\"cpu\",\n",
    "    debug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26fdf070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(340, 83)\n",
      "['prompt_id', 'batch_index', 'layer_index', 'layer_name', 'prompt_text', 'kl_ab_raw', 'kl_ba_raw', 'js_div_raw', 'js_dist_raw', 'tvd_raw', 'entropy_A_raw', 'entropy_B_raw', 'cosine_sim_raw', 'l2_dist_raw', 'logp_diff_raw', 'ppl_A_raw', 'ppl_B_raw', 'ppl_diff_raw', 'acc_A_raw', 'acc_B_raw', 'jaccard_raw', 'disagree_set_raw', 'agree_set_raw', 'agree_correct_raw', 'disagree_correct_raw', 'agree_wrong_raw', 'prob_overlap_raw', 'top_pred_ids_A_raw', 'top_pred_vals_A_raw', 'top_pred_ids_B_raw', 'top_pred_vals_B_raw', 'kl_ab_unit_rms', 'kl_ba_unit_rms', 'js_div_unit_rms', 'js_dist_unit_rms', 'tvd_unit_rms', 'entropy_A_unit_rms', 'entropy_B_unit_rms', 'cosine_sim_unit_rms', 'l2_dist_unit_rms', 'logp_diff_unit_rms', 'ppl_A_unit_rms', 'ppl_B_unit_rms', 'ppl_diff_unit_rms', 'acc_A_unit_rms', 'acc_B_unit_rms', 'jaccard_unit_rms', 'disagree_set_unit_rms', 'agree_set_unit_rms', 'agree_correct_unit_rms', 'disagree_correct_unit_rms', 'agree_wrong_unit_rms', 'prob_overlap_unit_rms', 'top_pred_ids_A_unit_rms', 'top_pred_vals_A_unit_rms', 'top_pred_ids_B_unit_rms', 'top_pred_vals_B_unit_rms', 'kl_ab_norm_rms', 'kl_ba_norm_rms', 'js_div_norm_rms', 'js_dist_norm_rms', 'tvd_norm_rms', 'entropy_A_norm_rms', 'entropy_B_norm_rms', 'cosine_sim_norm_rms', 'l2_dist_norm_rms', 'logp_diff_norm_rms', 'ppl_A_norm_rms', 'ppl_B_norm_rms', 'ppl_diff_norm_rms', 'acc_A_norm_rms', 'acc_B_norm_rms', 'jaccard_norm_rms', 'disagree_set_norm_rms', 'agree_set_norm_rms', 'agree_correct_norm_rms', 'disagree_correct_norm_rms', 'agree_wrong_norm_rms', 'prob_overlap_norm_rms', 'top_pred_ids_A_norm_rms', 'top_pred_vals_A_norm_rms', 'top_pred_ids_B_norm_rms', 'top_pred_vals_B_norm_rms']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_parquet(\"saved_data/topk/4bit_test/m_orig_m_4bit_batch000.parquet\")\n",
    "\n",
    "print(df.shape)\n",
    "print(df.columns.tolist()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc96c072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2849.375    , -1397.8828125,  -421.671875 , -2650.46875  ,\n",
       "        2668.390625 , -2862.546875 ,  2088.28125  ,  1438.09375  ,\n",
       "        1142.90625  ,  -997.3515625])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"ppl_diff_raw\"][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a31ba581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prompt_id                   0\n",
       "batch_index                 0\n",
       "layer_index                 0\n",
       "layer_name                  0\n",
       "prompt_text                 0\n",
       "                           ..\n",
       "prob_overlap_norm_rms       0\n",
       "top_pred_ids_A_norm_rms     0\n",
       "top_pred_vals_A_norm_rms    0\n",
       "top_pred_ids_B_norm_rms     0\n",
       "top_pred_vals_B_norm_rms    0\n",
       "Length: 83, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efba6a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw {'@1': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), '@10': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), '@5': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}\n",
      "unit_rms {'@1': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), '@10': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), '@5': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}\n",
      "norm_rms {'@1': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), '@10': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), '@5': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}\n"
     ]
    }
   ],
   "source": [
    "for m in [\"raw\", \"unit_rms\", \"norm_rms\"]:\n",
    "    print(m, df.iloc[0][f\"acc_A_{m}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "072ca179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>batch_index</th>\n",
       "      <th>layer_index</th>\n",
       "      <th>layer_name</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>kl_ab_raw</th>\n",
       "      <th>kl_ba_raw</th>\n",
       "      <th>js_div_raw</th>\n",
       "      <th>js_dist_raw</th>\n",
       "      <th>tvd_raw</th>\n",
       "      <th>...</th>\n",
       "      <th>disagree_set_norm_rms</th>\n",
       "      <th>agree_set_norm_rms</th>\n",
       "      <th>agree_correct_norm_rms</th>\n",
       "      <th>disagree_correct_norm_rms</th>\n",
       "      <th>agree_wrong_norm_rms</th>\n",
       "      <th>prob_overlap_norm_rms</th>\n",
       "      <th>top_pred_ids_A_norm_rms</th>\n",
       "      <th>top_pred_vals_A_norm_rms</th>\n",
       "      <th>top_pred_ids_B_norm_rms</th>\n",
       "      <th>top_pred_vals_B_norm_rms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>embed_tokens</td>\n",
       "      <td>when did richmond last play in a preliminary f...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.5604879877173516e-07, 0.0, 0...</td>\n",
       "      <td>[3.295296551186766e-07, 7.95488574567571e-07, ...</td>\n",
       "      <td>[1.647648275593383e-07, 3.977442872837855e-07,...</td>\n",
       "      <td>[0.00040591356810182333, 0.0006306705181486905...</td>\n",
       "      <td>[4.759094736073166e-07, 4.540966074273456e-07,...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>{'@1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...</td>\n",
       "      <td>{'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>{'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>{'@1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...</td>\n",
       "      <td>{'@1': [0.9999998807907104, 0.9999998807907104...</td>\n",
       "      <td>{'@1': [106240, 50974, 15631, 30986, 125312, 4...</td>\n",
       "      <td>{'@1': [8.04836872703163e-06, 8.04786759545095...</td>\n",
       "      <td>{'@1': [106240, 50974, 15631, 30986, 125312, 4...</td>\n",
       "      <td>{'@1': [8.048412382777315e-06, 8.0478621384827...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>embed_tokens</td>\n",
       "      <td>who sang what in the world's come over you</td>\n",
       "      <td>[0.0, 7.059189215397055e-07, 0.0, 4.4279076405...</td>\n",
       "      <td>[6.355795676427078e-07, 0.0, 1.700919511904430...</td>\n",
       "      <td>[3.177897838213539e-07, 3.5295946076985274e-07...</td>\n",
       "      <td>[0.0005637293797917664, 0.0005941047566011548,...</td>\n",
       "      <td>[5.015654096496291e-07, 5.726046765630599e-07,...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>{'@1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...</td>\n",
       "      <td>{'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>{'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>{'@1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...</td>\n",
       "      <td>{'@1': [0.9999998807907104, 0.9999998807907104...</td>\n",
       "      <td>{'@1': [16527, 15739, 775, 27253, 22832, 98940...</td>\n",
       "      <td>{'@1': [8.05455601948779e-06, 8.06495881988667...</td>\n",
       "      <td>{'@1': [16527, 15739, 775, 27253, 22832, 98940...</td>\n",
       "      <td>{'@1': [8.054635145526845e-06, 8.0649260780774...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>embed_tokens</td>\n",
       "      <td>who produces the most wool in the world</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 5.433208798422129e-07, 4....</td>\n",
       "      <td>[6.355795676427078e-07, 1.2710876262644888e-07...</td>\n",
       "      <td>[3.177897838213539e-07, 6.355438131322444e-08,...</td>\n",
       "      <td>[0.0005637293797917664, 0.0002521019196137786,...</td>\n",
       "      <td>[5.015654096496291e-07, 6.046816451998893e-07,...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>{'@1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...</td>\n",
       "      <td>{'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>{'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>{'@1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...</td>\n",
       "      <td>{'@1': [0.9999998807907104, 0.9999998807907104...</td>\n",
       "      <td>{'@1': [16527, 88215, 22832, 1818, 88443, 2725...</td>\n",
       "      <td>{'@1': [8.05455601948779e-06, 8.08752793091116...</td>\n",
       "      <td>{'@1': [16527, 88215, 22832, 1818, 88443, 2725...</td>\n",
       "      <td>{'@1': [8.054635145526845e-06, 8.0874269769992...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>embed_tokens</td>\n",
       "      <td>where does alaska the last frontier take place</td>\n",
       "      <td>[3.2161079843717744e-07, 0.0, 1.22883203612644...</td>\n",
       "      <td>[0.0, 8.771570492172032e-07, 0.0, 0.0, 2.18893...</td>\n",
       "      <td>[1.6080539921858872e-07, 4.385785246086016e-07...</td>\n",
       "      <td>[0.00040100672049447894, 0.0006622533546760678...</td>\n",
       "      <td>[4.811638518731343e-07, 4.230280410411069e-07,...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>{'@1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...</td>\n",
       "      <td>{'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>{'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>{'@1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...</td>\n",
       "      <td>{'@1': [0.9999998807907104, 0.9999998807907104...</td>\n",
       "      <td>{'@1': [93655, 38008, 8376, 598, 22832, 125312...</td>\n",
       "      <td>{'@1': [8.043350135267247e-06, 8.0232348409481...</td>\n",
       "      <td>{'@1': [93655, 38008, 8376, 598, 22832, 125312...</td>\n",
       "      <td>{'@1': [8.043406523938756e-06, 8.0232284744852...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>embed_tokens</td>\n",
       "      <td>a day to remember all i want cameos</td>\n",
       "      <td>[4.754832048092794e-07, 0.0, 1.210236035831258...</td>\n",
       "      <td>[0.0, 3.4339532817284635e-07, 0.0, 3.753275450...</td>\n",
       "      <td>[2.377416024046397e-07, 1.7169766408642317e-07...</td>\n",
       "      <td>[0.0004875885497312993, 0.00041436534957028925...</td>\n",
       "      <td>[3.634875156421913e-07, 4.2826491153391544e-07...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>{'@1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...</td>\n",
       "      <td>{'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>{'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>{'@1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...</td>\n",
       "      <td>{'@1': [0.9999998807907104, 0.9999998807907104...</td>\n",
       "      <td>{'@1': [6472, 12791, 880, 65420, 58182, 21162,...</td>\n",
       "      <td>{'@1': [7.964791620906908e-06, 8.0265626820619...</td>\n",
       "      <td>{'@1': [6472, 12791, 880, 65420, 58182, 21162,...</td>\n",
       "      <td>{'@1': [7.964817086758558e-06, 8.0265299402526...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   prompt_id  batch_index  layer_index    layer_name  \\\n",
       "0          0            0           -1  embed_tokens   \n",
       "1          1            0           -1  embed_tokens   \n",
       "2          2            0           -1  embed_tokens   \n",
       "3          3            0           -1  embed_tokens   \n",
       "4          4            0           -1  embed_tokens   \n",
       "\n",
       "                                         prompt_text  \\\n",
       "0  when did richmond last play in a preliminary f...   \n",
       "1         who sang what in the world's come over you   \n",
       "2            who produces the most wool in the world   \n",
       "3     where does alaska the last frontier take place   \n",
       "4                a day to remember all i want cameos   \n",
       "\n",
       "                                           kl_ab_raw  \\\n",
       "0  [0.0, 0.0, 0.0, 1.5604879877173516e-07, 0.0, 0...   \n",
       "1  [0.0, 7.059189215397055e-07, 0.0, 4.4279076405...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 5.433208798422129e-07, 4....   \n",
       "3  [3.2161079843717744e-07, 0.0, 1.22883203612644...   \n",
       "4  [4.754832048092794e-07, 0.0, 1.210236035831258...   \n",
       "\n",
       "                                           kl_ba_raw  \\\n",
       "0  [3.295296551186766e-07, 7.95488574567571e-07, ...   \n",
       "1  [6.355795676427078e-07, 0.0, 1.700919511904430...   \n",
       "2  [6.355795676427078e-07, 1.2710876262644888e-07...   \n",
       "3  [0.0, 8.771570492172032e-07, 0.0, 0.0, 2.18893...   \n",
       "4  [0.0, 3.4339532817284635e-07, 0.0, 3.753275450...   \n",
       "\n",
       "                                          js_div_raw  \\\n",
       "0  [1.647648275593383e-07, 3.977442872837855e-07,...   \n",
       "1  [3.177897838213539e-07, 3.5295946076985274e-07...   \n",
       "2  [3.177897838213539e-07, 6.355438131322444e-08,...   \n",
       "3  [1.6080539921858872e-07, 4.385785246086016e-07...   \n",
       "4  [2.377416024046397e-07, 1.7169766408642317e-07...   \n",
       "\n",
       "                                         js_dist_raw  \\\n",
       "0  [0.00040591356810182333, 0.0006306705181486905...   \n",
       "1  [0.0005637293797917664, 0.0005941047566011548,...   \n",
       "2  [0.0005637293797917664, 0.0002521019196137786,...   \n",
       "3  [0.00040100672049447894, 0.0006622533546760678...   \n",
       "4  [0.0004875885497312993, 0.00041436534957028925...   \n",
       "\n",
       "                                             tvd_raw  ...  \\\n",
       "0  [4.759094736073166e-07, 4.540966074273456e-07,...  ...   \n",
       "1  [5.015654096496291e-07, 5.726046765630599e-07,...  ...   \n",
       "2  [5.015654096496291e-07, 6.046816451998893e-07,...  ...   \n",
       "3  [4.811638518731343e-07, 4.230280410411069e-07,...  ...   \n",
       "4  [3.634875156421913e-07, 4.2826491153391544e-07...  ...   \n",
       "\n",
       "                               disagree_set_norm_rms  \\\n",
       "0  {'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "1  {'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "2  {'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "3  {'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "4  {'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "\n",
       "                                  agree_set_norm_rms  \\\n",
       "0  {'@1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...   \n",
       "1  {'@1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...   \n",
       "2  {'@1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...   \n",
       "3  {'@1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...   \n",
       "4  {'@1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...   \n",
       "\n",
       "                              agree_correct_norm_rms  \\\n",
       "0  {'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "1  {'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "2  {'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "3  {'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "4  {'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "\n",
       "                           disagree_correct_norm_rms  \\\n",
       "0  {'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "1  {'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "2  {'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "3  {'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "4  {'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "\n",
       "                                agree_wrong_norm_rms  \\\n",
       "0  {'@1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...   \n",
       "1  {'@1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...   \n",
       "2  {'@1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...   \n",
       "3  {'@1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...   \n",
       "4  {'@1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...   \n",
       "\n",
       "                               prob_overlap_norm_rms  \\\n",
       "0  {'@1': [0.9999998807907104, 0.9999998807907104...   \n",
       "1  {'@1': [0.9999998807907104, 0.9999998807907104...   \n",
       "2  {'@1': [0.9999998807907104, 0.9999998807907104...   \n",
       "3  {'@1': [0.9999998807907104, 0.9999998807907104...   \n",
       "4  {'@1': [0.9999998807907104, 0.9999998807907104...   \n",
       "\n",
       "                             top_pred_ids_A_norm_rms  \\\n",
       "0  {'@1': [106240, 50974, 15631, 30986, 125312, 4...   \n",
       "1  {'@1': [16527, 15739, 775, 27253, 22832, 98940...   \n",
       "2  {'@1': [16527, 88215, 22832, 1818, 88443, 2725...   \n",
       "3  {'@1': [93655, 38008, 8376, 598, 22832, 125312...   \n",
       "4  {'@1': [6472, 12791, 880, 65420, 58182, 21162,...   \n",
       "\n",
       "                            top_pred_vals_A_norm_rms  \\\n",
       "0  {'@1': [8.04836872703163e-06, 8.04786759545095...   \n",
       "1  {'@1': [8.05455601948779e-06, 8.06495881988667...   \n",
       "2  {'@1': [8.05455601948779e-06, 8.08752793091116...   \n",
       "3  {'@1': [8.043350135267247e-06, 8.0232348409481...   \n",
       "4  {'@1': [7.964791620906908e-06, 8.0265626820619...   \n",
       "\n",
       "                             top_pred_ids_B_norm_rms  \\\n",
       "0  {'@1': [106240, 50974, 15631, 30986, 125312, 4...   \n",
       "1  {'@1': [16527, 15739, 775, 27253, 22832, 98940...   \n",
       "2  {'@1': [16527, 88215, 22832, 1818, 88443, 2725...   \n",
       "3  {'@1': [93655, 38008, 8376, 598, 22832, 125312...   \n",
       "4  {'@1': [6472, 12791, 880, 65420, 58182, 21162,...   \n",
       "\n",
       "                            top_pred_vals_B_norm_rms  \n",
       "0  {'@1': [8.048412382777315e-06, 8.0478621384827...  \n",
       "1  {'@1': [8.054635145526845e-06, 8.0649260780774...  \n",
       "2  {'@1': [8.054635145526845e-06, 8.0874269769992...  \n",
       "3  {'@1': [8.043406523938756e-06, 8.0232284744852...  \n",
       "4  {'@1': [7.964817086758558e-06, 8.0265299402526...  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e93f7372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>batch_index</th>\n",
       "      <th>layer_index</th>\n",
       "      <th>layer_name</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>kl_ab_raw</th>\n",
       "      <th>kl_ba_raw</th>\n",
       "      <th>js_div_raw</th>\n",
       "      <th>js_dist_raw</th>\n",
       "      <th>tvd_raw</th>\n",
       "      <th>...</th>\n",
       "      <th>disagree_set_norm_rms</th>\n",
       "      <th>agree_set_norm_rms</th>\n",
       "      <th>agree_correct_norm_rms</th>\n",
       "      <th>disagree_correct_norm_rms</th>\n",
       "      <th>agree_wrong_norm_rms</th>\n",
       "      <th>prob_overlap_norm_rms</th>\n",
       "      <th>top_pred_ids_A_norm_rms</th>\n",
       "      <th>top_pred_vals_A_norm_rms</th>\n",
       "      <th>top_pred_ids_B_norm_rms</th>\n",
       "      <th>top_pred_vals_B_norm_rms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>output</td>\n",
       "      <td>what does the red stripes mean on the american...</td>\n",
       "      <td>[0.00931896548718214, 0.02275301143527031, 0.0...</td>\n",
       "      <td>[0.00875139981508255, 0.020966731011867523, 0....</td>\n",
       "      <td>[0.009035183116793633, 0.021859871223568916, 0...</td>\n",
       "      <td>[0.09505358338356018, 0.14785084128379822, 0.2...</td>\n",
       "      <td>[0.04915468022227287, 0.07283315807580948, 0.1...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'@1': [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0...</td>\n",
       "      <td>{'@1': [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0...</td>\n",
       "      <td>{'@1': [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0...</td>\n",
       "      <td>{'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0...</td>\n",
       "      <td>{'@1': [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>{'@1': [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0...</td>\n",
       "      <td>{'@1': [374, 279, 3492, 5425, 389, 389, 264, 3...</td>\n",
       "      <td>{'@1': [0.4756481945514679, 0.2824018895626068...</td>\n",
       "      <td>{'@1': [374, 279, 61301, 5425, 389, 304, 279, ...</td>\n",
       "      <td>{'@1': [0.4565294086933136, 0.2929996550083160...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>output</td>\n",
       "      <td>where did they film diary of a wimpy kid</td>\n",
       "      <td>[0.02899564430117607, 0.016912903636693954, 0....</td>\n",
       "      <td>[0.029145263135433197, 0.017903849482536316, 0...</td>\n",
       "      <td>[0.029070453718304634, 0.017408376559615135, 0...</td>\n",
       "      <td>[0.17050059139728546, 0.1319408118724823, 0.36...</td>\n",
       "      <td>[0.09413482248783112, 0.07486601918935776, 0.2...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'@1': [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>{'@1': [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0...</td>\n",
       "      <td>{'@1': [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0...</td>\n",
       "      <td>{'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>{'@1': [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>{'@1': [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0...</td>\n",
       "      <td>{'@1': [374, 499, 733, 279, 315, 264, 289, 318...</td>\n",
       "      <td>{'@1': [0.14577332139015198, 0.451576769351959...</td>\n",
       "      <td>{'@1': [374, 499, 636, 279, 315, 264, 289, 318...</td>\n",
       "      <td>{'@1': [0.15400931239128113, 0.506159126758575...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>output</td>\n",
       "      <td>where was beasts of the southern wild filmed</td>\n",
       "      <td>[0.02899564430117607, 0.014131640084087849, 0....</td>\n",
       "      <td>[0.029145263135433197, 0.01317090354859829, 0....</td>\n",
       "      <td>[0.029070453718304634, 0.013651272282004356, 0...</td>\n",
       "      <td>[0.17050059139728546, 0.11683866381645203, 0.1...</td>\n",
       "      <td>[0.09413482248783112, 0.03487376123666763, 0.0...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>{'@1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...</td>\n",
       "      <td>{'@1': [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0...</td>\n",
       "      <td>{'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>{'@1': [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0...</td>\n",
       "      <td>{'@1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...</td>\n",
       "      <td>{'@1': [374, 279, 315, 279, 18561, 8545, 42508...</td>\n",
       "      <td>{'@1': [0.14577332139015198, 0.772456526756286...</td>\n",
       "      <td>{'@1': [374, 279, 315, 279, 18561, 8545, 42508...</td>\n",
       "      <td>{'@1': [0.15400931239128113, 0.780452430248260...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>output</td>\n",
       "      <td>what part of the country are you likely to fin...</td>\n",
       "      <td>[0.00931893102824688, 0.002987947780638933, 0....</td>\n",
       "      <td>[0.008751489222049713, 0.0038406294770538807, ...</td>\n",
       "      <td>[0.009035210125148296, 0.003414288628846407, 0...</td>\n",
       "      <td>[0.09505372494459152, 0.05843191593885422, 0.2...</td>\n",
       "      <td>[0.04915442690253258, 0.011744649149477482, 0....</td>\n",
       "      <td>...</td>\n",
       "      <td>{'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>{'@1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...</td>\n",
       "      <td>{'@1': [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0...</td>\n",
       "      <td>{'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>{'@1': [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0...</td>\n",
       "      <td>{'@1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...</td>\n",
       "      <td>{'@1': [374, 315, 279, 8271, 374, 499, 505, 31...</td>\n",
       "      <td>{'@1': [0.4756476581096649, 0.9758495092391968...</td>\n",
       "      <td>{'@1': [374, 315, 279, 8271, 374, 499, 505, 31...</td>\n",
       "      <td>{'@1': [0.4565294086933136, 0.964128315448761,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>output</td>\n",
       "      <td>when did fosters home for imaginary friends start</td>\n",
       "      <td>[0.026482293382287025, 0.01734291948378086, 0....</td>\n",
       "      <td>[0.026023251935839653, 0.017519818618893623, 0...</td>\n",
       "      <td>[0.02625277265906334, 0.017431369051337242, 0....</td>\n",
       "      <td>[0.16202707588672638, 0.13202790915966034, 0.1...</td>\n",
       "      <td>[0.09061356633901596, 0.07100653648376465, 0.0...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0...</td>\n",
       "      <td>{'@1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0...</td>\n",
       "      <td>{'@1': [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0...</td>\n",
       "      <td>{'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>{'@1': [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0...</td>\n",
       "      <td>{'@1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0...</td>\n",
       "      <td>{'@1': [499, 279, 388, 2162, 369, 51052, 4885,...</td>\n",
       "      <td>{'@1': [0.12614338099956512, 0.323676854372024...</td>\n",
       "      <td>{'@1': [499, 279, 388, 2162, 369, 51052, 4885,...</td>\n",
       "      <td>{'@1': [0.14103320240974426, 0.300641596317291...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     prompt_id  batch_index  layer_index layer_name  \\\n",
       "335          5            0           32     output   \n",
       "336          6            0           32     output   \n",
       "337          7            0           32     output   \n",
       "338          8            0           32     output   \n",
       "339          9            0           32     output   \n",
       "\n",
       "                                           prompt_text  \\\n",
       "335  what does the red stripes mean on the american...   \n",
       "336           where did they film diary of a wimpy kid   \n",
       "337       where was beasts of the southern wild filmed   \n",
       "338  what part of the country are you likely to fin...   \n",
       "339  when did fosters home for imaginary friends start   \n",
       "\n",
       "                                             kl_ab_raw  \\\n",
       "335  [0.00931896548718214, 0.02275301143527031, 0.0...   \n",
       "336  [0.02899564430117607, 0.016912903636693954, 0....   \n",
       "337  [0.02899564430117607, 0.014131640084087849, 0....   \n",
       "338  [0.00931893102824688, 0.002987947780638933, 0....   \n",
       "339  [0.026482293382287025, 0.01734291948378086, 0....   \n",
       "\n",
       "                                             kl_ba_raw  \\\n",
       "335  [0.00875139981508255, 0.020966731011867523, 0....   \n",
       "336  [0.029145263135433197, 0.017903849482536316, 0...   \n",
       "337  [0.029145263135433197, 0.01317090354859829, 0....   \n",
       "338  [0.008751489222049713, 0.0038406294770538807, ...   \n",
       "339  [0.026023251935839653, 0.017519818618893623, 0...   \n",
       "\n",
       "                                            js_div_raw  \\\n",
       "335  [0.009035183116793633, 0.021859871223568916, 0...   \n",
       "336  [0.029070453718304634, 0.017408376559615135, 0...   \n",
       "337  [0.029070453718304634, 0.013651272282004356, 0...   \n",
       "338  [0.009035210125148296, 0.003414288628846407, 0...   \n",
       "339  [0.02625277265906334, 0.017431369051337242, 0....   \n",
       "\n",
       "                                           js_dist_raw  \\\n",
       "335  [0.09505358338356018, 0.14785084128379822, 0.2...   \n",
       "336  [0.17050059139728546, 0.1319408118724823, 0.36...   \n",
       "337  [0.17050059139728546, 0.11683866381645203, 0.1...   \n",
       "338  [0.09505372494459152, 0.05843191593885422, 0.2...   \n",
       "339  [0.16202707588672638, 0.13202790915966034, 0.1...   \n",
       "\n",
       "                                               tvd_raw  ...  \\\n",
       "335  [0.04915468022227287, 0.07283315807580948, 0.1...  ...   \n",
       "336  [0.09413482248783112, 0.07486601918935776, 0.2...  ...   \n",
       "337  [0.09413482248783112, 0.03487376123666763, 0.0...  ...   \n",
       "338  [0.04915442690253258, 0.011744649149477482, 0....  ...   \n",
       "339  [0.09061356633901596, 0.07100653648376465, 0.0...  ...   \n",
       "\n",
       "                                 disagree_set_norm_rms  \\\n",
       "335  {'@1': [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0...   \n",
       "336  {'@1': [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "337  {'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "338  {'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "339  {'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0...   \n",
       "\n",
       "                                    agree_set_norm_rms  \\\n",
       "335  {'@1': [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0...   \n",
       "336  {'@1': [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0...   \n",
       "337  {'@1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...   \n",
       "338  {'@1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...   \n",
       "339  {'@1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0...   \n",
       "\n",
       "                                agree_correct_norm_rms  \\\n",
       "335  {'@1': [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0...   \n",
       "336  {'@1': [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0...   \n",
       "337  {'@1': [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0...   \n",
       "338  {'@1': [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0...   \n",
       "339  {'@1': [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0...   \n",
       "\n",
       "                             disagree_correct_norm_rms  \\\n",
       "335  {'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0...   \n",
       "336  {'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "337  {'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "338  {'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "339  {'@1': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "\n",
       "                                  agree_wrong_norm_rms  \\\n",
       "335  {'@1': [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0...   \n",
       "336  {'@1': [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "337  {'@1': [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0...   \n",
       "338  {'@1': [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0...   \n",
       "339  {'@1': [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0...   \n",
       "\n",
       "                                 prob_overlap_norm_rms  \\\n",
       "335  {'@1': [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0...   \n",
       "336  {'@1': [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0...   \n",
       "337  {'@1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...   \n",
       "338  {'@1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...   \n",
       "339  {'@1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0...   \n",
       "\n",
       "                               top_pred_ids_A_norm_rms  \\\n",
       "335  {'@1': [374, 279, 3492, 5425, 389, 389, 264, 3...   \n",
       "336  {'@1': [374, 499, 733, 279, 315, 264, 289, 318...   \n",
       "337  {'@1': [374, 279, 315, 279, 18561, 8545, 42508...   \n",
       "338  {'@1': [374, 315, 279, 8271, 374, 499, 505, 31...   \n",
       "339  {'@1': [499, 279, 388, 2162, 369, 51052, 4885,...   \n",
       "\n",
       "                              top_pred_vals_A_norm_rms  \\\n",
       "335  {'@1': [0.4756481945514679, 0.2824018895626068...   \n",
       "336  {'@1': [0.14577332139015198, 0.451576769351959...   \n",
       "337  {'@1': [0.14577332139015198, 0.772456526756286...   \n",
       "338  {'@1': [0.4756476581096649, 0.9758495092391968...   \n",
       "339  {'@1': [0.12614338099956512, 0.323676854372024...   \n",
       "\n",
       "                               top_pred_ids_B_norm_rms  \\\n",
       "335  {'@1': [374, 279, 61301, 5425, 389, 304, 279, ...   \n",
       "336  {'@1': [374, 499, 636, 279, 315, 264, 289, 318...   \n",
       "337  {'@1': [374, 279, 315, 279, 18561, 8545, 42508...   \n",
       "338  {'@1': [374, 315, 279, 8271, 374, 499, 505, 31...   \n",
       "339  {'@1': [499, 279, 388, 2162, 369, 51052, 4885,...   \n",
       "\n",
       "                              top_pred_vals_B_norm_rms  \n",
       "335  {'@1': [0.4565294086933136, 0.2929996550083160...  \n",
       "336  {'@1': [0.15400931239128113, 0.506159126758575...  \n",
       "337  {'@1': [0.15400931239128113, 0.780452430248260...  \n",
       "338  {'@1': [0.4565294086933136, 0.964128315448761,...  \n",
       "339  {'@1': [0.14103320240974426, 0.300641596317291...  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6aa31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cosine_sim_norm_rms\"][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394ec611",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cosine_sim_raw\"][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e24dbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"l2_dist_raw\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668aa4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "cols = [\"kl_ab_raw\", \"js_div_raw\", \"disagree_correct_raw\"]\n",
    "def arr_len(x):\n",
    "    if isinstance(x, dict) and \"@1\" in x: \n",
    "        return len(x[\"@1\"])\n",
    "    if isinstance(x, (list, np.ndarray)):\n",
    "        return len(x)\n",
    "    return np.nan\n",
    "\n",
    "for c in cols:\n",
    "    df[f\"len_{c}\"] = df[c].apply(arr_len)\n",
    "\n",
    "print(df[[\"prompt_id\",\"layer_index\",\"len_kl_ab_raw\",\"len_js_div_raw\",\"len_disagree_correct_raw\"]].head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d06d96",
   "metadata": {},
   "source": [
    "# ==============================================\n",
    "# Plot TopK Summaries ==========================\n",
    "# =============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d78a9251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[merge] merged 50 parquet files → 17000 rows\n",
      "[diag] unique batch_index=50 | unique prompt_id=10 | unique (prompt,batch)=500\n",
      "[ok] prompt–batch pairs look good\n",
      "[ok] merged all models → 816000 rows total\n",
      "mode              norm_rms    raw  unit_rms\n",
      "metric                                     \n",
      "acc_A                51000  51000     51000\n",
      "acc_B                51000  51000     51000\n",
      "cosine_sim           17000  17000     17000\n",
      "disagree_correct     51000  51000     51000\n",
      "jaccard              51000  51000     51000\n",
      "l2_dist              17000  17000     17000\n",
      "ppl_diff             17000  17000     17000\n",
      "tvd                  17000  17000     17000\n",
      "[saved] saved_data/figures_topk_modes_fixed_full/overview_m_4bit.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"deep\")\n",
    "\n",
    "BASE = Path(\"saved_data\")\n",
    "#MODELS = [\"m_4bit\", \"m_8bit\", \"m_quant\"]\n",
    "MODELS = [\"m_4bit\"]\n",
    "OUT_DIR = BASE / \"figures_topk_modes_fixed_full\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TOPK_METRICS = [\"acc_A\", \"acc_B\", \"jaccard\", \"disagree_correct\"]\n",
    "CONT_METRICS = [\"cosine_sim\", \"l2_dist\", \"tvd\", \"ppl_diff\"]\n",
    "MODES = [\"raw\", \"unit_rms\", \"norm_rms\"]\n",
    "TOPK = [1, 5, 10]\n",
    "\n",
    "\n",
    "def merge_parquet_files(input_dir: str) -> pd.DataFrame:\n",
    "    files = sorted(Path(input_dir).glob(\"*.parquet\"))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No parquet files found in {input_dir}\")\n",
    "\n",
    "    dfs = []\n",
    "    for i, f in enumerate(files):\n",
    "        d = pd.read_parquet(f)\n",
    "        d[\"batch_index\"] = i\n",
    "        dfs.append(d)\n",
    "\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    print(f\"[merge] merged {len(files)} parquet files → {len(df)} rows\")\n",
    "\n",
    "    n_batches = df[\"batch_index\"].nunique()\n",
    "    n_prompts = df[\"prompt_id\"].nunique()\n",
    "    n_pairs = df.groupby([\"prompt_id\", \"batch_index\"]).ngroups\n",
    "    print(f\"[diag] unique batch_index={n_batches} | unique prompt_id={n_prompts} | unique (prompt,batch)={n_pairs}\")\n",
    "\n",
    "    if n_pairs < len(files) * 10:\n",
    "        print(\"[warn] fewer prompt–batch pairs than expected — possible ID overlap?\")\n",
    "    else:\n",
    "        print(\"[ok] prompt–batch pairs look good\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def extract_topk(df, metric, mode, k):\n",
    "    base = f\"{metric}_{mode}\"\n",
    "    if base not in df.columns:\n",
    "        return np.full(len(df), np.nan)\n",
    "    return df[base].apply(\n",
    "        lambda d: np.mean(d.get(f\"@{k}\", [])) if isinstance(d, dict) and f\"@{k}\" in d else np.nan\n",
    "    )\n",
    "\n",
    "\n",
    "def extract_flat(df, metric, mode):\n",
    "    col = f\"{metric}_{mode}\"\n",
    "    if col not in df.columns:\n",
    "        return np.full(len(df), np.nan)\n",
    "    return df[col].apply(\n",
    "        lambda v: np.mean(v) if isinstance(v, (list, np.ndarray)) and len(v) > 0 else np.nan\n",
    "    )\n",
    "\n",
    "\n",
    "dfs = []\n",
    "for model in MODELS:\n",
    "    topk_dir = BASE / \"topk\" / model\n",
    "    df = merge_parquet_files(topk_dir)\n",
    "\n",
    "    all_rows = []\n",
    "\n",
    "    for metric in TOPK_METRICS:\n",
    "        for mode in MODES:\n",
    "            for k in TOPK:\n",
    "                vals = extract_topk(df, metric, mode, k)\n",
    "                dsub = pd.DataFrame({\n",
    "                    \"model\": model,\n",
    "                    \"metric\": metric,\n",
    "                    \"mode\": mode,\n",
    "                    \"topk\": k,\n",
    "                    \"layer_index\": df.get(\"layer_index\", pd.Series(np.zeros(len(df)))),\n",
    "                    \"value\": vals\n",
    "                })\n",
    "                all_rows.append(dsub)\n",
    "\n",
    "    for metric in CONT_METRICS:\n",
    "        for mode in MODES:\n",
    "            vals = extract_flat(df, metric, mode)\n",
    "            dsub = pd.DataFrame({\n",
    "                \"model\": model,\n",
    "                \"metric\": metric,\n",
    "                \"mode\": mode,\n",
    "                \"topk\": 1,  \n",
    "                \"layer_index\": df.get(\"layer_index\", pd.Series(np.zeros(len(df)))),\n",
    "                \"value\": vals\n",
    "            })\n",
    "            all_rows.append(dsub)\n",
    "\n",
    "    dfs.append(pd.concat(all_rows, ignore_index=True))\n",
    "\n",
    "df_long = pd.concat(dfs, ignore_index=True).dropna(subset=[\"value\"])\n",
    "print(f\"[ok] merged all models → {len(df_long)} rows total\")\n",
    "print(df_long.groupby([\"metric\", \"mode\"])[\"value\"].count().unstack(fill_value=0))\n",
    "\n",
    "\n",
    "for model in MODELS:\n",
    "    dsub = df_long[df_long[\"model\"] == model]\n",
    "    if dsub.empty:\n",
    "        print(f\"[skip] no data for {model}\")\n",
    "        continue\n",
    "\n",
    "    metrics_unique = dsub[\"metric\"].unique().tolist()\n",
    "    nrows = int(np.ceil(len(metrics_unique) / 2))\n",
    "    fig, axes = plt.subplots(nrows, 2, figsize=(14, 4 * nrows))\n",
    "    fig.suptitle(f\"Top-K + Continuous Metrics — {model}\", fontsize=16, weight=\"bold\")\n",
    "\n",
    "    for ax, metric in zip(axes.flatten(), metrics_unique):\n",
    "        d = dsub[dsub[\"metric\"] == metric]\n",
    "        sns.lineplot(\n",
    "            data=d,\n",
    "            x=\"layer_index\",\n",
    "            y=\"value\",\n",
    "            hue=\"mode\",\n",
    "            style=\"topk\" if metric in TOPK_METRICS else None,\n",
    "            markers=True,\n",
    "            err_style=\"band\",\n",
    "            ax=ax\n",
    "        )\n",
    "        ax.set_title(metric.upper())\n",
    "        ax.set_xlabel(\"Layer index\")\n",
    "        ax.set_ylabel(\"Mean value\")\n",
    "        ax.legend(fontsize=8)\n",
    "        ax.tick_params(axis=\"x\", rotation=0)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    out_path = OUT_DIR / f\"overview_{model}.png\"\n",
    "    plt.savefig(out_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"[saved] {out_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b15b55",
   "metadata": {},
   "source": [
    "# ==============================================\n",
    "# TopK Correlations ============================\n",
    "# =============================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b62baa",
   "metadata": {},
   "source": [
    "### ==============================================\n",
    "### Correlation with Pooling =====================\n",
    "### =============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bea4a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[merge] merged 50 parquet files → 17000 rows\n",
      "[diag] unique batch_index=50 | unique prompt_id=10 | unique (prompt,batch)=500\n",
      "[ok] prompt–batch pairs look good\n",
      "[expand] added 36 flattened top-k columns\n",
      "[ok] normalized disagree_correct_raw_@1 → len=15\n",
      "[ok] normalized disagree_correct_unit_rms_@1 → len=15\n",
      "[ok] normalized disagree_correct_norm_rms_@1 → len=15\n",
      "[ok] normalized logp_diff_raw → len=15\n",
      "[ok] normalized logp_diff_unit_rms → len=15\n",
      "[ok] normalized logp_diff_norm_rms → len=15\n",
      "[done] Anchors preprocessed (binary + continuous, unified padding)]\n",
      "[anchor_map] built 500 anchors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "disagree_correct_raw: 100%|██████████| 34/34 [00:37<00:00,  1.11s/it]\n",
      "disagree_correct_unit_rms: 100%|██████████| 34/34 [00:37<00:00,  1.11s/it]\n",
      "disagree_correct_norm_rms: 100%|██████████| 34/34 [00:38<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] disagree_correct → 1929 pooled correlations\n",
      "[nan check] 102 NaN correlations out of 1929 total\n",
      "[anchor_map] built 500 anchors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp_diff_raw:   0%|          | 0/34 [00:00<?, ?it/s]/media/am/AM/LogitDiffLens/logit-lens-env/lib/python3.10/site-packages/scipy/stats/_stats_py.py:5405: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rpb, prob = pearsonr(x, y)\n",
      "logp_diff_raw: 100%|██████████| 34/34 [00:30<00:00,  1.10it/s]\n",
      "logp_diff_unit_rms:   0%|          | 0/34 [00:00<?, ?it/s]/media/am/AM/LogitDiffLens/logit-lens-env/lib/python3.10/site-packages/scipy/stats/_stats_py.py:5405: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rpb, prob = pearsonr(x, y)\n",
      "logp_diff_unit_rms: 100%|██████████| 34/34 [00:32<00:00,  1.05it/s]\n",
      "logp_diff_norm_rms:   0%|          | 0/34 [00:00<?, ?it/s]/media/am/AM/LogitDiffLens/logit-lens-env/lib/python3.10/site-packages/scipy/stats/_stats_py.py:5405: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rpb, prob = pearsonr(x, y)\n",
      "logp_diff_norm_rms: 100%|██████████| 34/34 [00:31<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] logp_diff → 1929 pooled correlations\n",
      "[nan check] 102 NaN correlations out of 1929 total\n",
      "[saved pooled correlations] saved_data/summary/m_quant/lw_m_quant_corr_pooled.csv\n",
      "[saved summary] saved_data/summary/m_quant/lw_m_quant_corr_pooled_summary_both.csv\n",
      "[diag] rows=3858  groups=3858\n",
      "[NaN summary rows: 204]\n",
      "[saved pooled summary] saved_data/summary/m_quant/lw_m_quant_corr_pooled_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr, pearsonr, kendalltau, pointbiserialr, chi2_contingency\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Merge parquet files\n",
    "# ============================================================\n",
    "def merge_parquet_files(input_dir: str) -> pd.DataFrame:\n",
    "    files = sorted(Path(input_dir).glob(\"*.parquet\"))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No parquet files found in {input_dir}\")\n",
    "\n",
    "    dfs = []\n",
    "    for i, f in enumerate(files):\n",
    "        d = pd.read_parquet(f)\n",
    "        d[\"batch_index\"] = i\n",
    "        dfs.append(d)\n",
    "\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    print(f\"[merge] merged {len(files)} parquet files → {len(df)} rows\")\n",
    "\n",
    "    n_batches = df[\"batch_index\"].nunique()\n",
    "    n_prompts = df[\"prompt_id\"].nunique()\n",
    "    n_pairs = df.groupby([\"prompt_id\", \"batch_index\"]).ngroups\n",
    "    print(f\"[diag] unique batch_index={n_batches} | unique prompt_id={n_prompts} | unique (prompt,batch)={n_pairs}\")\n",
    "\n",
    "    if n_pairs < len(files) * 10:\n",
    "        print(\"[warn] fewer prompt–batch pairs than expected — possible ID overlap?\")\n",
    "    else:\n",
    "        print(\"[ok] prompt–batch pairs look good\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Expand nested top-k metrics (safe names)\n",
    "# ============================================================\n",
    "def expand_topk_metrics(df, metrics, modes=(\"raw\",\"unit_rms\",\"norm_rms\"), topk_levels=(1,5,10)):\n",
    "    new_cols=[]\n",
    "    for metric in metrics:\n",
    "        for mode in modes:\n",
    "            base=f\"{metric}_{mode}\"\n",
    "            if base not in df.columns:\n",
    "                continue\n",
    "            for k in topk_levels:\n",
    "                new=f\"{base}_@{k}\"\n",
    "                df[new]=df[base].apply(\n",
    "                    lambda d: np.array(d.get(f\"@{k}\",[]),float)\n",
    "                    if isinstance(d,dict) and f\"@{k}\" in d else np.array([])\n",
    "                )\n",
    "                new_cols.append(new)\n",
    "    print(f\"[expand] added {len(new_cols)} flattened top-k columns\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Helper\n",
    "# ============================================================\n",
    "\"\"\"def safe_flatten(x):\n",
    "    if isinstance(x,(list,np.ndarray)):\n",
    "        return np.array(x,float).flatten()\n",
    "    return np.array([],float)\"\"\"\n",
    "def safe_flatten(v):\n",
    "    \"\"\"Ensure flattening of nested lists/arrays into 1D np.array.\"\"\"\n",
    "    if isinstance(v, (list, np.ndarray)):\n",
    "        return np.asarray(v, dtype=float).flatten()\n",
    "    try:\n",
    "        return np.array([float(v)], dtype=float)\n",
    "    except Exception:\n",
    "        return np.array([], dtype=float)\n",
    "\n",
    "# ============================================================\n",
    "# Extract anchors \n",
    "# ============================================================\n",
    "def extract_top1_disagreement_anchor(df, modes=(\"raw\", \"unit_rms\", \"norm_rms\")):\n",
    "    \"\"\"\n",
    "    Normaliserer 'disagree_correct' top-1 anchors så de får ens længde og er arrays af floats.\n",
    "    Matcher forventningerne i correlate_layers_by_anchor().\n",
    "    \"\"\"\n",
    "    for mode in modes:\n",
    "        base_col = f\"disagree_correct_{mode}\"\n",
    "        if base_col not in df.columns:\n",
    "            print(f\"[warn] missing {base_col}\")\n",
    "            continue\n",
    "\n",
    "        lengths = df[base_col].apply(\n",
    "            lambda d: len(d.get(\"@1\", [])) if isinstance(d, dict) and \"@1\" in d else 0\n",
    "        )\n",
    "        max_len = int(lengths.max() or 0)\n",
    "\n",
    "        def to_array(d):\n",
    "            if isinstance(d, dict) and \"@1\" in d:\n",
    "                arr = np.asarray(d[\"@1\"], dtype=float)\n",
    "            else:\n",
    "                arr = np.full(max_len, np.nan, dtype=float)\n",
    "            # pad if shorter than max_len\n",
    "            if len(arr) < max_len:\n",
    "                arr = np.pad(arr, (0, max_len - len(arr)), constant_values=np.nan)\n",
    "            return arr\n",
    "\n",
    "        out_col = f\"{base_col}_@1\"\n",
    "        df[out_col] = df[base_col].apply(to_array)\n",
    "        print(f\"[ok] normalized {out_col} (mode={mode}) → length={max_len}, dtype=float\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\"\"\"def preprocess_anchors(df, modes=(\"raw\", \"unit_rms\", \"norm_rms\")):\n",
    "    # === BINARY ANCHOR ===\n",
    "    for mode in modes:\n",
    "        col = f\"disagree_correct_{mode}\"\n",
    "        if col not in df.columns:\n",
    "            print(f\"[warn] missing {col}\")\n",
    "            continue\n",
    "\n",
    "        # Find max length\n",
    "        max_len = int(df[col].apply(\n",
    "            lambda d: len(d.get(\"@1\", [])) if isinstance(d, dict) else 0\n",
    "        ).max() or 0)\n",
    "\n",
    "        def to_array(d):\n",
    "            if isinstance(d, dict) and \"@1\" in d:\n",
    "                arr = np.asarray(d[\"@1\"], dtype=float)\n",
    "            else:\n",
    "                arr = np.full(max_len, np.nan, dtype=float)\n",
    "            if len(arr) < max_len:\n",
    "                arr = np.pad(arr, (0, max_len - len(arr)), constant_values=np.nan)\n",
    "            return arr\n",
    "\n",
    "        df[f\"{col}_@1\"] = df[col].apply(to_array)\n",
    "        print(f\"[ok] normalized {col}_@1 → len={max_len}\")\n",
    "\n",
    "    # === CONTINIOUS ANCHOR ===\n",
    "    for mode in modes:\n",
    "        col = f\"logp_diff_{mode}\"\n",
    "        if col not in df.columns:\n",
    "            print(f\"[warn] missing {col}\")\n",
    "            continue\n",
    "\n",
    "        def to_array(v):\n",
    "            if isinstance(v, (list, np.ndarray)):\n",
    "                return np.asarray(v, dtype=float)\n",
    "            # fallback for single values\n",
    "            try:\n",
    "                return np.array([float(v)], dtype=float)\n",
    "            except Exception:\n",
    "                return np.array([np.nan], dtype=float)\n",
    "\n",
    "        df[col] = df[col].apply(to_array)\n",
    "        print(f\"[ok] flattened {col}\")\n",
    "\n",
    "    print(\"[done] Anchors preprocessed (binary + continuous)\")\n",
    "    return df\"\"\"\n",
    "\n",
    "def preprocess_anchors(df, modes=(\"raw\", \"unit_rms\", \"norm_rms\")):\n",
    "    \"\"\"\n",
    "    Preprocess anchors (binary + continuous) for correlation analysis.\n",
    "    Ensures consistent vector lengths and NaN padding across all prompts.\n",
    "    Works identically for pooled and per-prompt correlations.\n",
    "    \"\"\"\n",
    "\n",
    "    # === BINARY ANCHOR ===\n",
    "    for mode in modes:\n",
    "        col = f\"disagree_correct_{mode}\"\n",
    "        if col not in df.columns:\n",
    "            print(f\"[warn] missing {col}\")\n",
    "            continue\n",
    "\n",
    "        # find max sequence length (@1-level)\n",
    "        max_len = int(df[col].apply(\n",
    "            lambda d: len(d.get(\"@1\", [])) if isinstance(d, dict) else 0\n",
    "        ).max() or 0)\n",
    "\n",
    "        def to_array(d):\n",
    "            if isinstance(d, dict) and \"@1\" in d:\n",
    "                arr = np.asarray(d[\"@1\"], dtype=float)\n",
    "            else:\n",
    "                arr = np.full(max_len, np.nan, dtype=float)\n",
    "            # pad to consistent length\n",
    "            if len(arr) < max_len:\n",
    "                arr = np.pad(arr, (0, max_len - len(arr)), constant_values=np.nan)\n",
    "            return arr\n",
    "\n",
    "        df[f\"{col}_@1\"] = df[col].apply(to_array)\n",
    "        print(f\"[ok] normalized {col}_@1 → len={max_len}\")\n",
    "\n",
    "    # === CONTINUOUS ANCHOR ===\n",
    "    for mode in modes:\n",
    "        col = f\"logp_diff_{mode}\"\n",
    "        if col not in df.columns:\n",
    "            print(f\"[warn] missing {col}\")\n",
    "            continue\n",
    "\n",
    "        # find max length across all prompts\n",
    "        max_len = int(df[col].apply(\n",
    "            lambda v: len(v) if isinstance(v, (list, np.ndarray)) else 0\n",
    "        ).max() or 0)\n",
    "\n",
    "        def to_array(v):\n",
    "            if isinstance(v, (list, np.ndarray)):\n",
    "                arr = np.asarray(v, dtype=float)\n",
    "            else:\n",
    "                try:\n",
    "                    arr = np.array([float(v)], dtype=float)\n",
    "                except Exception:\n",
    "                    arr = np.array([np.nan], dtype=float)\n",
    "            # pad to uniform length\n",
    "            if len(arr) < max_len:\n",
    "                arr = np.pad(arr, (0, max_len - len(arr)), constant_values=np.nan)\n",
    "            return arr\n",
    "\n",
    "        df[col] = df[col].apply(to_array)\n",
    "        print(f\"[ok] normalized {col} → len={max_len}\")\n",
    "\n",
    "    print(\"[done] Anchors preprocessed (binary + continuous, unified padding)]\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Correlation \n",
    "# ============================================================\n",
    "def _is_binary(arr, tol=1e-6):\n",
    "    arr = np.asarray(arr, dtype=float)\n",
    "    arr = arr[~np.isnan(arr)]\n",
    "    if len(arr) == 0:\n",
    "        return False\n",
    "    u = np.unique(np.round(arr, 6))\n",
    "    return np.all((np.abs(u - 0) < tol) | (np.abs(u - 1) < tol))\n",
    "\n",
    "\n",
    "def _phi_coefficient(x, y):\n",
    "    \"\"\"Phi coefficient for two binary arrays (0/1).\"\"\"\n",
    "    x, y = np.asarray(x).astype(int), np.asarray(y).astype(int)\n",
    "    if len(x) == 0 or len(y) == 0:\n",
    "        return np.nan\n",
    "    try:\n",
    "        table = pd.crosstab(x, y)\n",
    "        if table.shape != (2, 2):\n",
    "            return np.nan\n",
    "        chi2, _, _, _ = chi2_contingency(table, correction=False)\n",
    "        sign = np.sign((table.loc[1,1]*table.loc[0,0]) - (table.loc[1,0]*table.loc[0,1]))\n",
    "        return float(sign * np.sqrt(chi2 / len(x)))\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "# --- Deterministic metric-type mapping ---\n",
    "METRIC_TYPES = {\n",
    "    # Binary accuracy/agreement\n",
    "    **{f\"acc_A_@{k}\": \"binary\" for k in [1, 5, 10]},\n",
    "    **{f\"acc_B_@{k}\": \"binary\" for k in [1, 5, 10]},\n",
    "    \"disagree_correct\": \"binary\",\n",
    "    \"agree_correct\": \"binary\",\n",
    "    \"agree_wrong\": \"binary\",\n",
    "    \"agree_set\": \"binary\",\n",
    "    \"disagree_set\": \"binary\",\n",
    "\n",
    "    # Jaccard: only @1 is expected to be binary however, in theory, the other level could be as well\n",
    "    \"jaccard_@1\": \"binary\",\n",
    "    \"jaccard_@5\": \"continuous\",\n",
    "    \"jaccard_@10\": \"continuous\",\n",
    "\n",
    "    # rest of metrics are expected to be continious\n",
    "}\n",
    "\n",
    "\n",
    "def _choose_corr_func_fixed(anchor, metric):\n",
    "    \"\"\"Deterministisk valg af korrelationstype ud fra kendt datanatur.\"\"\"\n",
    "    # Anchors: vi kender dem\n",
    "    anchor_t = \"binary\" if \"disagree_correct\" in anchor else \"continuous\"\n",
    "    metric_t = METRIC_TYPES.get(metric, \"continuous\")\n",
    "\n",
    "    # Klassiske statistiske regler\n",
    "    if anchor_t == \"binary\" and metric_t == \"binary\":\n",
    "        return \"phi\", _phi_coefficient\n",
    "    elif anchor_t == \"binary\" or metric_t == \"binary\":\n",
    "        return \"pointbiserial\", pointbiserialr\n",
    "    else:\n",
    "        return \"spearman\", spearmanr\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Correlation (pooled version)\n",
    "# ============================================================\n",
    "def correlate_layers_by_anchor(\n",
    "    df,\n",
    "    anchor,\n",
    "    metrics,\n",
    "    modes=(\"raw\", \"unit_rms\", \"norm_rms\"),\n",
    "    topk_levels=(1, 5, 10),\n",
    "    n_boot=10,\n",
    "    n_perm=10,\n",
    "    seed=42,\n",
    "    output_dir=None,\n",
    "    model=\"m_8bit\",\n",
    "    min_valid=3,\n",
    "):\n",
    "    np.random.seed(seed)\n",
    "    results = []\n",
    "    df_out = df[df[\"layer_name\"].str.lower() == \"output\"]\n",
    "\n",
    "    # --- Build anchor map ---\n",
    "    anchor_map = {}\n",
    "    for _, row in df_out.iterrows():\n",
    "        key = (int(row[\"prompt_id\"]), int(row.get(\"batch_index\", 0)))\n",
    "        anchor_vecs = {}\n",
    "        for mode in modes:\n",
    "            col1 = f\"{anchor}_{mode}_@1\"\n",
    "            col2 = f\"{anchor}_{mode}\"\n",
    "            col = col1 if col1 in df.columns else col2\n",
    "            val = row.get(col)\n",
    "            if isinstance(val, (list, np.ndarray)) and len(val) > 0:\n",
    "                anchor_vecs[mode] = np.array(val, float)\n",
    "        if anchor_vecs:\n",
    "            anchor_map[key] = anchor_vecs\n",
    "    print(f\"[anchor_map] built {len(anchor_map)} anchors\")\n",
    "\n",
    "    # --- Force raw for these metrics ---\n",
    "    SHARED_METRICS = {\"cosine_sim\", \"l2_dist\"}\n",
    "\n",
    "    # ============================================================\n",
    "    # MAIN LOOP\n",
    "    # ============================================================\n",
    "    for mode in modes:\n",
    "        for (lname, lidx), layer_df in tqdm(df.groupby([\"layer_name\", \"layer_index\"]), desc=f\"{anchor}_{mode}\"):\n",
    "            for metric in metrics:\n",
    "                # Only have top-k variants for accuracy/Jaccard\n",
    "                is_topk_only = metric in {\"acc_A\", \"acc_B\", \"jaccard\"}\n",
    "                suffixes = [f\"_@{k}\" for k in topk_levels] if is_topk_only else [\"\"] + [f\"_@{k}\" for k in topk_levels]\n",
    "\n",
    "                for suffix in suffixes:\n",
    "                    src_mode = \"raw\" if metric in SHARED_METRICS else mode\n",
    "                    mcol = f\"{metric}_{src_mode}{suffix}\"\n",
    "                    if mcol not in layer_df.columns:\n",
    "                        continue\n",
    "\n",
    "                    anchor_vals, metric_vals = [], []\n",
    "                    for (pid, bid), group in layer_df.groupby([\"prompt_id\", \"batch_index\"]):\n",
    "                        key = (int(pid), int(bid))\n",
    "                        if key not in anchor_map or mode not in anchor_map[key]:\n",
    "                            continue\n",
    "                        a = anchor_map[key][mode]\n",
    "                        m = np.asarray(group[mcol].iloc[0], dtype=float).flatten()\n",
    "                        n = min(len(a), len(m))\n",
    "                        if n < min_valid:\n",
    "                            continue\n",
    "                        a, m = a[:n], m[:n]\n",
    "                        mask = np.isfinite(a) & np.isfinite(m)\n",
    "                        if mask.sum() < min_valid:\n",
    "                            continue\n",
    "                        anchor_vals.append(a[mask])\n",
    "                        metric_vals.append(m[mask])\n",
    "\n",
    "                    # --- NaN ---\n",
    "                    if not anchor_vals:\n",
    "                        results.append({\n",
    "                            \"mode\": mode,\n",
    "                            \"anchor\": anchor,\n",
    "                            \"metric\": f\"{metric}{suffix}\",\n",
    "                            \"corr_type\": \"undefined\",\n",
    "                            \"layer_name\": lname,\n",
    "                            \"layer_index\": lidx,\n",
    "                            \"rho\": np.nan,\n",
    "                            \"rho_boot_median\": np.nan,\n",
    "                            \"ci_low\": np.nan,\n",
    "                            \"ci_high\": np.nan,\n",
    "                            \"p_val\": np.nan,\n",
    "                            \"p_perm\": np.nan,\n",
    "                            \"n\": 0,\n",
    "                            \"pooling\": \"pooled\"\n",
    "                        })\n",
    "                        continue\n",
    "\n",
    "                    A = np.concatenate(anchor_vals)\n",
    "                    M = np.concatenate(metric_vals)\n",
    "                    mask = np.isfinite(A) & np.isfinite(M)\n",
    "                    n_used = int(mask.sum())\n",
    "                    if n_used < min_valid:\n",
    "                        continue\n",
    "                    A, M = A[mask], M[mask]\n",
    "\n",
    "                    if np.std(A) == 0 or np.std(M) == 0:\n",
    "                        continue\n",
    "\n",
    "                    # --- correlation type (fixed deterministic rule) ---\n",
    "                    cname, func = _choose_corr_func_fixed(anchor, f\"{metric}{suffix}\")\n",
    "\n",
    "                    # fallback hvis alt ender binært i praksis\n",
    "                    \"\"\"if cname != \"phi\" and _is_binary(A) and _is_binary(M):\n",
    "                        cname, func = \"phi\", _phi_coefficient\"\"\"\n",
    "\n",
    "                    # --- rho ---\n",
    "                    try:\n",
    "                        if cname == \"phi\":\n",
    "                            rho = func(A, M)\n",
    "                            pval = np.nan\n",
    "                        else:\n",
    "                            rho, pval = func(A, M)\n",
    "                    except Exception:\n",
    "                        rho, pval = np.nan, np.nan\n",
    "                    if not np.isfinite(rho):\n",
    "                        continue\n",
    "\n",
    "                    # --- bootstrap CI ---\n",
    "                    boot_rhos = []\n",
    "                    for _ in range(n_boot):\n",
    "                        idx = np.random.choice(n_used, n_used, replace=True)\n",
    "                        try:\n",
    "                            if cname == \"phi\":\n",
    "                                rho_b = func(A[idx], M[idx])\n",
    "                            else:\n",
    "                                rho_b, _ = func(A[idx], M[idx])\n",
    "                        except Exception:\n",
    "                            rho_b = np.nan\n",
    "                        if np.isfinite(rho_b):\n",
    "                            boot_rhos.append(rho_b)\n",
    "                    if len(boot_rhos) > 20:\n",
    "                        ci_low, ci_high = np.percentile(boot_rhos, [2.5, 97.5])\n",
    "                        rho_boot = np.median(boot_rhos)\n",
    "                    else:\n",
    "                        ci_low = ci_high = rho_boot = np.nan\n",
    "\n",
    "                    # --- permutation test ---\n",
    "                    perm_rhos = []\n",
    "                    for _ in range(n_perm):\n",
    "                        try:\n",
    "                            if cname == \"phi\":\n",
    "                                rho_p = func(A, np.random.permutation(M))\n",
    "                            else:\n",
    "                                rho_p, _ = func(A, np.random.permutation(M))\n",
    "                        except Exception:\n",
    "                            rho_p = np.nan\n",
    "                        if np.isfinite(rho_p):\n",
    "                            perm_rhos.append(rho_p)\n",
    "                    if len(perm_rhos) > 20:\n",
    "                        perm_rhos = np.array(perm_rhos)\n",
    "                        p_perm = (np.sum(np.abs(perm_rhos) >= abs(rho)) + 1) / (len(perm_rhos) + 1)\n",
    "                    else:\n",
    "                        p_perm = np.nan\n",
    "\n",
    "                    results.append({\n",
    "                        \"mode\": mode,\n",
    "                        \"anchor\": anchor,\n",
    "                        \"metric\": f\"{metric}{suffix}\",\n",
    "                        \"corr_type\": cname,\n",
    "                        \"layer_name\": lname,\n",
    "                        \"layer_index\": lidx,\n",
    "                        \"rho\": rho,\n",
    "                        \"rho_boot_median\": rho_boot,\n",
    "                        \"ci_low\": ci_low,\n",
    "                        \"ci_high\": ci_high,\n",
    "                        \"p_val\": pval,\n",
    "                        \"p_perm\": p_perm,\n",
    "                        \"n\": n_used,\n",
    "                        \"pooling\": \"pooled\"\n",
    "                    })\n",
    "\n",
    "    # ============================================================\n",
    "    # Wrap up\n",
    "    # ============================================================\n",
    "    df_corr = pd.DataFrame(results)\n",
    "    print(f\"[ok] {anchor} → {len(df_corr)} pooled correlations\")\n",
    "    if not df_corr.empty:\n",
    "        print(f\"[nan check] {df_corr['rho'].isna().sum()} NaN correlations out of {len(df_corr)} total\")\n",
    "\n",
    "    if output_dir:\n",
    "        out_path = Path(output_dir) / f\"lw_{model}_{anchor}_corr_pooled.csv\"\n",
    "        df_corr.to_csv(out_path, index=False)\n",
    "        print(f\"[saved correlations] {out_path}\")\n",
    "\n",
    "    return df_corr\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Summarize correlations\n",
    "# ============================================================\n",
    "def summarize_correlations(df_corr, output_dir, model, ci_mode=\"both\"):\n",
    "    df = df_corr.copy()\n",
    "\n",
    "    if \"n\" not in df.columns:\n",
    "        df[\"n\"] = 1\n",
    "\n",
    "    # z (only where rho is finite)\n",
    "    df[\"z\"] = np.nan\n",
    "    mask_finite = np.isfinite(df[\"rho\"])\n",
    "    df.loc[mask_finite, \"z\"] = np.arctanh(np.clip(df.loc[mask_finite, \"rho\"], -0.999999, 0.999999))\n",
    "\n",
    "    drop_cols = [c for c in [\"prompt_id\", \"batch_index\"] if c in df.columns]\n",
    "    if drop_cols:\n",
    "        df = df.drop(columns=drop_cols)\n",
    "\n",
    "    group_cols = [\"mode\", \"anchor\", \"metric\", \"corr_type\", \"layer_name\", \"layer_index\"]\n",
    "\n",
    "    def _weighted_stats(g):\n",
    "        out = {}\n",
    "\n",
    "        if not np.any(np.isfinite(g[\"rho\"])) or g[\"n\"].sum() == 0:\n",
    "            # keep but mark as NaN\n",
    "            for key in [\n",
    "                \"rho_mean\", \"rho_low\", \"rho_high\",\n",
    "                \"rho_boot_mean\", \"ci_low_emp\", \"ci_high_emp\", \"n_total\"\n",
    "            ]:\n",
    "                out[key] = np.nan\n",
    "            out[\"n_total\"] = 0\n",
    "        else:\n",
    "            # Fisher-Z mean + CI\n",
    "            z = g[\"z\"].dropna()\n",
    "            w = g.loc[z.index, \"n\"]\n",
    "            z_mean = np.average(z, weights=w)\n",
    "            z_std = np.sqrt(np.average((z - z_mean)**2, weights=w))\n",
    "            out[\"rho_mean\"] = np.tanh(z_mean)\n",
    "            out[\"rho_low\"] = np.tanh(z_mean - 1.96 * z_std)\n",
    "            out[\"rho_high\"] = np.tanh(z_mean + 1.96 * z_std)\n",
    "            out[\"n_total\"] = g[\"n\"].sum()\n",
    "\n",
    "            # Empirical (bootstrap) weighted\n",
    "            out[\"rho_boot_mean\"] = np.average(g[\"rho_boot_median\"].fillna(0), weights=w)\n",
    "            out[\"ci_low_emp\"] = np.average(g[\"ci_low\"].fillna(0), weights=w)\n",
    "            out[\"ci_high_emp\"] = np.average(g[\"ci_high\"].fillna(0), weights=w)\n",
    "\n",
    "        for k in group_cols:\n",
    "            out[k] = g[k].iloc[0]\n",
    "        return pd.DataFrame([out])\n",
    "\n",
    "    df_summary = pd.concat(\n",
    "        [_weighted_stats(g) for _, g in df.groupby(group_cols, group_keys=False)],\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "    if ci_mode == \"empirical\":\n",
    "        df_summary[\"rho_low_plot\"] = df_summary[\"ci_low_emp\"]\n",
    "        df_summary[\"rho_high_plot\"] = df_summary[\"ci_high_emp\"]\n",
    "    elif ci_mode == \"fisherz\":\n",
    "        df_summary[\"rho_low_plot\"] = df_summary[\"rho_low\"]\n",
    "        df_summary[\"rho_high_plot\"] = df_summary[\"rho_high\"]\n",
    "    else:\n",
    "        df_summary[\"rho_low_plot\"] = df_summary[\"rho_low\"]\n",
    "        df_summary[\"rho_high_plot\"] = df_summary[\"rho_high\"]\n",
    "\n",
    "    out_summary = Path(output_dir) / f\"lw_{model}_corr_pooled_summary_{ci_mode}.csv\"\n",
    "    df_summary.to_csv(out_summary, index=False)\n",
    "\n",
    "    print(f\"[saved summary] {out_summary}\")\n",
    "    print(f\"[diag] rows={len(df_summary)}  groups={df[group_cols].drop_duplicates().shape[0]}\")\n",
    "    print(f\"[NaN summary rows: {df_summary['rho_mean'].isna().sum()}]\")\n",
    "    return df_summary\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Run pooled correlation pipeline \n",
    "# ============================================================\n",
    "BASE = Path(\"saved_data\")\n",
    "model = \"m_quant\"\n",
    "output_dir = BASE / \"summary\" / model\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "topk_dir = BASE / \"topk\" / model\n",
    "df_topk = merge_parquet_files(topk_dir)\n",
    "df_topk = expand_topk_metrics(\n",
    "    df_topk,\n",
    "    metrics=[\"jaccard\", \"acc_A\", \"acc_B\", \"disagree_correct\"],\n",
    "    modes=(\"raw\", \"unit_rms\", \"norm_rms\")\n",
    ")\n",
    "df_topk = preprocess_anchors(df_topk)\n",
    "\n",
    "for m in [\"cosine_sim\", \"l2_dist\"]:\n",
    "    if f\"{m}_raw\" in df_topk.columns:\n",
    "        for mode in [\"unit_rms\", \"norm_rms\"]:\n",
    "            col_src = f\"{m}_raw\"\n",
    "            col_dst = f\"{m}_{mode}\"\n",
    "            if col_dst not in df_topk.columns:\n",
    "                df_topk[col_dst] = df_topk[col_src]\n",
    "                print(f\"[copy] propagated {col_src} → {col_dst}\")\n",
    "\n",
    "anchors = [\"disagree_correct\", \"logp_diff\"]\n",
    "metrics = [\n",
    "    \"kl_ab\", \"kl_ba\", \"js_div\", \"js_dist\", \"tvd\",\n",
    "    \"entropy_A\", \"entropy_B\", \"cosine_sim\", \"l2_dist\",\n",
    "    \"ppl_diff\", \"jaccard\", \"acc_A\", \"acc_B\"\n",
    "]\n",
    "\n",
    "df_corr_all = []\n",
    "for a in anchors:\n",
    "    df_corr_all.append(correlate_layers_by_anchor(df_topk, a, metrics, model=model))\n",
    "df_corr_all = pd.concat(df_corr_all, ignore_index=True)\n",
    "\n",
    "pooled_corr_path = output_dir / f\"lw_{model}_corr_pooled.csv\"\n",
    "pooled_summary_path = output_dir / f\"lw_{model}_corr_pooled_summary.csv\"\n",
    "\n",
    "df_corr_all.to_csv(pooled_corr_path, index=False)\n",
    "print(f\"[saved pooled correlations] {pooled_corr_path}\")\n",
    "\n",
    "df_summary = summarize_correlations(df_corr_all, output_dir=output_dir, model=model)\n",
    "print(f\"[saved pooled summary] {pooled_summary_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efabf6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "metric\n",
       "ppl_diff       1.0\n",
       "acc_A_@10      0.0\n",
       "acc_A_@1       0.0\n",
       "acc_A_@5       0.0\n",
       "acc_B_@1       0.0\n",
       "acc_B_@5       0.0\n",
       "acc_B_@10      0.0\n",
       "entropy_A      0.0\n",
       "entropy_B      0.0\n",
       "jaccard_@1     0.0\n",
       "cosine_sim     0.0\n",
       "jaccard_@10    0.0\n",
       "jaccard_@5     0.0\n",
       "js_div         0.0\n",
       "js_dist        0.0\n",
       "kl_ab          0.0\n",
       "kl_ba          0.0\n",
       "l2_dist        0.0\n",
       "tvd            0.0\n",
       "Name: rho, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corr_all[df_corr_all[\"rho\"].isna()].groupby(\"layer_name\").size()\n",
    "\n",
    "df_corr_all.groupby(\"metric\")[\"rho\"].apply(lambda s: s.isna().mean()).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "513a1168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mode\n",
       "norm_rms   -0.040288\n",
       "raw        -0.040288\n",
       "unit_rms   -0.040288\n",
       "Name: rho, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corr_all.query(\"metric.str.contains('cosine_sim')\").groupby(\"mode\")[\"rho\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e9e4281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          rho  rho_mean\n",
      "rho       1.0       1.0\n",
      "rho_mean  1.0       1.0\n"
     ]
    }
   ],
   "source": [
    "merged = pd.merge(\n",
    "    df_corr_all, df_summary,\n",
    "    on=[\"mode\",\"anchor\",\"metric\",\"corr_type\",\"layer_name\",\"layer_index\"],\n",
    "    how=\"inner\",\n",
    "    suffixes=(\"_corr\",\"_sum\")\n",
    ")\n",
    "print(merged[[\"rho\",\"rho_mean\"]].corr())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4bf0388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mode</th>\n",
       "      <th>anchor</th>\n",
       "      <th>metric</th>\n",
       "      <th>corr_type</th>\n",
       "      <th>layer_name</th>\n",
       "      <th>layer_index</th>\n",
       "      <th>rho</th>\n",
       "      <th>rho_boot_median</th>\n",
       "      <th>ci_low</th>\n",
       "      <th>ci_high</th>\n",
       "      <th>p_val</th>\n",
       "      <th>p_perm</th>\n",
       "      <th>n</th>\n",
       "      <th>pooling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>raw</td>\n",
       "      <td>disagree_correct</td>\n",
       "      <td>kl_ab</td>\n",
       "      <td>pointbiserial</td>\n",
       "      <td>embed_tokens</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.023328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.759996e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5044</td>\n",
       "      <td>pooled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>raw</td>\n",
       "      <td>disagree_correct</td>\n",
       "      <td>kl_ba</td>\n",
       "      <td>pointbiserial</td>\n",
       "      <td>embed_tokens</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.018672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.848729e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5044</td>\n",
       "      <td>pooled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>raw</td>\n",
       "      <td>disagree_correct</td>\n",
       "      <td>js_div</td>\n",
       "      <td>pointbiserial</td>\n",
       "      <td>embed_tokens</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.115474e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5044</td>\n",
       "      <td>pooled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>raw</td>\n",
       "      <td>disagree_correct</td>\n",
       "      <td>js_dist</td>\n",
       "      <td>pointbiserial</td>\n",
       "      <td>embed_tokens</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.002287</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.709944e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5044</td>\n",
       "      <td>pooled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>raw</td>\n",
       "      <td>disagree_correct</td>\n",
       "      <td>tvd</td>\n",
       "      <td>pointbiserial</td>\n",
       "      <td>embed_tokens</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.012805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.632298e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5044</td>\n",
       "      <td>pooled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3829</th>\n",
       "      <td>norm_rms</td>\n",
       "      <td>logp_diff</td>\n",
       "      <td>acc_A_@5</td>\n",
       "      <td>pointbiserial</td>\n",
       "      <td>output</td>\n",
       "      <td>32</td>\n",
       "      <td>0.160517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.829454e-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5044</td>\n",
       "      <td>pooled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3830</th>\n",
       "      <td>norm_rms</td>\n",
       "      <td>logp_diff</td>\n",
       "      <td>acc_A_@10</td>\n",
       "      <td>pointbiserial</td>\n",
       "      <td>output</td>\n",
       "      <td>32</td>\n",
       "      <td>0.181674</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.103509e-38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5044</td>\n",
       "      <td>pooled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3831</th>\n",
       "      <td>norm_rms</td>\n",
       "      <td>logp_diff</td>\n",
       "      <td>acc_B_@1</td>\n",
       "      <td>pointbiserial</td>\n",
       "      <td>output</td>\n",
       "      <td>32</td>\n",
       "      <td>0.064232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.985200e-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5044</td>\n",
       "      <td>pooled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3832</th>\n",
       "      <td>norm_rms</td>\n",
       "      <td>logp_diff</td>\n",
       "      <td>acc_B_@5</td>\n",
       "      <td>pointbiserial</td>\n",
       "      <td>output</td>\n",
       "      <td>32</td>\n",
       "      <td>0.125667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.296032e-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5044</td>\n",
       "      <td>pooled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3833</th>\n",
       "      <td>norm_rms</td>\n",
       "      <td>logp_diff</td>\n",
       "      <td>acc_B_@10</td>\n",
       "      <td>pointbiserial</td>\n",
       "      <td>output</td>\n",
       "      <td>32</td>\n",
       "      <td>0.156016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.490267e-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5044</td>\n",
       "      <td>pooled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3834 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          mode            anchor     metric      corr_type    layer_name  \\\n",
       "0          raw  disagree_correct      kl_ab  pointbiserial  embed_tokens   \n",
       "1          raw  disagree_correct      kl_ba  pointbiserial  embed_tokens   \n",
       "2          raw  disagree_correct     js_div  pointbiserial  embed_tokens   \n",
       "3          raw  disagree_correct    js_dist  pointbiserial  embed_tokens   \n",
       "4          raw  disagree_correct        tvd  pointbiserial  embed_tokens   \n",
       "...        ...               ...        ...            ...           ...   \n",
       "3829  norm_rms         logp_diff   acc_A_@5  pointbiserial        output   \n",
       "3830  norm_rms         logp_diff  acc_A_@10  pointbiserial        output   \n",
       "3831  norm_rms         logp_diff   acc_B_@1  pointbiserial        output   \n",
       "3832  norm_rms         logp_diff   acc_B_@5  pointbiserial        output   \n",
       "3833  norm_rms         logp_diff  acc_B_@10  pointbiserial        output   \n",
       "\n",
       "      layer_index       rho  rho_boot_median  ci_low  ci_high         p_val  \\\n",
       "0              -1  0.023328              NaN     NaN      NaN  9.759996e-02   \n",
       "1              -1 -0.018672              NaN     NaN      NaN  1.848729e-01   \n",
       "2              -1  0.001565              NaN     NaN      NaN  9.115474e-01   \n",
       "3              -1 -0.002287              NaN     NaN      NaN  8.709944e-01   \n",
       "4              -1 -0.012805              NaN     NaN      NaN  3.632298e-01   \n",
       "...           ...       ...              ...     ...      ...           ...   \n",
       "3829           32  0.160517              NaN     NaN      NaN  1.829454e-30   \n",
       "3830           32  0.181674              NaN     NaN      NaN  1.103509e-38   \n",
       "3831           32  0.064232              NaN     NaN      NaN  4.985200e-06   \n",
       "3832           32  0.125667              NaN     NaN      NaN  3.296032e-19   \n",
       "3833           32  0.156016              NaN     NaN      NaN  7.490267e-29   \n",
       "\n",
       "      p_perm     n pooling  \n",
       "0        NaN  5044  pooled  \n",
       "1        NaN  5044  pooled  \n",
       "2        NaN  5044  pooled  \n",
       "3        NaN  5044  pooled  \n",
       "4        NaN  5044  pooled  \n",
       "...      ...   ...     ...  \n",
       "3829     NaN  5044  pooled  \n",
       "3830     NaN  5044  pooled  \n",
       "3831     NaN  5044  pooled  \n",
       "3832     NaN  5044  pooled  \n",
       "3833     NaN  5044  pooled  \n",
       "\n",
       "[3834 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corr_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66dbc9f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rho_mean</th>\n",
       "      <th>rho_low</th>\n",
       "      <th>rho_high</th>\n",
       "      <th>n_total</th>\n",
       "      <th>rho_boot_mean</th>\n",
       "      <th>ci_low_emp</th>\n",
       "      <th>ci_high_emp</th>\n",
       "      <th>mode</th>\n",
       "      <th>anchor</th>\n",
       "      <th>metric</th>\n",
       "      <th>corr_type</th>\n",
       "      <th>layer_name</th>\n",
       "      <th>layer_index</th>\n",
       "      <th>rho_low_plot</th>\n",
       "      <th>rho_high_plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.001788</td>\n",
       "      <td>-0.001788</td>\n",
       "      <td>-0.001788</td>\n",
       "      <td>5044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>norm_rms</td>\n",
       "      <td>disagree_correct</td>\n",
       "      <td>acc_A_@1</td>\n",
       "      <td>phi</td>\n",
       "      <td>layer.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.001788</td>\n",
       "      <td>-0.001788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.002528</td>\n",
       "      <td>-0.002528</td>\n",
       "      <td>-0.002528</td>\n",
       "      <td>5044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>norm_rms</td>\n",
       "      <td>disagree_correct</td>\n",
       "      <td>acc_A_@1</td>\n",
       "      <td>phi</td>\n",
       "      <td>layer.10</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.002528</td>\n",
       "      <td>-0.002528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.002528</td>\n",
       "      <td>-0.002528</td>\n",
       "      <td>-0.002528</td>\n",
       "      <td>5044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>norm_rms</td>\n",
       "      <td>disagree_correct</td>\n",
       "      <td>acc_A_@1</td>\n",
       "      <td>phi</td>\n",
       "      <td>layer.11</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.002528</td>\n",
       "      <td>-0.002528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.001788</td>\n",
       "      <td>-0.001788</td>\n",
       "      <td>-0.001788</td>\n",
       "      <td>5044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>norm_rms</td>\n",
       "      <td>disagree_correct</td>\n",
       "      <td>acc_A_@1</td>\n",
       "      <td>phi</td>\n",
       "      <td>layer.12</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.001788</td>\n",
       "      <td>-0.001788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.004381</td>\n",
       "      <td>-0.004381</td>\n",
       "      <td>-0.004381</td>\n",
       "      <td>5044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>norm_rms</td>\n",
       "      <td>disagree_correct</td>\n",
       "      <td>acc_A_@1</td>\n",
       "      <td>phi</td>\n",
       "      <td>layer.13</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.004381</td>\n",
       "      <td>-0.004381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3829</th>\n",
       "      <td>0.017870</td>\n",
       "      <td>0.017870</td>\n",
       "      <td>0.017870</td>\n",
       "      <td>5044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unit_rms</td>\n",
       "      <td>logp_diff</td>\n",
       "      <td>tvd</td>\n",
       "      <td>spearman</td>\n",
       "      <td>layer.6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.017870</td>\n",
       "      <td>0.017870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3830</th>\n",
       "      <td>0.031248</td>\n",
       "      <td>0.031248</td>\n",
       "      <td>0.031248</td>\n",
       "      <td>5044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unit_rms</td>\n",
       "      <td>logp_diff</td>\n",
       "      <td>tvd</td>\n",
       "      <td>spearman</td>\n",
       "      <td>layer.7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.031248</td>\n",
       "      <td>0.031248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3831</th>\n",
       "      <td>0.036456</td>\n",
       "      <td>0.036456</td>\n",
       "      <td>0.036456</td>\n",
       "      <td>5044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unit_rms</td>\n",
       "      <td>logp_diff</td>\n",
       "      <td>tvd</td>\n",
       "      <td>spearman</td>\n",
       "      <td>layer.8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.036456</td>\n",
       "      <td>0.036456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3832</th>\n",
       "      <td>0.036417</td>\n",
       "      <td>0.036417</td>\n",
       "      <td>0.036417</td>\n",
       "      <td>5044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unit_rms</td>\n",
       "      <td>logp_diff</td>\n",
       "      <td>tvd</td>\n",
       "      <td>spearman</td>\n",
       "      <td>layer.9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.036417</td>\n",
       "      <td>0.036417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3833</th>\n",
       "      <td>0.019022</td>\n",
       "      <td>0.019022</td>\n",
       "      <td>0.019022</td>\n",
       "      <td>5044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unit_rms</td>\n",
       "      <td>logp_diff</td>\n",
       "      <td>tvd</td>\n",
       "      <td>spearman</td>\n",
       "      <td>output</td>\n",
       "      <td>32</td>\n",
       "      <td>0.019022</td>\n",
       "      <td>0.019022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3834 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rho_mean   rho_low  rho_high  n_total  rho_boot_mean  ci_low_emp  \\\n",
       "0    -0.001788 -0.001788 -0.001788     5044            0.0         0.0   \n",
       "1    -0.002528 -0.002528 -0.002528     5044            0.0         0.0   \n",
       "2    -0.002528 -0.002528 -0.002528     5044            0.0         0.0   \n",
       "3    -0.001788 -0.001788 -0.001788     5044            0.0         0.0   \n",
       "4    -0.004381 -0.004381 -0.004381     5044            0.0         0.0   \n",
       "...        ...       ...       ...      ...            ...         ...   \n",
       "3829  0.017870  0.017870  0.017870     5044            0.0         0.0   \n",
       "3830  0.031248  0.031248  0.031248     5044            0.0         0.0   \n",
       "3831  0.036456  0.036456  0.036456     5044            0.0         0.0   \n",
       "3832  0.036417  0.036417  0.036417     5044            0.0         0.0   \n",
       "3833  0.019022  0.019022  0.019022     5044            0.0         0.0   \n",
       "\n",
       "      ci_high_emp      mode            anchor    metric corr_type layer_name  \\\n",
       "0             0.0  norm_rms  disagree_correct  acc_A_@1       phi    layer.1   \n",
       "1             0.0  norm_rms  disagree_correct  acc_A_@1       phi   layer.10   \n",
       "2             0.0  norm_rms  disagree_correct  acc_A_@1       phi   layer.11   \n",
       "3             0.0  norm_rms  disagree_correct  acc_A_@1       phi   layer.12   \n",
       "4             0.0  norm_rms  disagree_correct  acc_A_@1       phi   layer.13   \n",
       "...           ...       ...               ...       ...       ...        ...   \n",
       "3829          0.0  unit_rms         logp_diff       tvd  spearman    layer.6   \n",
       "3830          0.0  unit_rms         logp_diff       tvd  spearman    layer.7   \n",
       "3831          0.0  unit_rms         logp_diff       tvd  spearman    layer.8   \n",
       "3832          0.0  unit_rms         logp_diff       tvd  spearman    layer.9   \n",
       "3833          0.0  unit_rms         logp_diff       tvd  spearman     output   \n",
       "\n",
       "      layer_index  rho_low_plot  rho_high_plot  \n",
       "0               1     -0.001788      -0.001788  \n",
       "1              10     -0.002528      -0.002528  \n",
       "2              11     -0.002528      -0.002528  \n",
       "3              12     -0.001788      -0.001788  \n",
       "4              13     -0.004381      -0.004381  \n",
       "...           ...           ...            ...  \n",
       "3829            6      0.017870       0.017870  \n",
       "3830            7      0.031248       0.031248  \n",
       "3831            8      0.036456       0.036456  \n",
       "3832            9      0.036417       0.036417  \n",
       "3833           32      0.019022       0.019022  \n",
       "\n",
       "[3834 rows x 15 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78e4b07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mode                  0\n",
       "anchor                0\n",
       "metric                0\n",
       "corr_type             0\n",
       "layer_name            0\n",
       "layer_index           0\n",
       "rho                 204\n",
       "rho_boot_median    3834\n",
       "ci_low             3834\n",
       "ci_high            3834\n",
       "p_val               897\n",
       "p_perm             3834\n",
       "n                     0\n",
       "pooling               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corr_all.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2add52da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rho_mean         204\n",
       "rho_low          204\n",
       "rho_high         204\n",
       "n_total            0\n",
       "rho_boot_mean    204\n",
       "ci_low_emp       204\n",
       "ci_high_emp      204\n",
       "mode               0\n",
       "anchor             0\n",
       "metric             0\n",
       "corr_type          0\n",
       "layer_name         0\n",
       "layer_index        0\n",
       "rho_low_plot     204\n",
       "rho_high_plot    204\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e985d1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfp = df_corr_all[df_corr_all[\"anchor\"] == \"disagree_correct\"]\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.lineplot(\n",
    "    data=dfp.dropna(subset=[\"rho\"]),\n",
    "    x=\"layer_index\", y=\"rho\",\n",
    "    hue=\"mode\"\n",
    ")\n",
    "\n",
    "# markér manglende lag\n",
    "missing = dfp[dfp[\"rho\"].isna()][\"layer_index\"].unique()\n",
    "plt.scatter(missing, [0]*len(missing), color=\"red\", marker=\"x\", label=\"missing\")\n",
    "plt.legend()\n",
    "plt.title(\"Disagree_correct correlation (NaN marked as red crosses)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80ae653",
   "metadata": {},
   "source": [
    "### ==============================================\n",
    "### Correlation Per Prompt =======================\n",
    "### =============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e172596a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[merge] merged 50 parquet files → 17000 rows\n",
      "[diag] unique batch_index=50 | unique prompt_id=10 | unique (prompt,batch)=500\n",
      "[ok] prompt–batch pairs look good\n",
      "[expand] added 36 flattened top-k columns\n",
      "[ok] normalized disagree_correct_raw_@1 → len=15\n",
      "[ok] normalized disagree_correct_unit_rms_@1 → len=15\n",
      "[ok] normalized disagree_correct_norm_rms_@1 → len=15\n",
      "[ok] normalized logp_diff_raw → len=15\n",
      "[ok] normalized logp_diff_unit_rms → len=15\n",
      "[ok] normalized logp_diff_norm_rms → len=15\n",
      "[done] Anchors preprocessed (binary + continuous, unified padding)]\n",
      "[anchor_map] built 500 anchors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "disagree_correct_raw: 100%|██████████| 34/34 [02:16<00:00,  4.00s/it]\n",
      "disagree_correct_unit_rms: 100%|██████████| 34/34 [02:14<00:00,  3.96s/it]\n",
      "disagree_correct_norm_rms: 100%|██████████| 34/34 [02:15<00:00,  4.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] disagree_correct → 1938 per-prompt correlations\n",
      "[NaN correlations: 111]\n",
      "[skipped constant=291515]\n",
      "[anchor_map] built 500 anchors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp_diff_raw: 100%|██████████| 34/34 [01:09<00:00,  2.05s/it]\n",
      "logp_diff_unit_rms: 100%|██████████| 34/34 [01:10<00:00,  2.07s/it]\n",
      "logp_diff_norm_rms: 100%|██████████| 34/34 [01:10<00:00,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] logp_diff → 1938 per-prompt correlations\n",
      "[NaN correlations: 111]\n",
      "[skipped constant=237054]\n",
      "[saved per-prompt correlations] saved_data/summary/m_quant/lw_m_quant_corr_perprompt.csv\n",
      "[saved summary] saved_data/summary/m_quant/lw_m_quant_corr_perprompt_summary_both.csv\n",
      "[diag] rows=3654  groups=3654\n",
      "[saved per-prompt summary] saved_data/summary/m_quant/lw_m_quant_corr_perprompt_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr, pearsonr, kendalltau, pointbiserialr, chi2_contingency\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Merge parquet files\n",
    "# ============================================================\n",
    "def merge_parquet_files(input_dir: str) -> pd.DataFrame:\n",
    "    files = sorted(Path(input_dir).glob(\"*.parquet\"))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No parquet files found in {input_dir}\")\n",
    "\n",
    "    dfs = []\n",
    "    for i, f in enumerate(files):\n",
    "        d = pd.read_parquet(f)\n",
    "        d[\"batch_index\"] = i\n",
    "        dfs.append(d)\n",
    "\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    print(f\"[merge] merged {len(files)} parquet files → {len(df)} rows\")\n",
    "\n",
    "    n_batches = df[\"batch_index\"].nunique()\n",
    "    n_prompts = df[\"prompt_id\"].nunique()\n",
    "    n_pairs = df.groupby([\"prompt_id\", \"batch_index\"]).ngroups\n",
    "    print(f\"[diag] unique batch_index={n_batches} | unique prompt_id={n_prompts} | unique (prompt,batch)={n_pairs}\")\n",
    "\n",
    "    if n_pairs < len(files) * 10:\n",
    "        print(\"[warn] fewer prompt–batch pairs than expected — possible ID overlap?\")\n",
    "    else:\n",
    "        print(\"[ok] prompt–batch pairs look good\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Expand nested top-k metrics \n",
    "# ============================================================\n",
    "def expand_topk_metrics(df, metrics, modes=(\"raw\",\"unit_rms\",\"norm_rms\"), topk_levels=(1,5,10)):\n",
    "    new_cols=[]\n",
    "    for metric in metrics:\n",
    "        for mode in modes:\n",
    "            base=f\"{metric}_{mode}\"\n",
    "            if base not in df.columns:\n",
    "                continue\n",
    "            for k in topk_levels:\n",
    "                new=f\"{base}_@{k}\"\n",
    "                df[new]=df[base].apply(\n",
    "                    lambda d: np.array(d.get(f\"@{k}\",[]),float)\n",
    "                    if isinstance(d,dict) and f\"@{k}\" in d else np.array([])\n",
    "                )\n",
    "                new_cols.append(new)\n",
    "    print(f\"[expand] added {len(new_cols)} flattened top-k columns\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Helper\n",
    "# ============================================================\n",
    "\"\"\"def safe_flatten(x):\n",
    "    if isinstance(x,(list,np.ndarray)):\n",
    "        return np.array(x,float).flatten()\n",
    "    return np.array([],float)\"\"\"\n",
    "def safe_flatten(v):\n",
    "    \"\"\"Ensure flattening of nested lists/arrays into 1D np.array.\"\"\"\n",
    "    if isinstance(v, (list, np.ndarray)):\n",
    "        return np.asarray(v, dtype=float).flatten()\n",
    "    try:\n",
    "        return np.array([float(v)], dtype=float)\n",
    "    except Exception:\n",
    "        return np.array([], dtype=float)\n",
    "\n",
    "# ============================================================\n",
    "# Extract anchors \n",
    "# ============================================================\n",
    "def extract_top1_disagreement_anchor(df, modes=(\"raw\",\"unit_rms\",\"norm_rms\")):\n",
    "    for mode in modes:\n",
    "        col=f\"disagree_correct_{mode}\"\n",
    "        if col not in df.columns:\n",
    "            print(f\"[warn] missing {col}\")\n",
    "            continue\n",
    "        max_len=int(df[col].apply(\n",
    "            lambda d: len(d.get(\"@1\",[])) if isinstance(d,dict) else 0\n",
    "        ).max() or 0)\n",
    "        def to_array(d):\n",
    "            if isinstance(d,dict) and \"@1\" in d:\n",
    "                arr=np.array(d[\"@1\"],float)\n",
    "            else:\n",
    "                arr=np.full(max_len,np.nan)\n",
    "            return arr\n",
    "        df[f\"{col}_@1\"]=df[col].apply(to_array)\n",
    "        print(f\"[ok] normalized {col}_@1 → len={max_len}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "\"\"\"def preprocess_anchors(df, modes=(\"raw\", \"unit_rms\", \"norm_rms\")):\n",
    "    for mode in modes:\n",
    "        col = f\"disagree_correct_{mode}\"\n",
    "        if col not in df.columns:\n",
    "            print(f\"[warn] missing {col}\")\n",
    "            continue\n",
    "\n",
    "        # find max length\n",
    "        max_len = int(df[col].apply(\n",
    "            lambda d: len(d.get(\"@1\", [])) if isinstance(d, dict) else 0\n",
    "        ).max() or 0)\n",
    "\n",
    "        def to_array(d):\n",
    "            if isinstance(d, dict) and \"@1\" in d:\n",
    "                arr = np.asarray(d[\"@1\"], dtype=float)\n",
    "            else:\n",
    "                arr = np.full(max_len, np.nan, dtype=float)\n",
    "            if len(arr) < max_len:\n",
    "                arr = np.pad(arr, (0, max_len - len(arr)), constant_values=np.nan)\n",
    "            return arr\n",
    "\n",
    "        df[f\"{col}_@1\"] = df[col].apply(to_array)\n",
    "        print(f\"[ok] normalized {col}_@1 → len={max_len}\")\n",
    "\n",
    "    for mode in modes:\n",
    "        col = f\"logp_diff_{mode}\"\n",
    "        if col not in df.columns:\n",
    "            print(f\"[warn] missing {col}\")\n",
    "            continue\n",
    "\n",
    "        def to_array(v):\n",
    "            if isinstance(v, (list, np.ndarray)):\n",
    "                return np.asarray(v, dtype=float)\n",
    "            # fallback for single values\n",
    "            try:\n",
    "                return np.array([float(v)], dtype=float)\n",
    "            except Exception:\n",
    "                return np.array([np.nan], dtype=float)\n",
    "\n",
    "        df[col] = df[col].apply(to_array)\n",
    "        print(f\"[ok] flattened {col}\")\n",
    "\n",
    "    print(\"[done] Anchors preprocessed (binary + continuous)\")\n",
    "    return df\"\"\"\n",
    "\n",
    "def preprocess_anchors(df, modes=(\"raw\", \"unit_rms\", \"norm_rms\")):\n",
    "    # === BINARY ANCHOR ===\n",
    "    for mode in modes:\n",
    "        col = f\"disagree_correct_{mode}\"\n",
    "        if col not in df.columns:\n",
    "            print(f\"[warn] missing {col}\")\n",
    "            continue\n",
    "\n",
    "        # find max sequence length (@1-level)\n",
    "        max_len = int(df[col].apply(\n",
    "            lambda d: len(d.get(\"@1\", [])) if isinstance(d, dict) else 0\n",
    "        ).max() or 0)\n",
    "\n",
    "        def to_array(d):\n",
    "            if isinstance(d, dict) and \"@1\" in d:\n",
    "                arr = np.asarray(d[\"@1\"], dtype=float)\n",
    "            else:\n",
    "                arr = np.full(max_len, np.nan, dtype=float)\n",
    "            # pad to consistent length\n",
    "            if len(arr) < max_len:\n",
    "                arr = np.pad(arr, (0, max_len - len(arr)), constant_values=np.nan)\n",
    "            return arr\n",
    "\n",
    "        df[f\"{col}_@1\"] = df[col].apply(to_array)\n",
    "        print(f\"[ok] normalized {col}_@1 → len={max_len}\")\n",
    "\n",
    "    # === CONTINUOUS ANCHOR ===\n",
    "    for mode in modes:\n",
    "        col = f\"logp_diff_{mode}\"\n",
    "        if col not in df.columns:\n",
    "            print(f\"[warn] missing {col}\")\n",
    "            continue\n",
    "\n",
    "        # find max length across all prompts\n",
    "        max_len = int(df[col].apply(\n",
    "            lambda v: len(v) if isinstance(v, (list, np.ndarray)) else 0\n",
    "        ).max() or 0)\n",
    "\n",
    "        def to_array(v):\n",
    "            if isinstance(v, (list, np.ndarray)):\n",
    "                arr = np.asarray(v, dtype=float)\n",
    "            else:\n",
    "                try:\n",
    "                    arr = np.array([float(v)], dtype=float)\n",
    "                except Exception:\n",
    "                    arr = np.array([np.nan], dtype=float)\n",
    "            # pad to uniform length\n",
    "            if len(arr) < max_len:\n",
    "                arr = np.pad(arr, (0, max_len - len(arr)), constant_values=np.nan)\n",
    "            return arr\n",
    "\n",
    "        df[col] = df[col].apply(to_array)\n",
    "        print(f\"[ok] normalized {col} → len={max_len}\")\n",
    "\n",
    "    print(\"[done] Anchors preprocessed (binary + continuous, unified padding)]\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Correlation \n",
    "# ============================================================\n",
    "def _is_binary(arr, tol=1e-6):\n",
    "    arr = np.asarray(arr, dtype=float)\n",
    "    arr = arr[~np.isnan(arr)]\n",
    "    if len(arr) == 0:\n",
    "        return False\n",
    "    u = np.unique(np.round(arr, 6))\n",
    "    return np.all((np.abs(u - 0) < tol) | (np.abs(u - 1) < tol))\n",
    "\n",
    "\n",
    "def _phi_coefficient(x, y):\n",
    "    \"\"\"Phi coefficient for two binary arrays (0/1).\"\"\"\n",
    "    x, y = np.asarray(x).astype(int), np.asarray(y).astype(int)\n",
    "    if len(x) == 0 or len(y) == 0:\n",
    "        return np.nan\n",
    "    try:\n",
    "        table = pd.crosstab(x, y)\n",
    "        if table.shape != (2, 2):\n",
    "            return np.nan\n",
    "        chi2, _, _, _ = chi2_contingency(table, correction=False)\n",
    "        sign = np.sign((table.loc[1, 1] * table.loc[0, 0]) - (table.loc[1, 0] * table.loc[0, 1]))\n",
    "        return float(sign * np.sqrt(chi2 / len(x)))\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "# --- Deterministic metric-type mapping ---\n",
    "METRIC_TYPES = {\n",
    "    # Binary accuracy/agreement\n",
    "    **{f\"acc_A_@{k}\": \"binary\" for k in [1, 5, 10]},\n",
    "    **{f\"acc_B_@{k}\": \"binary\" for k in [1, 5, 10]},\n",
    "    \"disagree_correct\": \"binary\",\n",
    "    \"agree_correct\": \"binary\",\n",
    "    \"agree_wrong\": \"binary\",\n",
    "    \"agree_set\": \"binary\",\n",
    "    \"disagree_set\": \"binary\",\n",
    "\n",
    "    # Jaccard: only @1 is expected to be binary\n",
    "    \"jaccard_@1\": \"binary\",\n",
    "    \"jaccard_@5\": \"continuous\",\n",
    "    \"jaccard_@10\": \"continuous\",\n",
    "\n",
    "    # Rest treated as continuous by default\n",
    "}\n",
    "\n",
    "\n",
    "def _choose_corr_func_fixed(anchor, metric):\n",
    "    \"\"\"Deterministic correlation type based on known data nature.\"\"\"\n",
    "    anchor_t = \"binary\" if \"disagree_correct\" in anchor else \"continuous\"\n",
    "    metric_t = METRIC_TYPES.get(metric, \"continuous\")\n",
    "\n",
    "    if anchor_t == \"binary\" and metric_t == \"binary\":\n",
    "        return \"phi\", _phi_coefficient\n",
    "    elif anchor_t == \"binary\" or metric_t == \"binary\":\n",
    "        return \"pointbiserial\", pointbiserialr\n",
    "    else:\n",
    "        return \"spearman\", spearmanr\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Correlation (per-prompt)\n",
    "# ============================================================\n",
    "def correlate_layers_by_anchor_perprompt(\n",
    "    df,\n",
    "    anchor,\n",
    "    metrics,\n",
    "    modes=(\"raw\", \"unit_rms\", \"norm_rms\"),\n",
    "    topk_levels=(1, 5, 10),\n",
    "    n_boot=10,\n",
    "    n_perm=10,\n",
    "    seed=42,\n",
    "    output_dir=None,\n",
    "    model=\"m_8bit\",\n",
    "    min_valid=3,\n",
    "):\n",
    "    np.random.seed(seed)\n",
    "    results = []\n",
    "    df_out = df[df[\"layer_name\"].str.lower() == \"output\"]\n",
    "\n",
    "    # --- Build anchor map from output layer ---\n",
    "    anchor_map = {}\n",
    "    for _, row in df_out.iterrows():\n",
    "        key = (int(row[\"prompt_id\"]), int(row.get(\"batch_index\", 0)))\n",
    "        anchor_vecs = {}\n",
    "        for mode in modes:\n",
    "            col1 = f\"{anchor}_{mode}_@1\"\n",
    "            col2 = f\"{anchor}_{mode}\"\n",
    "            col = col1 if col1 in df.columns else col2\n",
    "            val = row.get(col)\n",
    "            if isinstance(val, (list, np.ndarray)) and len(val) > 0:\n",
    "                anchor_vecs[mode] = np.array(val, float)\n",
    "        if anchor_vecs:\n",
    "            anchor_map[key] = anchor_vecs\n",
    "    print(f\"[anchor_map] built {len(anchor_map)} anchors\")\n",
    "\n",
    "    skip_const = 0\n",
    "    SHARED_METRICS = {\"cosine_sim\", \"l2_dist\"}\n",
    "\n",
    "    # --- Main correlation loop ---\n",
    "    for mode in modes:\n",
    "        for (lname, lidx), layer_df in tqdm(\n",
    "            df.groupby([\"layer_name\", \"layer_index\"]),\n",
    "            desc=f\"{anchor}_{mode}\"\n",
    "        ):\n",
    "            for metric in metrics:\n",
    "                is_topk_only = metric in {\"acc_A\", \"acc_B\", \"jaccard\"}\n",
    "                suffixes = [f\"_@{k}\" for k in topk_levels] if is_topk_only else [\"\"] + [f\"_@{k}\" for k in topk_levels]\n",
    "\n",
    "                for suffix in suffixes:\n",
    "                    src_mode = \"raw\" if metric in SHARED_METRICS else mode\n",
    "                    mcol = f\"{metric}_{src_mode}{suffix}\"\n",
    "                    if mcol not in layer_df.columns:\n",
    "                        continue\n",
    "\n",
    "                    per_prompt_rhos, per_prompt_ns = [], []\n",
    "\n",
    "                    for (pid, bid), group in layer_df.groupby([\"prompt_id\", \"batch_index\"]):\n",
    "                        key = (int(pid), int(bid))\n",
    "                        if key not in anchor_map or mode not in anchor_map[key]:\n",
    "                            continue\n",
    "\n",
    "                        a = anchor_map[key][mode]\n",
    "                        m = safe_flatten(group[mcol].iloc[0])\n",
    "                        n = min(len(a), len(m))\n",
    "                        if n < min_valid:\n",
    "                            continue\n",
    "\n",
    "                        a, m = a[:n], m[:n]\n",
    "                        mask = np.isfinite(a) & np.isfinite(m)\n",
    "                        n_used = int(mask.sum())\n",
    "                        if n_used < min_valid:\n",
    "                            continue\n",
    "\n",
    "                        if np.std(a[mask]) == 0 or np.std(m[mask]) == 0:\n",
    "                            skip_const += 1\n",
    "                            continue\n",
    "\n",
    "                        cname, corr_func = _choose_corr_func_fixed(anchor, f\"{metric}{suffix}\")\n",
    "\n",
    "                        try:\n",
    "                            if cname == \"phi\":\n",
    "                                rho = corr_func(a[mask], m[mask])\n",
    "                            else:\n",
    "                                rho, _ = corr_func(a[mask], m[mask])\n",
    "                        except Exception:\n",
    "                            rho = np.nan\n",
    "\n",
    "                        if np.isfinite(rho):\n",
    "                            per_prompt_rhos.append(rho)\n",
    "                            per_prompt_ns.append(n_used)\n",
    "\n",
    "                    # --- Handle missing prompts ---\n",
    "                    if not per_prompt_rhos:\n",
    "                        results.append({\n",
    "                            \"mode\": mode,\n",
    "                            \"anchor\": anchor,\n",
    "                            \"metric\": metric + suffix,\n",
    "                            \"corr_type\": \"undefined\",\n",
    "                            \"layer_name\": lname,\n",
    "                            \"layer_index\": lidx,\n",
    "                            \"rho\": np.nan,\n",
    "                            \"rho_boot_median\": np.nan,\n",
    "                            \"ci_low\": np.nan,\n",
    "                            \"ci_high\": np.nan,\n",
    "                            \"p_perm\": np.nan,\n",
    "                            \"n_prompts\": 0,\n",
    "                            \"n_used_mean\": np.nan,\n",
    "                            \"n_used_median\": np.nan,\n",
    "                            \"pooling\": \"per_prompt\"\n",
    "                        })\n",
    "                        continue\n",
    "\n",
    "                    # --- Aggregate correlations across prompts ---\n",
    "                    A = np.array(per_prompt_rhos)\n",
    "                    N = np.array(per_prompt_ns)\n",
    "                    rho = np.average(A, weights=N) if len(N) > 0 else np.nan\n",
    "                    \n",
    "                    \"\"\"z = np.arctanh(A)            # Fisher transform\n",
    "                    rho = np.tanh(np.average(z, weights=N))\"\"\"\n",
    "\n",
    "                    n_mean, n_median = np.nanmean(N), np.nanmedian(N)\n",
    "\n",
    "                    # --- Bootstrap CI ---\n",
    "                    if len(A) >= min_valid:\n",
    "                        boot_rhos = []\n",
    "                        for _ in range(n_boot):\n",
    "                            idx = np.random.choice(len(A), len(A), replace=True)\n",
    "                            boot_rhos.append(np.average(A[idx], weights=N[idx]))\n",
    "                        if len(boot_rhos) > 20:\n",
    "                            ci_low, ci_high = np.percentile(boot_rhos, [2.5, 97.5])\n",
    "                            rho_boot = np.median(boot_rhos)\n",
    "                        else:\n",
    "                            ci_low = ci_high = rho_boot = np.nan\n",
    "                    else:\n",
    "                        ci_low = ci_high = rho_boot = np.nan\n",
    "\n",
    "                    # --- Permutation test ---\n",
    "                    if len(A) >= min_valid:\n",
    "                        perm_rhos = []\n",
    "                        for _ in range(n_perm):\n",
    "                            perm_rhos.append(np.average(np.random.permutation(A), weights=N))\n",
    "                        if len(perm_rhos) > 20:\n",
    "                            perm_rhos = np.array(perm_rhos)\n",
    "                            p_perm = (np.sum(np.abs(perm_rhos) >= abs(rho)) + 1) / (len(perm_rhos) + 1)\n",
    "                        else:\n",
    "                            p_perm = np.nan\n",
    "                    else:\n",
    "                        p_perm = np.nan\n",
    "\n",
    "                    # --- Save results ---\n",
    "                    results.append({\n",
    "                        \"mode\": mode,\n",
    "                        \"anchor\": anchor,\n",
    "                        \"metric\": metric + suffix,\n",
    "                        \"corr_type\": cname,\n",
    "                        \"layer_name\": lname,\n",
    "                        \"layer_index\": lidx,\n",
    "                        \"rho\": rho,\n",
    "                        \"rho_boot_median\": rho_boot,\n",
    "                        \"ci_low\": ci_low,\n",
    "                        \"ci_high\": ci_high,\n",
    "                        \"p_perm\": p_perm,\n",
    "                        \"n_prompts\": len(A),\n",
    "                        \"n_used_mean\": n_mean,\n",
    "                        \"n_used_median\": n_median,\n",
    "                        \"pooling\": \"per_prompt\"\n",
    "                    })\n",
    "\n",
    "    # --- Final output ---\n",
    "    df_corr = pd.DataFrame(results)\n",
    "    print(f\"[ok] {anchor} → {len(df_corr)} per-prompt correlations\")\n",
    "    print(f\"[NaN correlations: {df_corr['rho'].isna().sum()}]\")\n",
    "    print(f\"[skipped constant={skip_const}]\")\n",
    "\n",
    "    if output_dir:\n",
    "        out_path = Path(output_dir) / f\"lw_{model}_{anchor}_corr_perprompt.csv\"\n",
    "        df_corr.to_csv(out_path, index=False)\n",
    "        print(f\"[saved per-prompt correlations] {out_path}\")\n",
    "\n",
    "    return df_corr\n",
    "\n",
    "# ============================================================\n",
    "# summarize_correlations_perprompt (fix for single-row groups)\n",
    "# ============================================================\n",
    "def summarize_correlations_perprompt(df_corr, output_dir, model, ci_mode=\"both\"):\n",
    "    df = df_corr.dropna(subset=[\"rho\"]).copy()\n",
    "    if \"n\" not in df.columns:\n",
    "        df[\"n\"] = 1\n",
    "    df[\"z\"] = np.arctanh(np.clip(df[\"rho\"], -0.999999, 0.999999))\n",
    "\n",
    "    drop_cols = [c for c in [\"prompt_id\", \"batch_index\"] if c in df.columns]\n",
    "    if drop_cols:\n",
    "        df = df.drop(columns=drop_cols)\n",
    "\n",
    "    group_cols = [\"mode\", \"anchor\", \"metric\", \"corr_type\", \"layer_name\", \"layer_index\"]\n",
    "\n",
    "    def _weighted_stats(g):\n",
    "        out = {}\n",
    "        if len(g) < 2:\n",
    "            out[\"rho_mean\"] = g[\"rho\"].iloc[0]\n",
    "            out[\"rho_low\"] = out[\"rho_high\"] = g[\"rho\"].iloc[0]\n",
    "            out[\"rho_boot_mean\"] = g[\"rho_boot_median\"].iloc[0]\n",
    "            out[\"ci_low_emp\"] = out[\"ci_high_emp\"] = np.nan\n",
    "            out[\"n_total\"] = g[\"n\"].sum()\n",
    "            for k in group_cols:\n",
    "                out[k] = g[k].iloc[0]\n",
    "            return pd.DataFrame([out])\n",
    "\n",
    "        w = g[\"n\"]\n",
    "        z = np.arctanh(np.clip(g[\"rho\"], -0.999999, 0.999999))\n",
    "        z_mean = np.average(z, weights=w)\n",
    "        z_std = np.sqrt(np.average((z - z_mean)**2, weights=w))\n",
    "        out[\"rho_mean\"] = np.tanh(z_mean)\n",
    "        out[\"rho_low\"] = np.tanh(z_mean - 1.96 * z_std)\n",
    "        out[\"rho_high\"] = np.tanh(z_mean + 1.96 * z_std)\n",
    "        out[\"n_total\"] = g[\"n\"].sum()\n",
    "\n",
    "        out[\"rho_boot_mean\"] = np.average(g[\"rho_boot_median\"], weights=w)\n",
    "        out[\"ci_low_emp\"] = np.average(g[\"ci_low\"], weights=w)\n",
    "        out[\"ci_high_emp\"] = np.average(g[\"ci_high\"], weights=w)\n",
    "\n",
    "        for k in group_cols:\n",
    "            out[k] = g[k].iloc[0]\n",
    "        return pd.DataFrame([out])\n",
    "\n",
    "    df_summary = pd.concat(\n",
    "        [_weighted_stats(g) for _, g in df.groupby(group_cols, group_keys=False)],\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "    if ci_mode in (\"empirical\", \"both\"):\n",
    "        df_summary[\"rho_low_plot\"] = df_summary[\"ci_low_emp\"]\n",
    "        df_summary[\"rho_high_plot\"] = df_summary[\"ci_high_emp\"]\n",
    "    else:\n",
    "        df_summary[\"rho_low_plot\"] = df_summary[\"rho_low\"]\n",
    "        df_summary[\"rho_high_plot\"] = df_summary[\"rho_high\"]\n",
    "\n",
    "    out_summary = Path(output_dir) / f\"lw_{model}_corr_perprompt_summary_{ci_mode}.csv\"\n",
    "    df_summary.to_csv(out_summary, index=False)\n",
    "    print(f\"[saved summary] {out_summary}\")\n",
    "    print(f\"[diag] rows={len(df_summary)}  groups={df[group_cols].drop_duplicates().shape[0]}\")\n",
    "    return df_summary\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Run per-prompt correlation pipeline\n",
    "# ============================================================\n",
    "BASE = Path(\"saved_data\")\n",
    "model = \"m_quant\"\n",
    "output_dir = BASE / \"summary\" / model\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "topk_dir = BASE / \"topk\" / model\n",
    "df_topk = merge_parquet_files(topk_dir)\n",
    "df_topk = expand_topk_metrics(\n",
    "    df_topk,\n",
    "    metrics=[\"jaccard\", \"acc_A\", \"acc_B\", \"disagree_correct\"],\n",
    "    modes=(\"raw\", \"unit_rms\", \"norm_rms\")\n",
    ")\n",
    "df_topk = preprocess_anchors(df_topk)\n",
    "\n",
    "for m in [\"cosine_sim\", \"l2_dist\"]:\n",
    "    if f\"{m}_raw\" in df_topk.columns:\n",
    "        for mode in [\"unit_rms\", \"norm_rms\"]:\n",
    "            col_src = f\"{m}_raw\"\n",
    "            col_dst = f\"{m}_{mode}\"\n",
    "            if col_dst not in df_topk.columns:\n",
    "                df_topk[col_dst] = df_topk[col_src]\n",
    "                print(f\"[copy] propagated {col_src} → {col_dst}\")\n",
    "\n",
    "anchors = [\"disagree_correct\", \"logp_diff\"]\n",
    "metrics = [\n",
    "    \"kl_ab\", \"kl_ba\", \"js_div\", \"js_dist\", \"tvd\",\n",
    "    \"entropy_A\", \"entropy_B\", \"cosine_sim\", \"l2_dist\",\n",
    "    \"ppl_diff\", \"jaccard\", \"acc_A\", \"acc_B\"\n",
    "]\n",
    "\n",
    "df_corr_perprompt_all = []\n",
    "for a in anchors:\n",
    "    df_corr_perprompt_all.append(\n",
    "        correlate_layers_by_anchor_perprompt(df_topk, a, metrics, model=model)\n",
    "    )\n",
    "df_corr_perprompt_all = pd.concat(df_corr_perprompt_all, ignore_index=True)\n",
    "\n",
    "perprompt_corr_path = output_dir / f\"lw_{model}_corr_perprompt.csv\"\n",
    "perprompt_summary_path = output_dir / f\"lw_{model}_corr_perprompt_summary.csv\"\n",
    "\n",
    "df_corr_perprompt_all.to_csv(perprompt_corr_path, index=False)\n",
    "print(f\"[saved per-prompt correlations] {perprompt_corr_path}\")\n",
    "\n",
    "df_summary_pp = summarize_correlations_perprompt(df_corr_perprompt_all, output_dir=output_dir, model=model)\n",
    "print(f\"[saved per-prompt summary] {perprompt_summary_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ce7dcdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mode\n",
       "norm_rms   -0.034492\n",
       "raw        -0.034492\n",
       "unit_rms   -0.034492\n",
       "Name: rho, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corr_perprompt_all.query(\"metric.str.contains('cosine_sim')\").groupby(\"mode\")[\"rho\"].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e19e8453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mode</th>\n",
       "      <th>anchor</th>\n",
       "      <th>metric</th>\n",
       "      <th>corr_type</th>\n",
       "      <th>layer_name</th>\n",
       "      <th>layer_index</th>\n",
       "      <th>rho</th>\n",
       "      <th>rho_boot_median</th>\n",
       "      <th>ci_low</th>\n",
       "      <th>ci_high</th>\n",
       "      <th>p_perm</th>\n",
       "      <th>n_prompts</th>\n",
       "      <th>n_used_mean</th>\n",
       "      <th>n_used_median</th>\n",
       "      <th>pooling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>raw</td>\n",
       "      <td>disagree_correct</td>\n",
       "      <td>kl_ab</td>\n",
       "      <td>pointbiserial</td>\n",
       "      <td>embed_tokens</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.046042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77</td>\n",
       "      <td>10.935065</td>\n",
       "      <td>10.0</td>\n",
       "      <td>per_prompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>raw</td>\n",
       "      <td>disagree_correct</td>\n",
       "      <td>kl_ba</td>\n",
       "      <td>pointbiserial</td>\n",
       "      <td>embed_tokens</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.051954</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77</td>\n",
       "      <td>10.935065</td>\n",
       "      <td>10.0</td>\n",
       "      <td>per_prompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>raw</td>\n",
       "      <td>disagree_correct</td>\n",
       "      <td>js_div</td>\n",
       "      <td>pointbiserial</td>\n",
       "      <td>embed_tokens</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.018521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77</td>\n",
       "      <td>10.935065</td>\n",
       "      <td>10.0</td>\n",
       "      <td>per_prompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>raw</td>\n",
       "      <td>disagree_correct</td>\n",
       "      <td>js_dist</td>\n",
       "      <td>pointbiserial</td>\n",
       "      <td>embed_tokens</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.014579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77</td>\n",
       "      <td>10.935065</td>\n",
       "      <td>10.0</td>\n",
       "      <td>per_prompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>raw</td>\n",
       "      <td>disagree_correct</td>\n",
       "      <td>tvd</td>\n",
       "      <td>pointbiserial</td>\n",
       "      <td>embed_tokens</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.014360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77</td>\n",
       "      <td>10.935065</td>\n",
       "      <td>10.0</td>\n",
       "      <td>per_prompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3871</th>\n",
       "      <td>norm_rms</td>\n",
       "      <td>logp_diff</td>\n",
       "      <td>acc_A_@5</td>\n",
       "      <td>pointbiserial</td>\n",
       "      <td>output</td>\n",
       "      <td>32</td>\n",
       "      <td>0.192738</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500</td>\n",
       "      <td>10.088000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>per_prompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3872</th>\n",
       "      <td>norm_rms</td>\n",
       "      <td>logp_diff</td>\n",
       "      <td>acc_A_@10</td>\n",
       "      <td>pointbiserial</td>\n",
       "      <td>output</td>\n",
       "      <td>32</td>\n",
       "      <td>0.215255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500</td>\n",
       "      <td>10.088000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>per_prompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3873</th>\n",
       "      <td>norm_rms</td>\n",
       "      <td>logp_diff</td>\n",
       "      <td>acc_B_@1</td>\n",
       "      <td>pointbiserial</td>\n",
       "      <td>output</td>\n",
       "      <td>32</td>\n",
       "      <td>0.092933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>494</td>\n",
       "      <td>10.107287</td>\n",
       "      <td>10.0</td>\n",
       "      <td>per_prompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>norm_rms</td>\n",
       "      <td>logp_diff</td>\n",
       "      <td>acc_B_@5</td>\n",
       "      <td>pointbiserial</td>\n",
       "      <td>output</td>\n",
       "      <td>32</td>\n",
       "      <td>0.161631</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500</td>\n",
       "      <td>10.088000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>per_prompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3875</th>\n",
       "      <td>norm_rms</td>\n",
       "      <td>logp_diff</td>\n",
       "      <td>acc_B_@10</td>\n",
       "      <td>pointbiserial</td>\n",
       "      <td>output</td>\n",
       "      <td>32</td>\n",
       "      <td>0.190724</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500</td>\n",
       "      <td>10.088000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>per_prompt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3876 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          mode            anchor     metric      corr_type    layer_name  \\\n",
       "0          raw  disagree_correct      kl_ab  pointbiserial  embed_tokens   \n",
       "1          raw  disagree_correct      kl_ba  pointbiserial  embed_tokens   \n",
       "2          raw  disagree_correct     js_div  pointbiserial  embed_tokens   \n",
       "3          raw  disagree_correct    js_dist  pointbiserial  embed_tokens   \n",
       "4          raw  disagree_correct        tvd  pointbiserial  embed_tokens   \n",
       "...        ...               ...        ...            ...           ...   \n",
       "3871  norm_rms         logp_diff   acc_A_@5  pointbiserial        output   \n",
       "3872  norm_rms         logp_diff  acc_A_@10  pointbiserial        output   \n",
       "3873  norm_rms         logp_diff   acc_B_@1  pointbiserial        output   \n",
       "3874  norm_rms         logp_diff   acc_B_@5  pointbiserial        output   \n",
       "3875  norm_rms         logp_diff  acc_B_@10  pointbiserial        output   \n",
       "\n",
       "      layer_index       rho  rho_boot_median  ci_low  ci_high  p_perm  \\\n",
       "0              -1  0.046042              NaN     NaN      NaN     NaN   \n",
       "1              -1 -0.051954              NaN     NaN      NaN     NaN   \n",
       "2              -1  0.018521              NaN     NaN      NaN     NaN   \n",
       "3              -1  0.014579              NaN     NaN      NaN     NaN   \n",
       "4              -1 -0.014360              NaN     NaN      NaN     NaN   \n",
       "...           ...       ...              ...     ...      ...     ...   \n",
       "3871           32  0.192738              NaN     NaN      NaN     NaN   \n",
       "3872           32  0.215255              NaN     NaN      NaN     NaN   \n",
       "3873           32  0.092933              NaN     NaN      NaN     NaN   \n",
       "3874           32  0.161631              NaN     NaN      NaN     NaN   \n",
       "3875           32  0.190724              NaN     NaN      NaN     NaN   \n",
       "\n",
       "      n_prompts  n_used_mean  n_used_median     pooling  \n",
       "0            77    10.935065           10.0  per_prompt  \n",
       "1            77    10.935065           10.0  per_prompt  \n",
       "2            77    10.935065           10.0  per_prompt  \n",
       "3            77    10.935065           10.0  per_prompt  \n",
       "4            77    10.935065           10.0  per_prompt  \n",
       "...         ...          ...            ...         ...  \n",
       "3871        500    10.088000           10.0  per_prompt  \n",
       "3872        500    10.088000           10.0  per_prompt  \n",
       "3873        494    10.107287           10.0  per_prompt  \n",
       "3874        500    10.088000           10.0  per_prompt  \n",
       "3875        500    10.088000           10.0  per_prompt  \n",
       "\n",
       "[3876 rows x 15 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corr_perprompt_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12453629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rho_mean</th>\n",
       "      <th>rho_low</th>\n",
       "      <th>rho_high</th>\n",
       "      <th>rho_boot_mean</th>\n",
       "      <th>ci_low_emp</th>\n",
       "      <th>ci_high_emp</th>\n",
       "      <th>n_total</th>\n",
       "      <th>mode</th>\n",
       "      <th>anchor</th>\n",
       "      <th>metric</th>\n",
       "      <th>corr_type</th>\n",
       "      <th>layer_name</th>\n",
       "      <th>layer_index</th>\n",
       "      <th>rho_low_plot</th>\n",
       "      <th>rho_high_plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.071429</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>norm_rms</td>\n",
       "      <td>disagree_correct</td>\n",
       "      <td>acc_A_@1</td>\n",
       "      <td>phi</td>\n",
       "      <td>layer.11</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.076923</td>\n",
       "      <td>-0.076923</td>\n",
       "      <td>-0.076923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>norm_rms</td>\n",
       "      <td>disagree_correct</td>\n",
       "      <td>acc_A_@1</td>\n",
       "      <td>phi</td>\n",
       "      <td>layer.12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.071429</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>norm_rms</td>\n",
       "      <td>disagree_correct</td>\n",
       "      <td>acc_A_@1</td>\n",
       "      <td>phi</td>\n",
       "      <td>layer.13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.071429</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>norm_rms</td>\n",
       "      <td>disagree_correct</td>\n",
       "      <td>acc_A_@1</td>\n",
       "      <td>phi</td>\n",
       "      <td>layer.14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.096822</td>\n",
       "      <td>-0.096822</td>\n",
       "      <td>-0.096822</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>norm_rms</td>\n",
       "      <td>disagree_correct</td>\n",
       "      <td>acc_A_@1</td>\n",
       "      <td>phi</td>\n",
       "      <td>layer.15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3525</th>\n",
       "      <td>0.006513</td>\n",
       "      <td>0.006513</td>\n",
       "      <td>0.006513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>unit_rms</td>\n",
       "      <td>logp_diff</td>\n",
       "      <td>tvd</td>\n",
       "      <td>spearman</td>\n",
       "      <td>layer.6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3526</th>\n",
       "      <td>0.026021</td>\n",
       "      <td>0.026021</td>\n",
       "      <td>0.026021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>unit_rms</td>\n",
       "      <td>logp_diff</td>\n",
       "      <td>tvd</td>\n",
       "      <td>spearman</td>\n",
       "      <td>layer.7</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3527</th>\n",
       "      <td>0.031489</td>\n",
       "      <td>0.031489</td>\n",
       "      <td>0.031489</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>unit_rms</td>\n",
       "      <td>logp_diff</td>\n",
       "      <td>tvd</td>\n",
       "      <td>spearman</td>\n",
       "      <td>layer.8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3528</th>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>unit_rms</td>\n",
       "      <td>logp_diff</td>\n",
       "      <td>tvd</td>\n",
       "      <td>spearman</td>\n",
       "      <td>layer.9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3529</th>\n",
       "      <td>0.018948</td>\n",
       "      <td>0.018948</td>\n",
       "      <td>0.018948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>unit_rms</td>\n",
       "      <td>logp_diff</td>\n",
       "      <td>tvd</td>\n",
       "      <td>spearman</td>\n",
       "      <td>output</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3530 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rho_mean   rho_low  rho_high  rho_boot_mean  ci_low_emp  ci_high_emp  \\\n",
       "0    -0.071429 -0.071429 -0.071429            NaN         NaN          NaN   \n",
       "1    -0.076923 -0.076923 -0.076923            NaN         NaN          NaN   \n",
       "2    -0.071429 -0.071429 -0.071429            NaN         NaN          NaN   \n",
       "3    -0.071429 -0.071429 -0.071429            NaN         NaN          NaN   \n",
       "4    -0.096822 -0.096822 -0.096822            NaN         NaN          NaN   \n",
       "...        ...       ...       ...            ...         ...          ...   \n",
       "3525  0.006513  0.006513  0.006513            NaN         NaN          NaN   \n",
       "3526  0.026021  0.026021  0.026021            NaN         NaN          NaN   \n",
       "3527  0.031489  0.031489  0.031489            NaN         NaN          NaN   \n",
       "3528  0.043021  0.043021  0.043021            NaN         NaN          NaN   \n",
       "3529  0.018948  0.018948  0.018948            NaN         NaN          NaN   \n",
       "\n",
       "      n_total      mode            anchor    metric corr_type layer_name  \\\n",
       "0           1  norm_rms  disagree_correct  acc_A_@1       phi   layer.11   \n",
       "1           1  norm_rms  disagree_correct  acc_A_@1       phi   layer.12   \n",
       "2           1  norm_rms  disagree_correct  acc_A_@1       phi   layer.13   \n",
       "3           1  norm_rms  disagree_correct  acc_A_@1       phi   layer.14   \n",
       "4           1  norm_rms  disagree_correct  acc_A_@1       phi   layer.15   \n",
       "...       ...       ...               ...       ...       ...        ...   \n",
       "3525        1  unit_rms         logp_diff       tvd  spearman    layer.6   \n",
       "3526        1  unit_rms         logp_diff       tvd  spearman    layer.7   \n",
       "3527        1  unit_rms         logp_diff       tvd  spearman    layer.8   \n",
       "3528        1  unit_rms         logp_diff       tvd  spearman    layer.9   \n",
       "3529        1  unit_rms         logp_diff       tvd  spearman     output   \n",
       "\n",
       "      layer_index  rho_low_plot  rho_high_plot  \n",
       "0              11           NaN            NaN  \n",
       "1              12           NaN            NaN  \n",
       "2              13           NaN            NaN  \n",
       "3              14           NaN            NaN  \n",
       "4              15           NaN            NaN  \n",
       "...           ...           ...            ...  \n",
       "3525            6           NaN            NaN  \n",
       "3526            7           NaN            NaN  \n",
       "3527            8           NaN            NaN  \n",
       "3528            9           NaN            NaN  \n",
       "3529           32           NaN            NaN  \n",
       "\n",
       "[3530 rows x 15 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary_pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b98e5f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mode                  0\n",
       "anchor                0\n",
       "metric                0\n",
       "corr_type             0\n",
       "layer_name            0\n",
       "layer_index           0\n",
       "rho                 346\n",
       "rho_boot_median    3876\n",
       "ci_low             3876\n",
       "ci_high            3876\n",
       "p_perm             3876\n",
       "n_prompts             0\n",
       "n_used_mean         346\n",
       "n_used_median       346\n",
       "pooling               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corr_perprompt_all.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "176ae5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rho_mean            0\n",
       "rho_low             0\n",
       "rho_high            0\n",
       "rho_boot_mean    3530\n",
       "ci_low_emp       3530\n",
       "ci_high_emp      3530\n",
       "n_total             0\n",
       "mode                0\n",
       "anchor              0\n",
       "metric              0\n",
       "corr_type           0\n",
       "layer_name          0\n",
       "layer_index         0\n",
       "rho_low_plot     3530\n",
       "rho_high_plot    3530\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary_pp.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e38a5a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6214142087001617e-18\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv(\"saved_data/summary/m_8bit/lw_m_8bit_corr_perprompt.csv\")\n",
    "df_sum = pd.read_csv(\"saved_data/summary/m_8bit/lw_m_8bit_corr_perprompt_summary_both.csv\")\n",
    "\n",
    "merged = df_sum.merge(df_raw, on=[\"mode\",\"anchor\",\"metric\",\"corr_type\",\"layer_index\"], suffixes=(\"_sum\",\"_raw\"))\n",
    "merged[\"diff\"] = merged[\"rho_mean\"] - merged[\"rho\"]\n",
    "\n",
    "print(merged[\"diff\"].abs().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bae48d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3645738272361821e-18\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv(\"saved_data/summary/m_8bit/lw_m_8bit_corr_pooled.csv\")\n",
    "df_sum = pd.read_csv(\"saved_data/summary/m_8bit/lw_m_8bit_corr_pooled_summary_both.csv\")\n",
    "\n",
    "merged = df_sum.merge(df_raw, on=[\"mode\",\"anchor\",\"metric\",\"corr_type\",\"layer_index\"], suffixes=(\"_sum\",\"_raw\"))\n",
    "merged[\"diff\"] = merged[\"rho_mean\"] - merged[\"rho\"]\n",
    "\n",
    "print(merged[\"diff\"].abs().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c32d6913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] merged 7512 rows from 1 models.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path(\"saved_data/summary\")\n",
    "MODELS = [\"m_4bit\", \"m_8bit\", \"m_quant\"]\n",
    "\n",
    "dfs = []\n",
    "for model in MODELS:\n",
    "    model_dir = BASE_DIR / model\n",
    "    if not model_dir.exists():\n",
    "        continue\n",
    "    for f in model_dir.glob(\"*_summary*.csv\"): \n",
    "        d = pd.read_csv(f)\n",
    "        d[\"model\"] = model\n",
    "        if \"pooled\" in f.stem:\n",
    "            d[\"pooling\"] = \"pooled\"\n",
    "        elif \"perprompt\" in f.stem or \"per_prompt\" in f.stem:\n",
    "            d[\"pooling\"] = \"per_prompt\"\n",
    "        else:\n",
    "            d[\"pooling\"] = \"unknown\"\n",
    "        dfs.append(d)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "print(f\"[ok] merged {len(df)} rows from {df['model'].nunique()} models.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4525b2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique layers per model:\n",
      "m_quant: [np.int64(-1), np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8)]... (34 layers total)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nUnique layers per model:\")\n",
    "for model in df[\"model\"].unique():\n",
    "    layers = sorted(df[df[\"model\"] == model][\"layer_index\"].unique())\n",
    "    print(f\"{model}: {layers[:10]}... ({len(layers)} layers total)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d131d6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_4bit: 0/9213 rows have NaN rho_mean (0.0%)\n",
      "m_8bit: 0/9242 rows have NaN rho_mean (0.0%)\n",
      "m_quant: 0/9468 rows have NaN rho_mean (0.0%)\n"
     ]
    }
   ],
   "source": [
    "for model in [\"m_4bit\", \"m_8bit\", \"m_quant\"]:\n",
    "    dsub = df[df[\"model\"] == model]\n",
    "    missing = dsub[\"rho_mean\"].isna().sum()\n",
    "    total = len(dsub)\n",
    "    print(f\"{model}: {missing}/{total} rows have NaN rho_mean ({missing/total:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d394b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[PER-PROMPT] Rows per model:\n",
      "model\n",
      "m_quant    3570\n",
      "m_8bit     3368\n",
      "m_4bit     3333\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique layers per model (per-prompt only):\n",
      "m_4bit: [np.int64(-1), np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8)]... (34 total layers)\n",
      "m_8bit: [np.int64(-1), np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8)]... (34 total layers)\n",
      "m_quant: [np.int64(-1), np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8)]... (34 total layers)\n"
     ]
    }
   ],
   "source": [
    "df_per = df[df[\"pooling\"] == \"per_prompt\"]\n",
    "\n",
    "print(\"\\n[PER-PROMPT] Rows per model:\")\n",
    "print(df_per[\"model\"].value_counts())\n",
    "\n",
    "print(\"\\nUnique layers per model (per-prompt only):\")\n",
    "for model in df_per[\"model\"].unique():\n",
    "    layers = sorted(df_per[df_per[\"model\"] == model][\"layer_index\"].unique())\n",
    "    print(f\"{model}: {layers[:10]}... ({len(layers)} total layers)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b53fb4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "m_4bit — mean rho_mean for early layers:\n",
      "layer_index\n",
      "-1    0.0257\n",
      " 0    0.0129\n",
      " 1    0.0053\n",
      " 2    0.0115\n",
      " 3   -0.0112\n",
      "Name: rho_mean, dtype: float64\n",
      "\n",
      "m_8bit — mean rho_mean for early layers:\n",
      "layer_index\n",
      "-1    0.0154\n",
      " 0    0.0031\n",
      " 1   -0.0032\n",
      " 2    0.0064\n",
      " 3   -0.0030\n",
      "Name: rho_mean, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for model in [\"m_4bit\", \"m_8bit\"]:\n",
    "    dsub = df_per[df_per[\"model\"] == model]\n",
    "    low_layers = dsub[dsub[\"layer_index\"] < 4] \n",
    "    print(f\"\\n{model} — mean rho_mean for early layers:\")\n",
    "    print(low_layers.groupby(\"layer_index\")[\"rho_mean\"].mean().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c24a9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== POOLED ===\n",
      "Alle mulige lag: [np.int64(-1), np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8)]... (34 total)\n",
      "m_4bit: 34 lag fundet, mangler 0 → ingen mangler\n",
      "m_8bit: 34 lag fundet, mangler 0 → ingen mangler\n",
      "m_quant: 34 lag fundet, mangler 0 → ingen mangler\n",
      "\n",
      "=== PER_PROMPT ===\n",
      "Alle mulige lag: [np.int64(-1), np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8)]... (34 total)\n",
      "m_4bit: 34 lag fundet, mangler 0 → ingen mangler\n",
      "m_8bit: 34 lag fundet, mangler 0 → ingen mangler\n",
      "m_quant: 34 lag fundet, mangler 0 → ingen mangler\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path(\"saved_data/summary\")\n",
    "MODELS = [\"m_4bit\", \"m_8bit\", \"m_quant\"]\n",
    "\n",
    "dfs = []\n",
    "for model in MODELS:\n",
    "    for f in (BASE_DIR / model).glob(\"*_summary*.csv\"):\n",
    "        d = pd.read_csv(f)\n",
    "        d[\"model\"] = model\n",
    "        if \"pooled\" in f.stem:\n",
    "            d[\"pooling\"] = \"pooled\"\n",
    "        elif \"perprompt\" in f.stem or \"per_prompt\" in f.stem:\n",
    "            d[\"pooling\"] = \"per_prompt\"\n",
    "        else:\n",
    "            d[\"pooling\"] = \"unknown\"\n",
    "        dfs.append(d)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "for pooling in [\"pooled\", \"per_prompt\"]:\n",
    "    print(f\"\\n=== {pooling.upper()} ===\")\n",
    "    d = df[df[\"pooling\"] == pooling]\n",
    "    all_layers = sorted(df[\"layer_index\"].unique())\n",
    "    print(f\"Alle mulige lag: {all_layers[:10]}... ({len(all_layers)} total)\")\n",
    "    for model in MODELS:\n",
    "        layers = sorted(d[d[\"model\"] == model][\"layer_index\"].unique())\n",
    "        missing = sorted(set(all_layers) - set(layers))\n",
    "        print(f\"{model}: {len(layers)} lag fundet, mangler {len(missing)} → {missing[:10] if missing else 'ingen mangler'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab210d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lag til stede: [np.int64(-1), np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(10), np.int64(11), np.int64(12), np.int64(13), np.int64(14), np.int64(15), np.int64(16), np.int64(17), np.int64(18), np.int64(19), np.int64(20), np.int64(21), np.int64(22), np.int64(23), np.int64(24), np.int64(25), np.int64(26), np.int64(27), np.int64(28), np.int64(29), np.int64(30), np.int64(31), np.int64(32)]\n",
      "Antal lag: 34\n"
     ]
    }
   ],
   "source": [
    "subset = df[\n",
    "    (df[\"model\"] == \"m_8bit\") &\n",
    "    (df[\"pooling\"] == \"per_prompt\") &\n",
    "    (df[\"anchor\"] == \"logp_diff\") &\n",
    "    (df[\"metric\"] == \"kl_ab\") &\n",
    "    (df[\"corr_type\"] == \"spearman\")\n",
    "]\n",
    "\n",
    "print(\"Lag til stede:\", sorted(subset[\"layer_index\"].unique()))\n",
    "print(\"Antal lag:\", subset[\"layer_index\"].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b18e9847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique layers per model (per_prompt):\n",
      "m_4bit: [np.int64(-1), np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8)] ... total 34\n",
      "m_8bit: [np.int64(-1), np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8)] ... total 34\n",
      "m_quant: [np.int64(-1), np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8)] ... total 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6961/2016669249.py:8: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  d = subset[(subset[\"model\"] == model) & (df[\"pooling\"] == \"per_prompt\")]\n",
      "/tmp/ipykernel_6961/2016669249.py:8: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  d = subset[(subset[\"model\"] == model) & (df[\"pooling\"] == \"per_prompt\")]\n",
      "/tmp/ipykernel_6961/2016669249.py:8: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  d = subset[(subset[\"model\"] == model) & (df[\"pooling\"] == \"per_prompt\")]\n"
     ]
    }
   ],
   "source": [
    "subset = df[\n",
    "    (df[\"anchor\"] == \"disagree_correct\") &\n",
    "    (df[\"corr_type\"] == \"pointbiserial\")\n",
    "]\n",
    "\n",
    "print(\"Unique layers per model (per_prompt):\")\n",
    "for model in df[\"model\"].unique():\n",
    "    d = subset[(subset[\"model\"] == model) & (df[\"pooling\"] == \"per_prompt\")]\n",
    "    print(f\"{model}: {sorted(d['layer_index'].unique())[:10]} ... total {d['layer_index'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae1fd30",
   "metadata": {},
   "source": [
    "# ==============================================\n",
    "# Plot TopK Correlations =======================\n",
    "# =============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1a89039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] merged 23160 rows from 3 models.\n",
      "                                            count   mean    std    min    25%  \\\n",
      "anchor           corr_type     pooling                                          \n",
      "disagree_correct phi           per_prompt  1857.0  0.018  0.156 -0.864 -0.070   \n",
      "                               pooled      2094.0  0.012  0.076 -0.529 -0.009   \n",
      "                 pointbiserial per_prompt  3366.0  0.018  0.087 -0.191 -0.036   \n",
      "                               pooled      3366.0  0.013  0.070 -0.185 -0.019   \n",
      "                 undefined     per_prompt     0.0    NaN    NaN    NaN    NaN   \n",
      "                               pooled         0.0    NaN    NaN    NaN    NaN   \n",
      "logp_diff        pointbiserial per_prompt  2094.0 -0.018  0.110 -0.328 -0.073   \n",
      "                               pooled      2094.0 -0.010  0.071 -0.338 -0.020   \n",
      "                 spearman      per_prompt  3366.0  0.028  0.107 -0.324 -0.020   \n",
      "                               pooled      3366.0  0.031  0.129 -0.390 -0.021   \n",
      "                 undefined     per_prompt     0.0    NaN    NaN    NaN    NaN   \n",
      "                               pooled         0.0    NaN    NaN    NaN    NaN   \n",
      "\n",
      "                                             50%    75%    max  \n",
      "anchor           corr_type     pooling                          \n",
      "disagree_correct phi           per_prompt  0.001  0.053  1.000  \n",
      "                               pooled     -0.003  0.018  0.489  \n",
      "                 pointbiserial per_prompt  0.013  0.061  0.455  \n",
      "                               pooled      0.010  0.048  0.401  \n",
      "                 undefined     per_prompt    NaN    NaN    NaN  \n",
      "                               pooled        NaN    NaN    NaN  \n",
      "logp_diff        pointbiserial per_prompt  0.010  0.051  0.455  \n",
      "                               pooled      0.000  0.016  0.207  \n",
      "                 spearman      per_prompt  0.017  0.063  0.442  \n",
      "                               pooled      0.018  0.069  0.522  \n",
      "                 undefined     per_prompt    NaN    NaN    NaN  \n",
      "                               pooled        NaN    NaN    NaN  \n",
      "[saved] saved_data/figures_rawcorr_all/pooled/spearman_logp_diff_pooled_metrics.png\n",
      "[saved] saved_data/figures_rawcorr_all/pooled/pointbiserial_disagree_correct_pooled_metrics.png\n",
      "[saved] saved_data/figures_rawcorr_all/pooled/phi_disagree_correct_pooled_metrics.png\n",
      "[saved] saved_data/figures_rawcorr_all/per_prompt/spearman_logp_diff_per_prompt_metrics.png\n",
      "[saved] saved_data/figures_rawcorr_all/per_prompt/pointbiserial_disagree_correct_per_prompt_metrics.png\n",
      "[saved] saved_data/figures_rawcorr_all/per_prompt/phi_disagree_correct_per_prompt_metrics.png\n",
      "\n",
      "[mixed plotting] Generating full cross-anchor × metric plots...\n",
      "[mixed] disagree_correct (pooled) → 18 metrics plotted\n",
      "[saved] saved_data/figures_rawcorr_all/pooled/mixed_all_disagree_correct_pooled_metrics.png\n",
      "[saved] saved_data/figures_rawcorr_all/pooled/mixed_all_disagree_correct_pooled_divergence.png\n",
      "[saved] saved_data/figures_rawcorr_all/pooled/mixed_all_disagree_correct_pooled_representation.png\n",
      "[saved] saved_data/figures_rawcorr_all/pooled/mixed_all_disagree_correct_pooled_accuracy.png\n",
      "[mixed] logp_diff (pooled) → 18 metrics plotted\n",
      "[saved] saved_data/figures_rawcorr_all/pooled/mixed_all_logp_diff_pooled_metrics.png\n",
      "[saved] saved_data/figures_rawcorr_all/pooled/mixed_all_logp_diff_pooled_divergence.png\n",
      "[saved] saved_data/figures_rawcorr_all/pooled/mixed_all_logp_diff_pooled_representation.png\n",
      "[saved] saved_data/figures_rawcorr_all/pooled/mixed_all_logp_diff_pooled_accuracy.png\n",
      "[mixed] disagree_correct (per_prompt) → 18 metrics plotted\n",
      "[saved] saved_data/figures_rawcorr_all/per_prompt/mixed_all_disagree_correct_per_prompt_metrics.png\n",
      "[saved] saved_data/figures_rawcorr_all/per_prompt/mixed_all_disagree_correct_per_prompt_divergence.png\n",
      "[saved] saved_data/figures_rawcorr_all/per_prompt/mixed_all_disagree_correct_per_prompt_representation.png\n",
      "[saved] saved_data/figures_rawcorr_all/per_prompt/mixed_all_disagree_correct_per_prompt_accuracy.png\n",
      "[mixed] logp_diff (per_prompt) → 18 metrics plotted\n",
      "[saved] saved_data/figures_rawcorr_all/per_prompt/mixed_all_logp_diff_per_prompt_metrics.png\n",
      "[saved] saved_data/figures_rawcorr_all/per_prompt/mixed_all_logp_diff_per_prompt_divergence.png\n",
      "[saved] saved_data/figures_rawcorr_all/per_prompt/mixed_all_logp_diff_per_prompt_representation.png\n",
      "[saved] saved_data/figures_rawcorr_all/per_prompt/mixed_all_logp_diff_per_prompt_accuracy.png\n",
      "\n",
      "Top correlations:\n",
      "          anchor    metric     corr_type   model      rho\n",
      "       logp_diff   l2_dist      spearman m_quant 0.216796\n",
      "       logp_diff     kl_ab      spearman m_quant 0.199479\n",
      "       logp_diff    js_div      spearman m_quant 0.198268\n",
      "       logp_diff   js_dist      spearman m_quant 0.198267\n",
      "       logp_diff       tvd      spearman m_quant 0.197601\n",
      "       logp_diff     kl_ba      spearman m_quant 0.192367\n",
      "disagree_correct acc_A_@10           phi m_quant 0.104912\n",
      "disagree_correct  acc_A_@5           phi m_quant 0.092202\n",
      "disagree_correct  acc_A_@1           phi m_quant 0.078308\n",
      "disagree_correct     kl_ab pointbiserial  m_8bit 0.058194\n",
      "disagree_correct    js_div pointbiserial  m_8bit 0.058087\n",
      "disagree_correct     kl_ba pointbiserial  m_8bit 0.057839\n",
      "disagree_correct     kl_ab pointbiserial  m_4bit 0.057298\n",
      "disagree_correct    js_div pointbiserial  m_4bit 0.056793\n",
      "disagree_correct       tvd pointbiserial  m_4bit 0.056415\n",
      "disagree_correct   js_dist pointbiserial  m_4bit 0.056323\n",
      "       logp_diff acc_A_@10 pointbiserial  m_8bit 0.055988\n",
      "disagree_correct     kl_ba pointbiserial  m_4bit 0.055793\n",
      "disagree_correct   js_dist pointbiserial  m_8bit 0.054389\n",
      "disagree_correct       tvd pointbiserial  m_8bit 0.053275\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# === STYLE ===\n",
    "sns.set_theme(style=\"whitegrid\", context=\"talk\", palette=\"deep\")\n",
    "plt.rcParams.update({\n",
    "    \"axes.titlesize\": 12,\n",
    "    \"axes.labelsize\": 11,\n",
    "    \"legend.fontsize\": 8,\n",
    "    \"xtick.labelsize\": 9,\n",
    "    \"ytick.labelsize\": 9,\n",
    "})\n",
    "\n",
    "# === CONFIG ===\n",
    "BASE_DIR = Path(\"saved_data/summary\")\n",
    "MODELS = [\"m_4bit\", \"m_8bit\", \"m_quant\"]\n",
    "ANCHORS_CONTINUOUS = [\"logp_diff\"]\n",
    "ANCHORS_BINARY = [\"disagree_correct\"]\n",
    "OUT_ROOT = Path(\"saved_data/figures_rawcorr_all\")\n",
    "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "LAYOUT_MODE = \"metric\"   # \"mode\" | \"metric\" | \"group\"\n",
    "\n",
    "SPEARMAN_METRICS = [\n",
    "    \"tvd\",\"kl_ab\",\"kl_ba\",\"js_div\",\"js_dist\",\"cosine_sim\",\n",
    "    \"l2_dist\",\"ppl_diff\",\"jaccard_@1\",\"jaccard_@5\",\"jaccard_@10\"\n",
    "]\n",
    "BISERIAL_METRICS = [\n",
    "    \"acc_A_@1\",\"acc_A_@5\",\"acc_A_@10\",\n",
    "    \"acc_B_@1\",\"acc_B_@5\",\"acc_B_@10\",\n",
    "    \"disagree_correct\",\"jaccard_@1\",\"jaccard_@5\",\"jaccard_@10\"\n",
    "]\n",
    "GROUPS = {\n",
    "    \"divergence\": [\"tvd\",\"kl_ab\",\"kl_ba\",\"js_div\",\"js_dist\",\"ppl_diff\"],\n",
    "    \"representation\": [\"cosine_sim\",\"l2_dist\",\"jaccard_@1\",\"jaccard_@5\",\"jaccard_@10\"],\n",
    "    \"accuracy\": [\"acc_A_@1\",\"acc_B_@1\",\"acc_A_@5\",\"acc_B_@5\",\"disagree_correct\"]\n",
    "}\n",
    "\n",
    "# === LOAD RAW CORR FILES ===\n",
    "dfs = []\n",
    "for model in MODELS:\n",
    "    model_dir = BASE_DIR / model\n",
    "    if not model_dir.exists():\n",
    "        continue\n",
    "    for f in model_dir.glob(\"*corr_*.csv\"):\n",
    "        if \"summary\" in f.name:\n",
    "            continue\n",
    "        d = pd.read_csv(f)\n",
    "        d[\"model\"] = model\n",
    "        if \"pooled\" in f.stem:\n",
    "            d[\"pooling\"] = \"pooled\"\n",
    "        elif \"perprompt\" in f.stem or \"per_prompt\" in f.stem:\n",
    "            d[\"pooling\"] = \"per_prompt\"\n",
    "        else:\n",
    "            d[\"pooling\"] = \"unknown\"\n",
    "        dfs.append(d)\n",
    "\n",
    "if not dfs:\n",
    "    raise RuntimeError(\"No raw correlation files found!\")\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "for c in [\"rho\"]:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "df[\"layer_index\"] = pd.to_numeric(df[\"layer_index\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "df[\"rho_smooth\"] = df[\"rho\"]  # raw values only\n",
    "\n",
    "print(f\"[ok] merged {len(df)} rows from {df['model'].nunique()} models.\")\n",
    "print(df.groupby([\"anchor\",\"corr_type\",\"pooling\"])[\"rho\"].describe().round(3))\n",
    "\n",
    "# === HELPERS ===\n",
    "def _auto_subplots(n_items, n_cols=3):\n",
    "    n_rows = int(np.ceil(n_items / n_cols))\n",
    "    return n_rows, n_cols\n",
    "\n",
    "def _finalize_grid(fig, axes, title, save_path=None):\n",
    "    for ax in axes.flat:\n",
    "        if not ax.has_data():\n",
    "            ax.axis(\"off\")\n",
    "    fig.suptitle(title, fontsize=15, weight=\"bold\")\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    if save_path:\n",
    "        fig.savefig(save_path, dpi=250, bbox_inches=\"tight\")\n",
    "        print(f\"[saved] {save_path}\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def _mark_nans(ax, dsub):\n",
    "    d_nan = dsub[dsub[\"rho\"].isna()]\n",
    "    if not d_nan.empty:\n",
    "        for i, model in enumerate(sorted(d_nan[\"model\"].unique())):\n",
    "            d_m = d_nan[d_nan[\"model\"] == model]\n",
    "            ax.scatter(\n",
    "                d_m[\"layer_index\"],\n",
    "                [-0.95 + 0.05*i] * len(d_m),\n",
    "                color=\"red\", marker=\"x\", s=50, label=f\"{model} NaN\"\n",
    "            )\n",
    "\n",
    "# === PLOT FUNCTIONS ===\n",
    "def plot_by_mode(df_sub, corr_type, anchor, pooling, out_dir):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "    for ax, mode in zip(axes, [\"raw\", \"unit_rms\", \"norm_rms\"]):\n",
    "        dmode = df_sub[df_sub[\"mode\"] == mode]\n",
    "        if dmode.empty:\n",
    "            ax.text(0.5, 0.5, \"no data\", ha=\"center\", va=\"center\", fontsize=11)\n",
    "            continue\n",
    "        sns.lineplot(\n",
    "            data=dmode, x=\"layer_index\", y=\"rho_smooth\",\n",
    "            hue=\"model\", style=\"metric\", lw=2, ax=ax\n",
    "        )\n",
    "        _mark_nans(ax, dmode)\n",
    "        ax.axhline(0, color=\"black\", linestyle=\":\")\n",
    "        ax.axhline(0.3, color=\"gray\", linestyle=\"--\", lw=0.6, alpha=0.4)\n",
    "        ax.axhline(-0.3, color=\"gray\", linestyle=\"--\", lw=0.6, alpha=0.4)\n",
    "        ax.set_ylim(-1, 1)\n",
    "        ax.set_title(mode.upper(), fontsize=12, weight=\"bold\")\n",
    "        ax.set_xlabel(\"Layer index\")\n",
    "        ax.set_ylabel(\"ρ\" if mode == \"raw\" else \"\")\n",
    "        ax.legend(fontsize=8)\n",
    "    _finalize_grid(fig, axes, f\"{corr_type.capitalize()} — {anchor} ({pooling})\",\n",
    "                   out_dir / f\"{corr_type}_{anchor}_{pooling}_modes.png\")\n",
    "\n",
    "def plot_by_metric(df_sub, corr_type, anchor, pooling, out_dir, n_cols=3):\n",
    "    metrics = sorted(df_sub[\"metric\"].unique())\n",
    "    n_rows, n_cols = _auto_subplots(len(metrics), n_cols)\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(6 * n_cols, 3.5 * n_rows), sharey=True)\n",
    "    axes = np.array(axes).reshape(-1)\n",
    "    for ax, metric in zip(axes, metrics):\n",
    "        dmet = df_sub[df_sub[\"metric\"] == metric]\n",
    "        if dmet.empty:\n",
    "            continue\n",
    "        sns.lineplot(\n",
    "            data=dmet, x=\"layer_index\", y=\"rho_smooth\",\n",
    "            hue=\"model\", style=\"mode\", lw=2.2, ax=ax\n",
    "        )\n",
    "        _mark_nans(ax, dmet)\n",
    "        ax.axhline(0, color=\"black\", linestyle=\":\")\n",
    "        ax.axhline(0.3, color=\"gray\", linestyle=\"--\", lw=0.6, alpha=0.4)\n",
    "        ax.axhline(-0.3, color=\"gray\", linestyle=\"--\", lw=0.6, alpha=0.4)\n",
    "        ax.set_ylim(-1, 1)\n",
    "        ax.set_title(metric, fontsize=10)\n",
    "        ax.set_xlabel(\"Layer index\")\n",
    "        ax.set_ylabel(\"ρ\")\n",
    "        ax.legend(fontsize=8, frameon=True)\n",
    "    _finalize_grid(fig, axes, f\"{corr_type.capitalize()} — {anchor} ({pooling})\",\n",
    "                   out_dir / f\"{corr_type}_{anchor}_{pooling}_metrics.png\")\n",
    "\n",
    "def plot_by_group(df_sub, corr_type, anchor, pooling, out_dir):\n",
    "    for gname, gmetrics in GROUPS.items():\n",
    "        dgroup = df_sub[df_sub[\"metric\"].isin(gmetrics)]\n",
    "        if dgroup.empty:\n",
    "            continue\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "        for ax, mode in zip(axes, [\"raw\", \"unit_rms\", \"norm_rms\"]):\n",
    "            dmode = dgroup[dgroup[\"mode\"] == mode]\n",
    "            if dmode.empty:\n",
    "                ax.text(0.5, 0.5, \"no data\", ha=\"center\", va=\"center\", fontsize=11)\n",
    "                continue\n",
    "            sns.lineplot(\n",
    "                data=dmode, x=\"layer_index\", y=\"rho_smooth\",\n",
    "                hue=\"model\", style=\"metric\", lw=2, ax=ax\n",
    "            )\n",
    "            _mark_nans(ax, dmode)\n",
    "            ax.axhline(0, color=\"black\", linestyle=\":\")\n",
    "            ax.axhline(0.3, color=\"gray\", linestyle=\"--\", lw=0.6, alpha=0.4)\n",
    "            ax.axhline(-0.3, color=\"gray\", linestyle=\"--\", lw=0.6, alpha=0.4)\n",
    "            ax.set_ylim(-1, 1)\n",
    "            ax.set_title(f\"{gname.title()} ({mode})\", fontsize=11)\n",
    "            ax.set_xlabel(\"Layer index\")\n",
    "            ax.set_ylabel(\"ρ\" if mode == \"raw\" else \"\")\n",
    "            ax.legend(fontsize=8, frameon=True)\n",
    "        _finalize_grid(fig, axes,\n",
    "                       f\"{gname.capitalize()} — {corr_type.capitalize()} ({anchor}/{pooling})\",\n",
    "                       out_dir / f\"{corr_type}_{anchor}_{pooling}_{gname}.png\")\n",
    "\n",
    "# === MAIN LOOP ===\n",
    "for pooling in [\"pooled\", \"per_prompt\"]:\n",
    "    out_dir = OUT_ROOT / pooling\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Continuous (Spearman)\n",
    "    for anchor in ANCHORS_CONTINUOUS:\n",
    "        df_s = df[\n",
    "            (df[\"anchor\"] == anchor)\n",
    "            & (df[\"corr_type\"] == \"spearman\")\n",
    "            & (df[\"pooling\"] == pooling)\n",
    "            & (df[\"metric\"].isin(SPEARMAN_METRICS))\n",
    "        ]\n",
    "        if df_s.empty:\n",
    "            continue\n",
    "        if LAYOUT_MODE == \"mode\":\n",
    "            plot_by_mode(df_s, \"spearman\", anchor, pooling, out_dir)\n",
    "        elif LAYOUT_MODE == \"metric\":\n",
    "            plot_by_metric(df_s, \"spearman\", anchor, pooling, out_dir)\n",
    "        elif LAYOUT_MODE == \"group\":\n",
    "            plot_by_group(df_s, \"spearman\", anchor, pooling, out_dir)\n",
    "\n",
    "    # Binary (Point-biserial & Phi)\n",
    "    for corr_type in [\"pointbiserial\", \"phi\"]:\n",
    "        for anchor in ANCHORS_BINARY:\n",
    "            df_b = df[\n",
    "                (df[\"anchor\"] == anchor)\n",
    "                & (df[\"corr_type\"] == corr_type)\n",
    "                & (df[\"pooling\"] == pooling)\n",
    "                & (df[\"metric\"].isin(BISERIAL_METRICS))\n",
    "            ]\n",
    "            if df_b.empty:\n",
    "                continue\n",
    "            if LAYOUT_MODE == \"mode\":\n",
    "                plot_by_mode(df_b, corr_type, anchor, pooling, out_dir)\n",
    "            elif LAYOUT_MODE == \"metric\":\n",
    "                plot_by_metric(df_b, corr_type, anchor, pooling, out_dir)\n",
    "            elif LAYOUT_MODE == \"group\":\n",
    "                plot_by_group(df_b, corr_type, anchor, pooling, out_dir)\n",
    "\n",
    "# === MIXED ALL-COMBINATION PLOTS ===\n",
    "print(\"\\n[mixed plotting] Generating full cross-anchor × metric plots...\")\n",
    "\n",
    "ALL_CORR_TYPES = [\"phi\", \"pointbiserial\", \"spearman\"]\n",
    "\n",
    "for pooling in [\"pooled\", \"per_prompt\"]:\n",
    "    out_dir = OUT_ROOT / pooling\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for anchor in ANCHORS_BINARY + ANCHORS_CONTINUOUS:\n",
    "        df_all = df[\n",
    "            (df[\"anchor\"] == anchor)\n",
    "            & (df[\"pooling\"] == pooling)\n",
    "            & (df[\"corr_type\"].isin(ALL_CORR_TYPES))\n",
    "        ]\n",
    "        if df_all.empty:\n",
    "            print(f\"[skip] no data for {anchor} ({pooling})\")\n",
    "            continue\n",
    "\n",
    "        print(f\"[mixed] {anchor} ({pooling}) → {df_all['metric'].nunique()} metrics plotted\")\n",
    "        plot_by_metric(df_all, \"mixed_all\", anchor, pooling, out_dir)\n",
    "        plot_by_group(df_all, \"mixed_all\", anchor, pooling, out_dir)\n",
    "\n",
    "# === QUICK TOPLIST ===\n",
    "top = (\n",
    "    df.groupby([\"anchor\", \"metric\", \"corr_type\", \"model\"])[\"rho\"]\n",
    "      .mean().reset_index()\n",
    "      .sort_values(\"rho\", ascending=False)\n",
    ")\n",
    "print(\"\\nTop correlations:\")\n",
    "print(top.head(20).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce8f1c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rho</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rho\n",
       "count  0.0\n",
       "mean   NaN\n",
       "std    NaN\n",
       "min    NaN\n",
       "25%    NaN\n",
       "50%    NaN\n",
       "75%    NaN\n",
       "max    NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query(\"metric == 'ppl_diff'\")[[\"rho\",\"corr_type\",\"anchor\",\"pooling\"]].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd887014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] merged 23160 rows from 3 models.\n",
      "                                            count   mean    std    min    25%  \\\n",
      "anchor           corr_type     pooling                                          \n",
      "disagree_correct phi           per_prompt  1857.0  0.018  0.156 -0.864 -0.070   \n",
      "                               pooled      2094.0  0.012  0.076 -0.529 -0.009   \n",
      "                 pointbiserial per_prompt  3366.0  0.018  0.087 -0.191 -0.036   \n",
      "                               pooled      3366.0  0.013  0.070 -0.185 -0.019   \n",
      "                 undefined     per_prompt     0.0    NaN    NaN    NaN    NaN   \n",
      "                               pooled         0.0    NaN    NaN    NaN    NaN   \n",
      "logp_diff        pointbiserial per_prompt  2094.0 -0.018  0.110 -0.328 -0.073   \n",
      "                               pooled      2094.0 -0.010  0.071 -0.338 -0.020   \n",
      "                 spearman      per_prompt  3366.0  0.028  0.107 -0.324 -0.020   \n",
      "                               pooled      3366.0  0.031  0.129 -0.390 -0.021   \n",
      "                 undefined     per_prompt     0.0    NaN    NaN    NaN    NaN   \n",
      "                               pooled         0.0    NaN    NaN    NaN    NaN   \n",
      "\n",
      "                                             50%    75%    max  \n",
      "anchor           corr_type     pooling                          \n",
      "disagree_correct phi           per_prompt  0.001  0.053  1.000  \n",
      "                               pooled     -0.003  0.018  0.489  \n",
      "                 pointbiserial per_prompt  0.013  0.061  0.455  \n",
      "                               pooled      0.010  0.048  0.401  \n",
      "                 undefined     per_prompt    NaN    NaN    NaN  \n",
      "                               pooled        NaN    NaN    NaN  \n",
      "logp_diff        pointbiserial per_prompt  0.010  0.051  0.455  \n",
      "                               pooled      0.000  0.016  0.207  \n",
      "                 spearman      per_prompt  0.017  0.063  0.442  \n",
      "                               pooled      0.018  0.069  0.522  \n",
      "                 undefined     per_prompt    NaN    NaN    NaN  \n",
      "                               pooled        NaN    NaN    NaN  \n",
      "[saved] saved_data/figures_rawcorr/pooled/spearman_logp_diff_pooled_metrics.png\n",
      "[saved] saved_data/figures_rawcorr/pooled/pointbiserial_disagree_correct_pooled_metrics.png\n",
      "[saved] saved_data/figures_rawcorr/pooled/phi_disagree_correct_pooled_metrics.png\n",
      "[saved] saved_data/figures_rawcorr/per_prompt/spearman_logp_diff_per_prompt_metrics.png\n",
      "[saved] saved_data/figures_rawcorr/per_prompt/pointbiserial_disagree_correct_per_prompt_metrics.png\n",
      "[saved] saved_data/figures_rawcorr/per_prompt/phi_disagree_correct_per_prompt_metrics.png\n",
      "\n",
      "Top correlations:\n",
      "          anchor    metric     corr_type   model      rho\n",
      "       logp_diff   l2_dist      spearman m_quant 0.216796\n",
      "       logp_diff     kl_ab      spearman m_quant 0.199479\n",
      "       logp_diff    js_div      spearman m_quant 0.198268\n",
      "       logp_diff   js_dist      spearman m_quant 0.198267\n",
      "       logp_diff       tvd      spearman m_quant 0.197601\n",
      "       logp_diff     kl_ba      spearman m_quant 0.192367\n",
      "disagree_correct acc_A_@10           phi m_quant 0.104912\n",
      "disagree_correct  acc_A_@5           phi m_quant 0.092202\n",
      "disagree_correct  acc_A_@1           phi m_quant 0.078308\n",
      "disagree_correct     kl_ab pointbiserial  m_8bit 0.058194\n",
      "disagree_correct    js_div pointbiserial  m_8bit 0.058087\n",
      "disagree_correct     kl_ba pointbiserial  m_8bit 0.057839\n",
      "disagree_correct     kl_ab pointbiserial  m_4bit 0.057298\n",
      "disagree_correct    js_div pointbiserial  m_4bit 0.056793\n",
      "disagree_correct       tvd pointbiserial  m_4bit 0.056415\n",
      "disagree_correct   js_dist pointbiserial  m_4bit 0.056323\n",
      "       logp_diff acc_A_@10 pointbiserial  m_8bit 0.055988\n",
      "disagree_correct     kl_ba pointbiserial  m_4bit 0.055793\n",
      "disagree_correct   js_dist pointbiserial  m_8bit 0.054389\n",
      "disagree_correct       tvd pointbiserial  m_8bit 0.053275\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# === STYLE ===\n",
    "sns.set_theme(style=\"whitegrid\", context=\"talk\", palette=\"deep\")\n",
    "plt.rcParams.update({\n",
    "    \"axes.titlesize\": 12,\n",
    "    \"axes.labelsize\": 11,\n",
    "    \"legend.fontsize\": 8,\n",
    "    \"xtick.labelsize\": 9,\n",
    "    \"ytick.labelsize\": 9,\n",
    "})\n",
    "\n",
    "# === CONFIG ===\n",
    "BASE_DIR = Path(\"saved_data/summary\")\n",
    "MODELS = [\"m_4bit\", \"m_8bit\", \"m_quant\"]\n",
    "ANCHORS_CONTINUOUS = [\"logp_diff\"]\n",
    "ANCHORS_BINARY = [\"disagree_correct\"]\n",
    "OUT_ROOT = Path(\"saved_data/figures_rawcorr\")\n",
    "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "LAYOUT_MODE = \"metric\"   # \"mode\" | \"metric\" | \"group\"\n",
    "\n",
    "SPEARMAN_METRICS = [\n",
    "    \"tvd\",\"kl_ab\",\"kl_ba\",\"js_div\",\"js_dist\",\"cosine_sim\",\n",
    "    \"l2_dist\",\"ppl_diff\",\"jaccard_@1\",\"jaccard_@5\",\"jaccard_@10\"\n",
    "]\n",
    "BISERIAL_METRICS = [\n",
    "    \"acc_A_@1\",\"acc_A_@5\",\"acc_A_@10\",\n",
    "    \"acc_B_@1\",\"acc_B_@5\",\"acc_B_@10\",\n",
    "    \"disagree_correct\",\"jaccard_@1\",\"jaccard_@5\",\"jaccard_@10\"\n",
    "]\n",
    "GROUPS = {\n",
    "    \"divergence\": [\"tvd\",\"kl_ab\",\"kl_ba\",\"js_div\",\"js_dist\",\"ppl_diff\"],\n",
    "    \"representation\": [\"cosine_sim\",\"l2_dist\",\"jaccard_@1\",\"jaccard_@5\",\"jaccard_@10\"],\n",
    "    \"accuracy\": [\"acc_A_@1\",\"acc_B_@1\",\"acc_A_@5\",\"acc_B_@5\",\"disagree_correct\"]\n",
    "}\n",
    "\n",
    "# === LOAD RAW CORR FILES ===\n",
    "dfs = []\n",
    "for model in MODELS:\n",
    "    model_dir = BASE_DIR / model\n",
    "    if not model_dir.exists():\n",
    "        continue\n",
    "    for f in model_dir.glob(\"*corr_*.csv\"):\n",
    "        if \"summary\" in f.name:\n",
    "            continue\n",
    "        d = pd.read_csv(f)\n",
    "        d[\"model\"] = model\n",
    "        if \"pooled\" in f.stem:\n",
    "            d[\"pooling\"] = \"pooled\"\n",
    "        elif \"perprompt\" in f.stem or \"per_prompt\" in f.stem:\n",
    "            d[\"pooling\"] = \"per_prompt\"\n",
    "        else:\n",
    "            d[\"pooling\"] = \"unknown\"\n",
    "        dfs.append(d)\n",
    "\n",
    "if not dfs:\n",
    "    raise RuntimeError(\"No raw correlation files found!\")\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "for c in [\"rho\"]:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "df[\"layer_index\"] = pd.to_numeric(df[\"layer_index\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "df[\"rho_smooth\"] = df[\"rho\"]  # raw values only\n",
    "\n",
    "print(f\"[ok] merged {len(df)} rows from {df['model'].nunique()} models.\")\n",
    "print(df.groupby([\"anchor\",\"corr_type\",\"pooling\"])[\"rho\"].describe().round(3))\n",
    "\n",
    "# === HELPERS ===\n",
    "def _auto_subplots(n_items, n_cols=3):\n",
    "    n_rows = int(np.ceil(n_items / n_cols))\n",
    "    return n_rows, n_cols\n",
    "\n",
    "def _finalize_grid(fig, axes, title, save_path=None):\n",
    "    for ax in axes.flat:\n",
    "        if not ax.has_data():\n",
    "            ax.axis(\"off\")\n",
    "    fig.suptitle(title, fontsize=15, weight=\"bold\")\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    if save_path:\n",
    "        fig.savefig(save_path, dpi=250, bbox_inches=\"tight\")\n",
    "        print(f\"[saved] {save_path}\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def _mark_nans(ax, dsub):\n",
    "    d_nan = dsub[dsub[\"rho\"].isna()]\n",
    "    if not d_nan.empty:\n",
    "        for i, model in enumerate(sorted(d_nan[\"model\"].unique())):\n",
    "            d_m = d_nan[d_nan[\"model\"] == model]\n",
    "            ax.scatter(\n",
    "                d_m[\"layer_index\"],\n",
    "                [-0.95 + 0.05*i] * len(d_m),  # lidt forskudt pr. model\n",
    "                color=\"red\", marker=\"x\", s=50, label=f\"{model} NaN\"\n",
    "            )\n",
    "\n",
    "# === PLOT FUNCTIONS ===\n",
    "def plot_by_mode(df_sub, corr_type, anchor, pooling, out_dir):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "    for ax, mode in zip(axes, [\"raw\", \"unit_rms\", \"norm_rms\"]):\n",
    "        dmode = df_sub[df_sub[\"mode\"] == mode]\n",
    "        if dmode.empty:\n",
    "            ax.text(0.5, 0.5, \"no data\", ha=\"center\", va=\"center\", fontsize=11)\n",
    "            continue\n",
    "        sns.lineplot(\n",
    "            data=dmode, x=\"layer_index\", y=\"rho_smooth\",\n",
    "            hue=\"model\", style=\"metric\", lw=2, ax=ax\n",
    "        )\n",
    "        _mark_nans(ax, dmode)\n",
    "        ax.axhline(0, color=\"black\", linestyle=\":\")\n",
    "        ax.axhline(0.3, color=\"gray\", linestyle=\"--\", lw=0.6, alpha=0.4)\n",
    "        ax.axhline(-0.3, color=\"gray\", linestyle=\"--\", lw=0.6, alpha=0.4)\n",
    "        ax.set_ylim(-1, 1)\n",
    "        ax.set_title(mode.upper(), fontsize=12, weight=\"bold\")\n",
    "        ax.set_xlabel(\"Layer index\")\n",
    "        ax.set_ylabel(\"ρ\" if mode == \"raw\" else \"\")\n",
    "        ax.legend(fontsize=8)\n",
    "    _finalize_grid(fig, axes, f\"{corr_type.capitalize()} — {anchor} ({pooling})\",\n",
    "                   out_dir / f\"{corr_type}_{anchor}_{pooling}_modes.png\")\n",
    "\n",
    "def plot_by_metric(df_sub, corr_type, anchor, pooling, out_dir, n_cols=3):\n",
    "    metrics = sorted(df_sub[\"metric\"].unique())\n",
    "    n_rows, n_cols = _auto_subplots(len(metrics), n_cols)\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(6 * n_cols, 3.5 * n_rows), sharey=True)\n",
    "    axes = np.array(axes).reshape(-1)\n",
    "    for ax, metric in zip(axes, metrics):\n",
    "        dmet = df_sub[df_sub[\"metric\"] == metric]\n",
    "        if dmet.empty:\n",
    "            continue\n",
    "        sns.lineplot(\n",
    "            data=dmet, x=\"layer_index\", y=\"rho_smooth\",\n",
    "            hue=\"model\", style=\"mode\", lw=2.2, ax=ax\n",
    "        )\n",
    "        _mark_nans(ax, dmet)\n",
    "        ax.axhline(0, color=\"black\", linestyle=\":\")\n",
    "        ax.axhline(0.3, color=\"gray\", linestyle=\"--\", lw=0.6, alpha=0.4)\n",
    "        ax.axhline(-0.3, color=\"gray\", linestyle=\"--\", lw=0.6, alpha=0.4)\n",
    "        ax.set_ylim(-1, 1)\n",
    "        ax.set_title(metric, fontsize=10)\n",
    "        ax.set_xlabel(\"Layer index\")\n",
    "        ax.set_ylabel(\"ρ\")\n",
    "        ax.legend(fontsize=8, frameon=True)\n",
    "    _finalize_grid(fig, axes, f\"{corr_type.capitalize()} — {anchor} ({pooling})\",\n",
    "                   out_dir / f\"{corr_type}_{anchor}_{pooling}_metrics.png\")\n",
    "\n",
    "def plot_by_group(df_sub, corr_type, anchor, pooling, out_dir):\n",
    "    for gname, gmetrics in GROUPS.items():\n",
    "        dgroup = df_sub[df_sub[\"metric\"].isin(gmetrics)]\n",
    "        if dgroup.empty:\n",
    "            continue\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "        for ax, mode in zip(axes, [\"raw\", \"unit_rms\", \"norm_rms\"]):\n",
    "            dmode = dgroup[dgroup[\"mode\"] == mode]\n",
    "            if dmode.empty:\n",
    "                ax.text(0.5, 0.5, \"no data\", ha=\"center\", va=\"center\", fontsize=11)\n",
    "                continue\n",
    "            sns.lineplot(\n",
    "                data=dmode, x=\"layer_index\", y=\"rho_smooth\",\n",
    "                hue=\"model\", style=\"metric\", lw=2, ax=ax\n",
    "            )\n",
    "            _mark_nans(ax, dmode)\n",
    "            ax.axhline(0, color=\"black\", linestyle=\":\")\n",
    "            ax.axhline(0.3, color=\"gray\", linestyle=\"--\", lw=0.6, alpha=0.4)\n",
    "            ax.axhline(-0.3, color=\"gray\", linestyle=\"--\", lw=0.6, alpha=0.4)\n",
    "            ax.set_ylim(-1, 1)\n",
    "            ax.set_title(f\"{gname.title()} ({mode})\", fontsize=11)\n",
    "            ax.set_xlabel(\"Layer index\")\n",
    "            ax.set_ylabel(\"ρ\" if mode == \"raw\" else \"\")\n",
    "            ax.legend(fontsize=8, frameon=True)\n",
    "        _finalize_grid(fig, axes,\n",
    "                       f\"{gname.capitalize()} — {corr_type.capitalize()} ({anchor}/{pooling})\",\n",
    "                       out_dir / f\"{corr_type}_{anchor}_{pooling}_{gname}.png\")\n",
    "\n",
    "# === MAIN LOOP ===\n",
    "for pooling in [\"pooled\", \"per_prompt\"]:\n",
    "    out_dir = OUT_ROOT / pooling\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Continuous (Spearman)\n",
    "    for anchor in ANCHORS_CONTINUOUS:\n",
    "        df_s = df[\n",
    "            (df[\"anchor\"] == anchor)\n",
    "            & (df[\"corr_type\"] == \"spearman\")\n",
    "            & (df[\"pooling\"] == pooling)\n",
    "            & (df[\"metric\"].isin(SPEARMAN_METRICS))\n",
    "        ]\n",
    "        if df_s.empty:\n",
    "            continue\n",
    "        if LAYOUT_MODE == \"mode\":\n",
    "            plot_by_mode(df_s, \"spearman\", anchor, pooling, out_dir)\n",
    "        elif LAYOUT_MODE == \"metric\":\n",
    "            plot_by_metric(df_s, \"spearman\", anchor, pooling, out_dir)\n",
    "        elif LAYOUT_MODE == \"group\":\n",
    "            plot_by_group(df_s, \"spearman\", anchor, pooling, out_dir)\n",
    "\n",
    "    # Binary (Point-biserial & Phi)\n",
    "    for corr_type in [\"pointbiserial\", \"phi\"]:\n",
    "        for anchor in ANCHORS_BINARY:\n",
    "            df_b = df[\n",
    "                (df[\"anchor\"] == anchor)\n",
    "                & (df[\"corr_type\"] == corr_type)\n",
    "                & (df[\"pooling\"] == pooling)\n",
    "                & (df[\"metric\"].isin(BISERIAL_METRICS))\n",
    "            ]\n",
    "            if df_b.empty:\n",
    "                continue\n",
    "            if LAYOUT_MODE == \"mode\":\n",
    "                plot_by_mode(df_b, corr_type, anchor, pooling, out_dir)\n",
    "            elif LAYOUT_MODE == \"metric\":\n",
    "                plot_by_metric(df_b, corr_type, anchor, pooling, out_dir)\n",
    "            elif LAYOUT_MODE == \"group\":\n",
    "                plot_by_group(df_b, corr_type, anchor, pooling, out_dir)\n",
    "\n",
    "# === QUICK TOPLIST ===\n",
    "top = (\n",
    "    df.groupby([\"anchor\", \"metric\", \"corr_type\", \"model\"])[\"rho\"]\n",
    "      .mean().reset_index()\n",
    "      .sort_values(\"rho\", ascending=False)\n",
    ")\n",
    "print(\"\\nTop correlations:\")\n",
    "print(top.head(20).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f88821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# === STYLE ===\n",
    "sns.set_theme(style=\"whitegrid\", context=\"talk\", palette=\"deep\")\n",
    "plt.rcParams.update({\n",
    "    \"axes.titlesize\": 12,\n",
    "    \"axes.labelsize\": 11,\n",
    "    \"legend.fontsize\": 8,\n",
    "    \"xtick.labelsize\": 9,\n",
    "    \"ytick.labelsize\": 9,\n",
    "})\n",
    "\n",
    "# === CONFIG ===\n",
    "BASE_DIR = Path(\"saved_data/summary\")\n",
    "MODELS = [\"m_4bit\", \"m_8bit\", \"m_quant\"]\n",
    "ANCHORS_CONTINUOUS = [\"logp_diff\"]\n",
    "ANCHORS_BINARY = [\"disagree_correct\"]\n",
    "OUT_ROOT = Path(\"saved_data/figures_flexible_rawcorr\")\n",
    "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "LAYOUT_MODE = \"metric\"   # \"mode\" | \"metric\" | \"group\"\n",
    "\n",
    "SPEARMAN_METRICS = [\n",
    "    \"tvd\",\"kl_ab\",\"kl_ba\",\"js_div\",\"js_dist\",\"cosine_sim\",\n",
    "    \"l2_dist\",\"ppl_diff\",\"jaccard_@1\",\"jaccard_@5\",\"jaccard_@10\"\n",
    "]\n",
    "BISERIAL_METRICS = [\n",
    "    \"acc_A_@1\",\"acc_A_@5\",\"acc_A_@10\",\n",
    "    \"acc_B_@1\",\"acc_B_@5\",\"acc_B_@10\",\n",
    "    \"disagree_correct\",\"jaccard_@1\",\"jaccard_@5\",\"jaccard_@10\"\n",
    "]\n",
    "GROUPS = {\n",
    "    \"divergence\": [\"tvd\",\"kl_ab\",\"kl_ba\",\"js_div\",\"js_dist\",\"ppl_diff\"],\n",
    "    \"representation\": [\"cosine_sim\",\"l2_dist\",\"jaccard_@1\",\"jaccard_@5\",\"jaccard_@10\"],\n",
    "    \"accuracy\": [\"acc_A_@1\",\"acc_B_@1\",\"acc_A_@5\",\"acc_B_@5\",\"disagree_correct\"]\n",
    "}\n",
    "\n",
    "# === LOAD RAW CORR FILES ===\n",
    "dfs = []\n",
    "for model in MODELS:\n",
    "    model_dir = BASE_DIR / model\n",
    "    if not model_dir.exists():\n",
    "        continue\n",
    "    for f in model_dir.glob(\"*corr_*.csv\"):\n",
    "        if \"summary\" in f.name:\n",
    "            continue\n",
    "        d = pd.read_csv(f)\n",
    "        d[\"model\"] = model\n",
    "        if \"pooled\" in f.stem:\n",
    "            d[\"pooling\"] = \"pooled\"\n",
    "        elif \"perprompt\" in f.stem or \"per_prompt\" in f.stem:\n",
    "            d[\"pooling\"] = \"per_prompt\"\n",
    "        else:\n",
    "            d[\"pooling\"] = \"unknown\"\n",
    "        dfs.append(d)\n",
    "\n",
    "if not dfs:\n",
    "    raise RuntimeError(\"No raw correlation files found!\")\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "for c in [\"rho\"]:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "df[\"layer_index\"] = pd.to_numeric(df[\"layer_index\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "# === RAW VALUES (no smoothing) ===\n",
    "df[\"rho_smooth\"] = df[\"rho\"]\n",
    "\n",
    "print(f\"[ok] merged {len(df)} rows from {df['model'].nunique()} models.\")\n",
    "print(df.groupby([\"anchor\",\"corr_type\",\"pooling\"])[\"rho\"].describe().round(3))\n",
    "\n",
    "# === HELPERS ===\n",
    "def _auto_subplots(n_items, n_cols=3):\n",
    "    n_rows = int(np.ceil(n_items / n_cols))\n",
    "    return n_rows, n_cols\n",
    "\n",
    "def _finalize_grid(fig, axes, title, save_path=None):\n",
    "    for ax in axes.flat:\n",
    "        if not ax.has_data():\n",
    "            ax.axis(\"off\")\n",
    "    fig.suptitle(title, fontsize=15, weight=\"bold\")\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    if save_path:\n",
    "        fig.savefig(save_path, dpi=250, bbox_inches=\"tight\")\n",
    "        print(f\"[saved] {save_path}\")\n",
    "    plt.close(fig)\n",
    "\n",
    "# === ADD NAN MARKERS ===\n",
    "def _mark_nans(ax, dsub):\n",
    "    d_nan = dsub[dsub[\"rho\"].isna()]\n",
    "    if not d_nan.empty:\n",
    "        ax.scatter(\n",
    "            d_nan[\"layer_index\"],\n",
    "            [0] * len(d_nan),\n",
    "            color=\"red\", marker=\"x\", s=60, label=\"NaN / no corr\"\n",
    "        )\n",
    "\n",
    "# === PLOT FUNCTIONS ===\n",
    "def plot_by_mode(df_sub, corr_type, anchor, pooling, out_dir):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "    for ax, mode in zip(axes, [\"raw\", \"unit_rms\", \"norm_rms\"]):\n",
    "        dmode = df_sub[df_sub[\"mode\"] == mode]\n",
    "        if dmode.empty:\n",
    "            ax.text(0.5, 0.5, \"no data\", ha=\"center\", va=\"center\", fontsize=11)\n",
    "            continue\n",
    "        sns.lineplot(\n",
    "            data=dmode, x=\"layer_index\", y=\"rho_smooth\",\n",
    "            hue=\"model\", style=\"metric\", lw=2, ax=ax\n",
    "        )\n",
    "        _mark_nans(ax, dmode)\n",
    "        ax.axhline(0, color=\"black\", linestyle=\":\")\n",
    "        ax.axhline(0.3, color=\"gray\", linestyle=\"--\", lw=0.6, alpha=0.4)\n",
    "        ax.axhline(-0.3, color=\"gray\", linestyle=\"--\", lw=0.6, alpha=0.4)\n",
    "        ax.set_ylim(-1, 1)\n",
    "        ax.set_title(mode.upper(), fontsize=12, weight=\"bold\")\n",
    "        ax.set_xlabel(\"Layer index\")\n",
    "        ax.set_ylabel(\"ρ\" if mode == \"raw\" else \"\")\n",
    "        ax.legend(fontsize=8)\n",
    "    _finalize_grid(fig, axes, f\"{corr_type.capitalize()} — {anchor} ({pooling})\",\n",
    "                   out_dir / f\"{corr_type}_{anchor}_{pooling}_modes.png\")\n",
    "\n",
    "def plot_by_metric(df_sub, corr_type, anchor, pooling, out_dir, n_cols=3):\n",
    "    metrics = sorted(df_sub[\"metric\"].unique())\n",
    "    n_rows, n_cols = _auto_subplots(len(metrics), n_cols)\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(6 * n_cols, 3.5 * n_rows), sharey=True)\n",
    "    axes = np.array(axes).reshape(-1)\n",
    "    for ax, metric in zip(axes, metrics):\n",
    "        dmet = df_sub[df_sub[\"metric\"] == metric]\n",
    "        if dmet.empty:\n",
    "            continue\n",
    "        sns.lineplot(\n",
    "            data=dmet, x=\"layer_index\", y=\"rho_smooth\",\n",
    "            hue=\"model\", style=\"mode\", lw=2.2, ax=ax\n",
    "        )\n",
    "        _mark_nans(ax, dmet)\n",
    "        ax.axhline(0, color=\"black\", linestyle=\":\")\n",
    "        ax.axhline(0.3, color=\"gray\", linestyle=\"--\", lw=0.6, alpha=0.4)\n",
    "        ax.axhline(-0.3, color=\"gray\", linestyle=\"--\", lw=0.6, alpha=0.4)\n",
    "        ax.set_ylim(-1, 1)\n",
    "        ax.set_title(metric, fontsize=10)\n",
    "        ax.set_xlabel(\"Layer index\")\n",
    "        ax.set_ylabel(\"ρ\")\n",
    "        ax.legend(fontsize=8, frameon=True)\n",
    "    _finalize_grid(fig, axes, f\"{corr_type.capitalize()} — {anchor} ({pooling})\",\n",
    "                   out_dir / f\"{corr_type}_{anchor}_{pooling}_metrics.png\")\n",
    "\n",
    "def plot_by_group(df_sub, corr_type, anchor, pooling, out_dir):\n",
    "    for gname, gmetrics in GROUPS.items():\n",
    "        dgroup = df_sub[df_sub[\"metric\"].isin(gmetrics)]\n",
    "        if dgroup.empty:\n",
    "            continue\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "        for ax, mode in zip(axes, [\"raw\", \"unit_rms\", \"norm_rms\"]):\n",
    "            dmode = dgroup[dgroup[\"mode\"] == mode]\n",
    "            if dmode.empty:\n",
    "                ax.text(0.5, 0.5, \"no data\", ha=\"center\", va=\"center\", fontsize=11)\n",
    "                continue\n",
    "            sns.lineplot(\n",
    "                data=dmode, x=\"layer_index\", y=\"rho_smooth\",\n",
    "                hue=\"model\", style=\"metric\", lw=2, ax=ax\n",
    "            )\n",
    "            _mark_nans(ax, dmode)\n",
    "            ax.axhline(0, color=\"black\", linestyle=\":\")\n",
    "            ax.axhline(0.3, color=\"gray\", linestyle=\"--\", lw=0.6, alpha=0.4)\n",
    "            ax.axhline(-0.3, color=\"gray\", linestyle=\"--\", lw=0.6, alpha=0.4)\n",
    "            ax.set_ylim(-1, 1)\n",
    "            ax.set_title(f\"{gname.title()} ({mode})\", fontsize=11)\n",
    "            ax.set_xlabel(\"Layer index\")\n",
    "            ax.set_ylabel(\"ρ\" if mode == \"raw\" else \"\")\n",
    "            ax.legend(fontsize=8, frameon=True)\n",
    "        _finalize_grid(fig, axes,\n",
    "                       f\"{gname.capitalize()} — {corr_type.capitalize()} ({anchor}/{pooling})\",\n",
    "                       out_dir / f\"{corr_type}_{anchor}_{pooling}_{gname}.png\")\n",
    "\n",
    "# === MAIN LOOP ===\n",
    "for pooling in [\"pooled\", \"per_prompt\"]:\n",
    "    out_dir = OUT_ROOT / pooling\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Continuous (Spearman)\n",
    "    for anchor in ANCHORS_CONTINUOUS:\n",
    "        df_s = df[\n",
    "            (df[\"anchor\"] == anchor)\n",
    "            & (df[\"corr_type\"] == \"spearman\")\n",
    "            & (df[\"pooling\"] == pooling)\n",
    "            & (df[\"metric\"].isin(SPEARMAN_METRICS))\n",
    "        ]\n",
    "        if df_s.empty:\n",
    "            continue\n",
    "        if LAYOUT_MODE == \"mode\":\n",
    "            plot_by_mode(df_s, \"spearman\", anchor, pooling, out_dir)\n",
    "        elif LAYOUT_MODE == \"metric\":\n",
    "            plot_by_metric(df_s, \"spearman\", anchor, pooling, out_dir)\n",
    "        elif LAYOUT_MODE == \"group\":\n",
    "            plot_by_group(df_s, \"spearman\", anchor, pooling, out_dir)\n",
    "\n",
    "    # Binary (Point-biserial & Phi)\n",
    "    for corr_type in [\"pointbiserial\", \"phi\"]:\n",
    "        for anchor in ANCHORS_BINARY:\n",
    "            df_b = df[\n",
    "                (df[\"anchor\"] == anchor)\n",
    "                & (df[\"corr_type\"] == corr_type)\n",
    "                & (df[\"pooling\"] == pooling)\n",
    "                & (df[\"metric\"].isin(BISERIAL_METRICS))\n",
    "            ]\n",
    "            if df_b.empty:\n",
    "                continue\n",
    "            if LAYOUT_MODE == \"mode\":\n",
    "                plot_by_mode(df_b, corr_type, anchor, pooling, out_dir)\n",
    "            elif LAYOUT_MODE == \"metric\":\n",
    "                plot_by_metric(df_b, corr_type, anchor, pooling, out_dir)\n",
    "            elif LAYOUT_MODE == \"group\":\n",
    "                plot_by_group(df_b, corr_type, anchor, pooling, out_dir)\n",
    "\n",
    "# === QUICK TOPLIST ===\n",
    "top = (\n",
    "    df.groupby([\"anchor\", \"metric\", \"corr_type\", \"model\"])[\"rho\"]\n",
    "      .mean().reset_index()\n",
    "      .sort_values(\"rho\", ascending=False)\n",
    ")\n",
    "print(\"\\nTop correlations:\")\n",
    "print(top.head(20).to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a84c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] merged 27923 rows from 3 models.\n",
      "[saved] saved_data/figures_flexible_clean/pooled/spearman_logp_diff_pooled_metrics.png\n",
      "[saved] saved_data/figures_flexible_clean/pooled/pointbiserial_disagree_correct_pooled_metrics.png\n",
      "[saved] saved_data/figures_flexible_clean/per_prompt/spearman_logp_diff_per_prompt_metrics.png\n",
      "[saved] saved_data/figures_flexible_clean/per_prompt/pointbiserial_disagree_correct_per_prompt_metrics.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", context=\"talk\", palette=\"deep\")\n",
    "\n",
    "\n",
    "BASE_DIR = Path(\"saved_data/summary\")\n",
    "MODELS = [\"m_4bit\", \"m_8bit\", \"m_quant\"]\n",
    "ANCHORS_CONTINUOUS = [\"logp_diff\"]\n",
    "ANCHORS_BINARY = [\"disagree_correct\"]\n",
    "OUT_ROOT = Path(\"saved_data/figures_flexible_clean\")\n",
    "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "LAYOUT_MODE = \"metric\"   # \"mode\" | \"metric\" | \"group\"\n",
    "\n",
    "SPEARMAN_METRICS = [\n",
    "    \"tvd\",\"kl_ab\",\"kl_ba\",\"js_div\",\"js_dist\",\"cosine_sim\",\n",
    "    \"l2_dist\",\"ppl_diff\",\"jaccard_@1\",\"jaccard_@5\",\"jaccard_@10\"\n",
    "]\n",
    "BISERIAL_METRICS = [\n",
    "    \"acc_A_@1\",\"acc_A_@5\",\"acc_A_@10\",\n",
    "    \"acc_B_@1\",\"acc_B_@5\",\"acc_B_@10\",\n",
    "    \"disagree_correct\",\"jaccard_@1\",\"jaccard_@5\",\"jaccard_@10\"\n",
    "]\n",
    "\n",
    "GROUPS = {\n",
    "    \"divergence\": [\"tvd\",\"kl_ab\",\"kl_ba\",\"js_div\",\"js_dist\",\"ppl_diff\"],\n",
    "    \"representation\": [\"cosine_sim\",\"l2_dist\",\"jaccard_@1\",\"jaccard_@5\",\"jaccard_@10\"],\n",
    "    \"accuracy\": [\"acc_A_@1\",\"acc_B_@1\",\"acc_A_@5\",\"acc_B_@5\",\"disagree_correct\"]\n",
    "}\n",
    "\n",
    "\n",
    "dfs = []\n",
    "for model in MODELS:\n",
    "    model_dir = BASE_DIR / model\n",
    "    if not model_dir.exists():\n",
    "        continue\n",
    "    for f in model_dir.glob(\"*_summary*.csv\"): \n",
    "        d = pd.read_csv(f)\n",
    "        d[\"model\"] = model\n",
    "        if \"pooled\" in f.stem:\n",
    "            d[\"pooling\"] = \"pooled\"\n",
    "        elif \"perprompt\" in f.stem or \"per_prompt\" in f.stem:\n",
    "            d[\"pooling\"] = \"per_prompt\"\n",
    "        else:\n",
    "            d[\"pooling\"] = \"unknown\"\n",
    "        dfs.append(d)\n",
    "\n",
    "if not dfs:\n",
    "    raise RuntimeError(\"No summary files found!\")\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "for c in [\"rho_mean\",\"rho_low\",\"rho_high\"]:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "df[\"layer_index\"] = pd.to_numeric(df[\"layer_index\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "print(f\"[ok] merged {len(df)} rows from {df['model'].nunique()} models.\")\n",
    "\n",
    "\n",
    "def _auto_subplots(n_items, n_cols=3):\n",
    "    \"\"\"Return dynamic rows/cols for a clean subplot grid.\"\"\"\n",
    "    n_rows = int(np.ceil(n_items / n_cols))\n",
    "    return n_rows, n_cols\n",
    "\n",
    "\n",
    "def _finalize_grid(fig, axes, title, save_path=None):\n",
    "    \"\"\"Uniform cleanup for figure layout.\"\"\"\n",
    "    for ax in axes.flat:\n",
    "        if not ax.has_data():\n",
    "            ax.axis(\"off\")\n",
    "    fig.suptitle(title, fontsize=15, weight=\"bold\")\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    if save_path:\n",
    "        fig.savefig(save_path, dpi=250, bbox_inches=\"tight\")\n",
    "        print(f\"[saved] {save_path}\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def plot_by_mode(df_sub, corr_type, anchor, pooling, out_dir):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "    modes = [\"raw\", \"unit_rms\", \"norm_rms\"]\n",
    "\n",
    "    for ax, mode in zip(axes, modes):\n",
    "        dmode = df_sub[df_sub[\"mode\"] == mode]\n",
    "        if dmode.empty:\n",
    "            ax.text(0.5, 0.5, \"no data\", ha=\"center\", va=\"center\", fontsize=11)\n",
    "            continue\n",
    "        sns.lineplot(\n",
    "            data=dmode, x=\"layer_index\", y=\"rho_mean\",\n",
    "            hue=\"model\", style=\"metric\", markers=False,\n",
    "            lw=2, ax=ax\n",
    "        )\n",
    "        ax.set_title(mode.upper(), fontsize=12, weight=\"bold\")\n",
    "        ax.set_xlabel(\"Layer index\")\n",
    "        ax.set_ylabel(\"Mean ρ\" if mode == \"raw\" else \"\")\n",
    "        ax.axhline(0, color=\"black\", linestyle=\":\")\n",
    "        ax.legend(fontsize=8)\n",
    "\n",
    "    _finalize_grid(fig, axes, f\"{corr_type.capitalize()} — {anchor} ({pooling})\",\n",
    "                   out_dir / f\"{corr_type}_{anchor}_{pooling}_modes.png\")\n",
    "\n",
    "\n",
    "def plot_by_metric(df_sub, corr_type, anchor, pooling, out_dir, n_cols=3):\n",
    "    metrics = sorted(df_sub[\"metric\"].unique())\n",
    "    n_rows, n_cols = _auto_subplots(len(metrics), n_cols)\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(6 * n_cols, 3.5 * n_rows), sharey=True)\n",
    "    axes = np.array(axes).reshape(-1)\n",
    "\n",
    "    for ax, metric in zip(axes, metrics):\n",
    "        dmet = df_sub[df_sub[\"metric\"] == metric]\n",
    "        if dmet.empty:\n",
    "            continue\n",
    "        sns.lineplot(\n",
    "            data=dmet, x=\"layer_index\", y=\"rho_mean\",\n",
    "            hue=\"model\", style=\"mode\", lw=2.2,\n",
    "            ax=ax\n",
    "        )\n",
    "        ax.axhline(0, color=\"black\", linestyle=\":\")\n",
    "        ax.set_title(metric, fontsize=10)\n",
    "        ax.set_xlabel(\"Layer index\")\n",
    "        ax.set_ylabel(\"ρ\")\n",
    "        ax.legend(fontsize=8, frameon=True)\n",
    "\n",
    "    _finalize_grid(fig, axes, f\"{corr_type.capitalize()} — {anchor} ({pooling})\",\n",
    "                   out_dir / f\"{corr_type}_{anchor}_{pooling}_metrics.png\")\n",
    "\n",
    "\n",
    "def plot_by_group(df_sub, corr_type, anchor, pooling, out_dir):\n",
    "    for gname, gmetrics in GROUPS.items():\n",
    "        dgroup = df_sub[df_sub[\"metric\"].isin(gmetrics)]\n",
    "        if dgroup.empty:\n",
    "            continue\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "        for ax, mode in zip(axes, [\"raw\", \"unit_rms\", \"norm_rms\"]):\n",
    "            dmode = dgroup[dgroup[\"mode\"] == mode]\n",
    "            if dmode.empty:\n",
    "                ax.text(0.5, 0.5, \"no data\", ha=\"center\", va=\"center\", fontsize=11)\n",
    "                continue\n",
    "            sns.lineplot(\n",
    "                data=dmode, x=\"layer_index\", y=\"rho_mean\",\n",
    "                hue=\"model\", style=\"metric\", lw=2,\n",
    "                ax=ax\n",
    "            )\n",
    "            ax.axhline(0, color=\"black\", linestyle=\":\")\n",
    "            ax.set_title(f\"{gname.title()} ({mode})\", fontsize=11)\n",
    "            ax.set_xlabel(\"Layer index\")\n",
    "            ax.set_ylabel(\"ρ\" if mode == \"raw\" else \"\")\n",
    "            ax.legend(fontsize=8, frameon=True)\n",
    "\n",
    "        _finalize_grid(fig, axes,\n",
    "                       f\"{gname.capitalize()} — {corr_type.capitalize()} ({anchor}/{pooling})\",\n",
    "                       out_dir / f\"{corr_type}_{anchor}_{pooling}_{gname}.png\")\n",
    "\n",
    "\n",
    "for pooling in [\"pooled\", \"per_prompt\"]:\n",
    "    out_dir = OUT_ROOT / pooling\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Continuous anchors Spearman\n",
    "    for anchor in ANCHORS_CONTINUOUS:\n",
    "        df_s = df[\n",
    "            (df[\"anchor\"] == anchor)\n",
    "            & (df[\"corr_type\"] == \"spearman\")\n",
    "            & (df[\"pooling\"] == pooling)\n",
    "            & (df[\"metric\"].isin(SPEARMAN_METRICS))\n",
    "        ]\n",
    "        if df_s.empty:\n",
    "            continue\n",
    "        if LAYOUT_MODE == \"mode\":\n",
    "            plot_by_mode(df_s, \"spearman\", anchor, pooling, out_dir)\n",
    "        elif LAYOUT_MODE == \"metric\":\n",
    "            plot_by_metric(df_s, \"spearman\", anchor, pooling, out_dir)\n",
    "        elif LAYOUT_MODE == \"group\":\n",
    "            plot_by_group(df_s, \"spearman\", anchor, pooling, out_dir)\n",
    "\n",
    "    # Binary anchors Point-biserial\n",
    "    for anchor in ANCHORS_BINARY:\n",
    "        df_b = df[\n",
    "            (df[\"anchor\"] == anchor)\n",
    "            & (df[\"corr_type\"] == \"pointbiserial\")\n",
    "            & (df[\"pooling\"] == pooling)\n",
    "            & (df[\"metric\"].isin(BISERIAL_METRICS))\n",
    "        ]\n",
    "        if df_b.empty:\n",
    "            continue\n",
    "        if LAYOUT_MODE == \"mode\":\n",
    "            plot_by_mode(df_b, \"pointbiserial\", anchor, pooling, out_dir)\n",
    "        elif LAYOUT_MODE == \"metric\":\n",
    "            plot_by_metric(df_b, \"pointbiserial\", anchor, pooling, out_dir)\n",
    "        elif LAYOUT_MODE == \"group\":\n",
    "            plot_by_group(df_b, \"pointbiserial\", anchor, pooling, out_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e61b4a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] merged 27923 raw correlation rows from 3 models.\n",
      "[saved] saved_data/figures_flexible_rawcorr/pooled/spearman_logp_diff_pooled_metrics_raw.png\n",
      "[saved] saved_data/figures_flexible_rawcorr/pooled/pointbiserial_disagree_correct_pooled_metrics_raw.png\n",
      "[saved] saved_data/figures_flexible_rawcorr/per_prompt/spearman_logp_diff_per_prompt_metrics_raw.png\n",
      "[saved] saved_data/figures_flexible_rawcorr/per_prompt/pointbiserial_disagree_correct_per_prompt_metrics_raw.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", context=\"talk\", palette=\"deep\")\n",
    "\n",
    "# === CONFIG ===\n",
    "BASE_DIR = Path(\"saved_data/summary\")\n",
    "MODELS = [\"m_4bit\", \"m_8bit\", \"m_quant\"]\n",
    "ANCHORS_CONTINUOUS = [\"logp_diff\"]\n",
    "ANCHORS_BINARY = [\"disagree_correct\"]\n",
    "OUT_ROOT = Path(\"saved_data/figures_flexible_rawcorr\")\n",
    "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "LAYOUT_MODE = \"metric\"   # \"mode\" | \"metric\" | \"group\"\n",
    "\n",
    "SPEARMAN_METRICS = [\n",
    "    \"tvd\",\"kl_ab\",\"kl_ba\",\"js_div\",\"js_dist\",\"cosine_sim\",\n",
    "    \"l2_dist\",\"ppl_diff\",\"jaccard_@1\",\"jaccard_@5\",\"jaccard_@10\"\n",
    "]\n",
    "BISERIAL_METRICS = [\n",
    "    \"acc_A_@1\",\"acc_A_@5\",\"acc_A_@10\",\n",
    "    \"acc_B_@1\",\"acc_B_@5\",\"acc_B_@10\",\n",
    "    \"disagree_correct\",\"jaccard_@1\",\"jaccard_@5\",\"jaccard_@10\"\n",
    "]\n",
    "GROUPS = {\n",
    "    \"divergence\": [\"tvd\",\"kl_ab\",\"kl_ba\",\"js_div\",\"js_dist\",\"ppl_diff\"],\n",
    "    \"representation\": [\"cosine_sim\",\"l2_dist\",\"jaccard_@1\",\"jaccard_@5\",\"jaccard_@10\"],\n",
    "    \"accuracy\": [\"acc_A_@1\",\"acc_B_@1\",\"acc_A_@5\",\"acc_B_@5\",\"disagree_correct\"]\n",
    "}\n",
    "\n",
    "\n",
    "# === LOAD RAW CORR FILES (not summaries) ===\n",
    "dfs = []\n",
    "for model in MODELS:\n",
    "    model_dir = BASE_DIR / model\n",
    "    if not model_dir.exists():\n",
    "        continue\n",
    "    for f in model_dir.glob(\"*corr_*.csv\"):\n",
    "        if \"summary\" in f.name:\n",
    "            continue  # skip summaries\n",
    "        d = pd.read_csv(f)\n",
    "        d[\"model\"] = model\n",
    "        if \"pooled\" in f.stem:\n",
    "            d[\"pooling\"] = \"pooled\"\n",
    "        elif \"perprompt\" in f.stem or \"per_prompt\" in f.stem:\n",
    "            d[\"pooling\"] = \"per_prompt\"\n",
    "        else:\n",
    "            d[\"pooling\"] = \"unknown\"\n",
    "        dfs.append(d)\n",
    "\n",
    "if not dfs:\n",
    "    raise RuntimeError(\"No raw correlation files found!\")\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "for c in [\"rho\"]:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "df[\"layer_index\"] = pd.to_numeric(df[\"layer_index\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "print(f\"[ok] merged {len(df)} raw correlation rows from {df['model'].nunique()} models.\")\n",
    "\n",
    "\n",
    "# === PLOTTING HELPERS ===\n",
    "def _auto_subplots(n_items, n_cols=3):\n",
    "    n_rows = int(np.ceil(n_items / n_cols))\n",
    "    return n_rows, n_cols\n",
    "\n",
    "def _finalize_grid(fig, axes, title, save_path=None):\n",
    "    for ax in axes.flat:\n",
    "        if not ax.has_data():\n",
    "            ax.axis(\"off\")\n",
    "    fig.suptitle(title, fontsize=15, weight=\"bold\")\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    if save_path:\n",
    "        fig.savefig(save_path, dpi=250, bbox_inches=\"tight\")\n",
    "        print(f\"[saved] {save_path}\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# === PLOT FUNCTIONS (identiske men y='rho') ===\n",
    "def plot_by_mode(df_sub, corr_type, anchor, pooling, out_dir):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "    modes = [\"raw\", \"unit_rms\", \"norm_rms\"]\n",
    "    for ax, mode in zip(axes, modes):\n",
    "        dmode = df_sub[df_sub[\"mode\"] == mode]\n",
    "        if dmode.empty:\n",
    "            ax.text(0.5, 0.5, \"no data\", ha=\"center\", va=\"center\", fontsize=11)\n",
    "            continue\n",
    "        sns.lineplot(\n",
    "            data=dmode, x=\"layer_index\", y=\"rho\",\n",
    "            hue=\"model\", style=\"metric\", lw=2, ax=ax\n",
    "        )\n",
    "        ax.set_title(mode.upper(), fontsize=12, weight=\"bold\")\n",
    "        ax.set_xlabel(\"Layer index\")\n",
    "        ax.set_ylabel(\"ρ\" if mode == \"raw\" else \"\")\n",
    "        ax.axhline(0, color=\"black\", linestyle=\":\")\n",
    "        ax.legend(fontsize=8)\n",
    "    _finalize_grid(fig, axes, f\"{corr_type.capitalize()} — {anchor} ({pooling})\",\n",
    "                   out_dir / f\"{corr_type}_{anchor}_{pooling}_modes_raw.png\")\n",
    "\n",
    "\n",
    "def plot_by_metric(df_sub, corr_type, anchor, pooling, out_dir, n_cols=3):\n",
    "    metrics = sorted(df_sub[\"metric\"].unique())\n",
    "    n_rows, n_cols = _auto_subplots(len(metrics), n_cols)\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(6 * n_cols, 3.5 * n_rows), sharey=True)\n",
    "    axes = np.array(axes).reshape(-1)\n",
    "    for ax, metric in zip(axes, metrics):\n",
    "        dmet = df_sub[df_sub[\"metric\"] == metric]\n",
    "        if dmet.empty:\n",
    "            continue\n",
    "        sns.lineplot(\n",
    "            data=dmet, x=\"layer_index\", y=\"rho\",\n",
    "            hue=\"model\", style=\"mode\", lw=2.2, ax=ax\n",
    "        )\n",
    "        ax.axhline(0, color=\"black\", linestyle=\":\")\n",
    "        ax.set_title(metric, fontsize=10)\n",
    "        ax.set_xlabel(\"Layer index\")\n",
    "        ax.set_ylabel(\"ρ\")\n",
    "        ax.legend(fontsize=8, frameon=True)\n",
    "    _finalize_grid(fig, axes, f\"{corr_type.capitalize()} — {anchor} ({pooling})\",\n",
    "                   out_dir / f\"{corr_type}_{anchor}_{pooling}_metrics_raw.png\")\n",
    "\n",
    "\n",
    "def plot_by_group(df_sub, corr_type, anchor, pooling, out_dir):\n",
    "    for gname, gmetrics in GROUPS.items():\n",
    "        dgroup = df_sub[df_sub[\"metric\"].isin(gmetrics)]\n",
    "        if dgroup.empty:\n",
    "            continue\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "        for ax, mode in zip(axes, [\"raw\", \"unit_rms\", \"norm_rms\"]):\n",
    "            dmode = dgroup[dgroup[\"mode\"] == mode]\n",
    "            if dmode.empty:\n",
    "                ax.text(0.5, 0.5, \"no data\", ha=\"center\", va=\"center\", fontsize=11)\n",
    "                continue\n",
    "            sns.lineplot(\n",
    "                data=dmode, x=\"layer_index\", y=\"rho\",\n",
    "                hue=\"model\", style=\"metric\", lw=2, ax=ax\n",
    "            )\n",
    "            ax.axhline(0, color=\"black\", linestyle=\":\")\n",
    "            ax.set_title(f\"{gname.title()} ({mode})\", fontsize=11)\n",
    "            ax.set_xlabel(\"Layer index\")\n",
    "            ax.set_ylabel(\"ρ\" if mode == \"raw\" else \"\")\n",
    "            ax.legend(fontsize=8, frameon=True)\n",
    "        _finalize_grid(fig, axes,\n",
    "                       f\"{gname.capitalize()} — {corr_type.capitalize()} ({anchor}/{pooling})\",\n",
    "                       out_dir / f\"{corr_type}_{anchor}_{pooling}_{gname}_raw.png\")\n",
    "\n",
    "\n",
    "# === MAIN LOOP ===\n",
    "for pooling in [\"pooled\", \"per_prompt\"]:\n",
    "    out_dir = OUT_ROOT / pooling\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Continuous (Spearman)\n",
    "    for anchor in ANCHORS_CONTINUOUS:\n",
    "        df_s = df[\n",
    "            (df[\"anchor\"] == anchor)\n",
    "            & (df[\"corr_type\"] == \"spearman\")\n",
    "            & (df[\"pooling\"] == pooling)\n",
    "            & (df[\"metric\"].isin(SPEARMAN_METRICS))\n",
    "        ]\n",
    "        if df_s.empty:\n",
    "            continue\n",
    "        if LAYOUT_MODE == \"mode\":\n",
    "            plot_by_mode(df_s, \"spearman\", anchor, pooling, out_dir)\n",
    "        elif LAYOUT_MODE == \"metric\":\n",
    "            plot_by_metric(df_s, \"spearman\", anchor, pooling, out_dir)\n",
    "        elif LAYOUT_MODE == \"group\":\n",
    "            plot_by_group(df_s, \"spearman\", anchor, pooling, out_dir)\n",
    "\n",
    "    # Binary (Point-biserial)\n",
    "    for anchor in ANCHORS_BINARY:\n",
    "        df_b = df[\n",
    "            (df[\"anchor\"] == anchor)\n",
    "            & (df[\"corr_type\"] == \"pointbiserial\")\n",
    "            & (df[\"pooling\"] == pooling)\n",
    "            & (df[\"metric\"].isin(BISERIAL_METRICS))\n",
    "        ]\n",
    "        if df_b.empty:\n",
    "            continue\n",
    "        if LAYOUT_MODE == \"mode\":\n",
    "            plot_by_mode(df_b, \"pointbiserial\", anchor, pooling, out_dir)\n",
    "        elif LAYOUT_MODE == \"metric\":\n",
    "            plot_by_metric(df_b, \"pointbiserial\", anchor, pooling, out_dir)\n",
    "        elif LAYOUT_MODE == \"group\":\n",
    "            plot_by_group(df_b, \"pointbiserial\", anchor, pooling, out_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b619394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] merged 27923 rows from 3 models.\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/pooled/m_4bit_spearman_logp_diff_pooled_raw_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/pooled/m_8bit_spearman_logp_diff_pooled_raw_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/pooled/m_quant_spearman_logp_diff_pooled_raw_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/pooled/m_4bit_spearman_logp_diff_pooled_unit_rms_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/pooled/m_8bit_spearman_logp_diff_pooled_unit_rms_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/pooled/m_quant_spearman_logp_diff_pooled_unit_rms_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/pooled/m_4bit_spearman_logp_diff_pooled_norm_rms_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/pooled/m_8bit_spearman_logp_diff_pooled_norm_rms_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/pooled/m_quant_spearman_logp_diff_pooled_norm_rms_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/pooled/m_4bit_pointbiserial_disagree_correct_pooled_raw_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/pooled/m_8bit_pointbiserial_disagree_correct_pooled_raw_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/pooled/m_quant_pointbiserial_disagree_correct_pooled_raw_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/pooled/m_4bit_pointbiserial_disagree_correct_pooled_unit_rms_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/pooled/m_8bit_pointbiserial_disagree_correct_pooled_unit_rms_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/pooled/m_quant_pointbiserial_disagree_correct_pooled_unit_rms_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/pooled/m_4bit_pointbiserial_disagree_correct_pooled_norm_rms_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/pooled/m_8bit_pointbiserial_disagree_correct_pooled_norm_rms_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/pooled/m_quant_pointbiserial_disagree_correct_pooled_norm_rms_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/per_prompt/m_4bit_spearman_logp_diff_per_prompt_raw_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/per_prompt/m_8bit_spearman_logp_diff_per_prompt_raw_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/per_prompt/m_quant_spearman_logp_diff_per_prompt_raw_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/per_prompt/m_4bit_spearman_logp_diff_per_prompt_unit_rms_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/per_prompt/m_8bit_spearman_logp_diff_per_prompt_unit_rms_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/per_prompt/m_quant_spearman_logp_diff_per_prompt_unit_rms_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/per_prompt/m_4bit_spearman_logp_diff_per_prompt_norm_rms_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/per_prompt/m_8bit_spearman_logp_diff_per_prompt_norm_rms_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/per_prompt/m_quant_spearman_logp_diff_per_prompt_norm_rms_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/per_prompt/m_4bit_pointbiserial_disagree_correct_per_prompt_raw_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/per_prompt/m_8bit_pointbiserial_disagree_correct_per_prompt_raw_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/per_prompt/m_quant_pointbiserial_disagree_correct_per_prompt_raw_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/per_prompt/m_4bit_pointbiserial_disagree_correct_per_prompt_unit_rms_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/per_prompt/m_8bit_pointbiserial_disagree_correct_per_prompt_unit_rms_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/per_prompt/m_quant_pointbiserial_disagree_correct_per_prompt_unit_rms_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/per_prompt/m_4bit_pointbiserial_disagree_correct_per_prompt_norm_rms_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/per_prompt/m_8bit_pointbiserial_disagree_correct_per_prompt_norm_rms_heatmap.png\n",
      "[saved] saved_data/figures_heatmaps_rawcorr/per_prompt/m_quant_pointbiserial_disagree_correct_per_prompt_norm_rms_heatmap.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", context=\"talk\", palette=\"deep\")\n",
    "\n",
    "# === CONFIG ===\n",
    "BASE_DIR = Path(\"saved_data/summary\")\n",
    "MODELS = [\"m_4bit\", \"m_8bit\", \"m_quant\"]\n",
    "ANCHORS_CONTINUOUS = [\"logp_diff\"]\n",
    "ANCHORS_BINARY = [\"disagree_correct\"]\n",
    "OUT_ROOT = Path(\"saved_data/figures_heatmaps_rawcorr\")\n",
    "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SPEARMAN_METRICS = [\n",
    "    \"tvd\",\"kl_ab\",\"kl_ba\",\"js_div\",\"js_dist\",\"cosine_sim\",\n",
    "    \"l2_dist\",\"ppl_diff\",\"jaccard_@1\",\"jaccard_@5\",\"jaccard_@10\"\n",
    "]\n",
    "BISERIAL_METRICS = [\n",
    "    \"acc_A_@1\",\"acc_A_@5\",\"acc_A_@10\",\n",
    "    \"acc_B_@1\",\"acc_B_@5\",\"acc_B_@10\",\n",
    "    \"disagree_correct\",\"jaccard_@1\",\"jaccard_@5\",\"jaccard_@10\"\n",
    "]\n",
    "\n",
    "# === LOAD RAW CORR FILES ===\n",
    "dfs = []\n",
    "for model in MODELS:\n",
    "    model_dir = BASE_DIR / model\n",
    "    if not model_dir.exists():\n",
    "        continue\n",
    "    for f in model_dir.glob(\"*corr_*.csv\"):\n",
    "        if \"summary\" in f.name:\n",
    "            continue\n",
    "        d = pd.read_csv(f)\n",
    "        d[\"model\"] = model\n",
    "        if \"pooled\" in f.stem:\n",
    "            d[\"pooling\"] = \"pooled\"\n",
    "        elif \"perprompt\" in f.stem or \"per_prompt\" in f.stem:\n",
    "            d[\"pooling\"] = \"per_prompt\"\n",
    "        else:\n",
    "            d[\"pooling\"] = \"unknown\"\n",
    "        dfs.append(d)\n",
    "\n",
    "if not dfs:\n",
    "    raise RuntimeError(\"No raw correlation files found!\")\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "df[\"rho\"] = pd.to_numeric(df[\"rho\"], errors=\"coerce\")\n",
    "df[\"layer_index\"] = pd.to_numeric(df[\"layer_index\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "print(f\"[ok] merged {len(df)} rows from {df['model'].nunique()} models.\")\n",
    "\n",
    "\n",
    "# === HEATMAP FUNCTION ===\n",
    "def plot_heatmap(df_sub, corr_type, anchor, pooling, out_dir):\n",
    "    \"\"\"\n",
    "    Plots rho values as a heatmap (metric x layer) for each model/mode combo.\n",
    "    \"\"\"\n",
    "    modes = [\"raw\", \"unit_rms\", \"norm_rms\"]\n",
    "    for mode in modes:\n",
    "        dmode = df_sub[df_sub[\"mode\"] == mode]\n",
    "        if dmode.empty:\n",
    "            continue\n",
    "\n",
    "        for model in dmode[\"model\"].unique():\n",
    "            dmodel = dmode[dmode[\"model\"] == model]\n",
    "            if dmodel.empty:\n",
    "                continue\n",
    "\n",
    "            # Pivot so that rows = metric, columns = layer_index\n",
    "            heat = dmodel.pivot_table(\n",
    "                index=\"metric\", columns=\"layer_index\", values=\"rho\", aggfunc=\"mean\"\n",
    "            ).sort_index()\n",
    "\n",
    "            plt.figure(figsize=(12, max(6, 0.4 * len(heat))))\n",
    "            sns.heatmap(\n",
    "                heat, cmap=\"coolwarm\", center=0, annot=True, fmt=\".2f\",\n",
    "                cbar_kws={\"label\": \"ρ (correlation)\"}, linewidths=0.4\n",
    "            )\n",
    "            plt.title(f\"{model} — {anchor} ({pooling}, {corr_type}, {mode})\", fontsize=13, weight=\"bold\")\n",
    "            plt.xlabel(\"Layer index\")\n",
    "            plt.ylabel(\"Metric\")\n",
    "            plt.tight_layout()\n",
    "\n",
    "            out_path = out_dir / f\"{model}_{corr_type}_{anchor}_{pooling}_{mode}_heatmap.png\"\n",
    "            plt.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n",
    "            plt.close()\n",
    "            print(f\"[saved] {out_path}\")\n",
    "\n",
    "\n",
    "# === MAIN LOOP ===\n",
    "for pooling in [\"pooled\", \"per_prompt\"]:\n",
    "    out_dir = OUT_ROOT / pooling\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Continuous anchors (Spearman)\n",
    "    for anchor in ANCHORS_CONTINUOUS:\n",
    "        df_s = df[\n",
    "            (df[\"anchor\"] == anchor)\n",
    "            & (df[\"corr_type\"] == \"spearman\")\n",
    "            & (df[\"pooling\"] == pooling)\n",
    "            & (df[\"metric\"].isin(SPEARMAN_METRICS))\n",
    "        ]\n",
    "        if not df_s.empty:\n",
    "            plot_heatmap(df_s, \"spearman\", anchor, pooling, out_dir)\n",
    "\n",
    "    # Binary anchors (Point-biserial)\n",
    "    for anchor in ANCHORS_BINARY:\n",
    "        df_b = df[\n",
    "            (df[\"anchor\"] == anchor)\n",
    "            & (df[\"corr_type\"] == \"pointbiserial\")\n",
    "            & (df[\"pooling\"] == pooling)\n",
    "            & (df[\"metric\"].isin(BISERIAL_METRICS))\n",
    "        ]\n",
    "        if not df_b.empty:\n",
    "            plot_heatmap(df_b, \"pointbiserial\", anchor, pooling, out_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logit-lens-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
